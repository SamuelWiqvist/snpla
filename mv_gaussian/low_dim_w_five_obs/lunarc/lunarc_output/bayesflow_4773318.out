Input args:
Dim: 2
seed: 45
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.7918772872444242, eval loss: 7.014392375946045
Epoch: 1, loss: 0.4944429590040818, eval loss: 0.5628485679626465
Epoch: 2, loss: 0.4539724289509468, eval loss: 0.4905233085155487
Epoch: 3, loss: 0.44102926199091597, eval loss: 0.5879785418510437
Epoch: 4, loss: 0.43563008077675475, eval loss: 0.4878731667995453
Epoch: 5, loss: 0.4251757372939028, eval loss: 0.40757933259010315
Epoch: 6, loss: 0.4131426954997005, eval loss: 0.4280107021331787
Epoch: 7, loss: 0.4157181320199743, eval loss: 0.4350341856479645
Epoch: 8, loss: 0.4062573881691787, eval loss: 0.47221389412879944
Epoch: 9, loss: 0.40481481575639916, eval loss: 0.4230867326259613
Epoch: 10, loss: 0.3996815910515579, eval loss: 0.49931225180625916
Epoch: 11, loss: 0.40089105428487526, eval loss: 0.3982296884059906
Epoch: 12, loss: 0.3953611599249416, eval loss: 0.42018792033195496
Epoch: 13, loss: 0.3966045224072877, eval loss: 0.40866512060165405
Epoch: 14, loss: 0.39112236970147934, eval loss: 0.4245360493659973
Epoch: 15, loss: 0.39151700451999205, eval loss: 0.4231131672859192
Epoch: 16, loss: 0.390566292044241, eval loss: 0.3956393003463745
Epoch: 17, loss: 0.38933196495188893, eval loss: 0.41488730907440186
Epoch: 18, loss: 0.3889693421163247, eval loss: 0.4025686979293823
Epoch: 19, loss: 0.38899704214010855, eval loss: 0.4305616021156311
Epoch: 20, loss: 0.38761259215010796, eval loss: 0.4788030683994293
Epoch: 21, loss: 0.38511776327621194, eval loss: 0.40334293246269226
Epoch: 22, loss: 0.3871925436575839, eval loss: 0.4080154299736023
Epoch: 23, loss: 0.38329928193670637, eval loss: 0.4005488455295563
Epoch: 24, loss: 0.3858080623319256, eval loss: 0.4154375493526459
Epoch: 25, loss: 0.3828460525877017, eval loss: 0.4262863099575043
Epoch: 26, loss: 0.38281639850581994, eval loss: 0.4065324068069458
Epoch: 27, loss: 0.38579837901939756, eval loss: 0.4213447570800781
Epoch: 28, loss: 0.3820923790030065, eval loss: 0.40948963165283203
Epoch: 29, loss: 0.3829421166008979, eval loss: 0.40116599202156067
Epoch: 30, loss: 0.382770484131006, eval loss: 0.40316346287727356
Epoch: 31, loss: 0.3814396174735157, eval loss: 0.40150848031044006
Epoch: 32, loss: 0.3830585839296691, eval loss: 0.38548946380615234
Epoch: 33, loss: 0.38550101313740015, eval loss: 0.41067832708358765
Epoch: 34, loss: 0.3828936057991814, eval loss: 0.43470698595046997
Epoch: 35, loss: 0.38294651498959864, eval loss: 0.4064423739910126
Epoch: 36, loss: 0.384076560040121, eval loss: 0.39859139919281006
Epoch: 37, loss: 0.3830739812775937, eval loss: 0.403313010931015
Epoch: 38, loss: 0.38372754309792073, eval loss: 0.4012959897518158
Epoch: 39, loss: 0.3829794851253973, eval loss: 0.3967074155807495
Epoch: 40, loss: 0.3841186315706, eval loss: 0.4303480386734009
Epoch: 41, loss: 0.3851765831478406, eval loss: 0.40795817971229553
Epoch: 42, loss: 0.38433631156454795, eval loss: 0.38876742124557495
Epoch: 43, loss: 0.38565717729972676, eval loss: 0.434377521276474
Epoch: 44, loss: 0.3833659079083009, eval loss: 0.4325219392776489
Epoch: 45, loss: 0.3859151646785904, eval loss: 0.4006807804107666
Epoch: 46, loss: 0.38468700455556243, eval loss: 0.40617015957832336
Epoch: 47, loss: 0.3854403282772546, eval loss: 0.39945051074028015
Epoch: 48, loss: 0.3847276705487457, eval loss: 0.40717220306396484
Epoch: 49, loss: 0.3846311271704326, eval loss: 0.38737788796424866

Runtime:759.93
KL div untrained: 5.485068041979446e+16
KL div trained: 0.002
