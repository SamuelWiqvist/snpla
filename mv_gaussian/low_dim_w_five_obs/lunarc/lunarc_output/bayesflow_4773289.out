Input args:
Dim: 2
seed: 16
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.7920299249142408, eval loss: 7.120282173156738
Epoch: 1, loss: 0.48937720008194446, eval loss: 0.5171732902526855
Epoch: 2, loss: 0.45848567351233216, eval loss: 0.3975921869277954
Epoch: 3, loss: 0.4447472678456688, eval loss: 0.4405280649662018
Epoch: 4, loss: 0.43033280500472754, eval loss: 0.48294904828071594
Epoch: 5, loss: 0.4189461933809798, eval loss: 0.39880284667015076
Epoch: 6, loss: 0.4127522678556852, eval loss: 0.43753767013549805
Epoch: 7, loss: 0.4057934877322987, eval loss: 0.3717591166496277
Epoch: 8, loss: 0.4057968020183034, eval loss: 0.4375361204147339
Epoch: 9, loss: 0.3993763321172446, eval loss: 0.3561280071735382
Epoch: 10, loss: 0.3980570770558552, eval loss: 0.3706344664096832
Epoch: 11, loss: 0.39434910454321653, eval loss: 0.34926578402519226
Epoch: 12, loss: 0.39126965479685166, eval loss: 0.3381330370903015
Epoch: 13, loss: 0.39119982949414406, eval loss: 0.3582252860069275
Epoch: 14, loss: 0.38926767802098766, eval loss: 0.3496827781200409
Epoch: 15, loss: 0.38741573766834336, eval loss: 0.35911861062049866
Epoch: 16, loss: 0.38582121314655526, eval loss: 0.3569110929965973
Epoch: 17, loss: 0.3864577336295042, eval loss: 0.35556918382644653
Epoch: 18, loss: 0.3876495726576832, eval loss: 0.3588801324367523
Epoch: 19, loss: 0.3866022679094749, eval loss: 0.35356006026268005
Epoch: 20, loss: 0.3843710397859104, eval loss: 0.3348914384841919
Epoch: 21, loss: 0.38208534349745604, eval loss: 0.3654996454715729
Epoch: 22, loss: 0.3813463778584264, eval loss: 0.3558707535266876
Epoch: 23, loss: 0.3808315464435145, eval loss: 0.33771827816963196
Epoch: 24, loss: 0.38199500873684883, eval loss: 0.34817972779273987
Epoch: 25, loss: 0.38028033897569913, eval loss: 0.3715922236442566
Epoch: 26, loss: 0.38163881699168994, eval loss: 0.3444593548774719
Epoch: 27, loss: 0.37712900529440957, eval loss: 0.35820239782333374
Epoch: 28, loss: 0.3807222211988483, eval loss: 0.34555548429489136
Epoch: 29, loss: 0.38173748793662526, eval loss: 0.3320401906967163
Epoch: 30, loss: 0.3803983109834371, eval loss: 0.3515267074108124
Epoch: 31, loss: 0.3808097216346505, eval loss: 0.3263118267059326
Epoch: 32, loss: 0.38178261722147, eval loss: 0.3260365426540375
Epoch: 33, loss: 0.38011276340286715, eval loss: 0.32002806663513184
Epoch: 34, loss: 0.38067550509920695, eval loss: 0.35450005531311035
Epoch: 35, loss: 0.3797946699967724, eval loss: 0.36890295147895813
Epoch: 36, loss: 0.38129159494128545, eval loss: 0.34763869643211365
Epoch: 37, loss: 0.3803334966598777, eval loss: 0.3348929286003113
Epoch: 38, loss: 0.3806380956759676, eval loss: 0.3265295922756195
Epoch: 39, loss: 0.38175251065578775, eval loss: 0.3597044050693512
Epoch: 40, loss: 0.3820060837474739, eval loss: 0.32548290491104126
Epoch: 41, loss: 0.38148473073146305, eval loss: 0.3418777585029602
Epoch: 42, loss: 0.3822359535351279, eval loss: 0.36348235607147217
Epoch: 43, loss: 0.38137676318961894, eval loss: 0.3272066116333008
Epoch: 44, loss: 0.38330299298933823, eval loss: 0.34054550528526306
Epoch: 45, loss: 0.38300148665788586, eval loss: 0.3200104534626007
Epoch: 46, loss: 0.3807506202463992, eval loss: 0.3355393707752228
Epoch: 47, loss: 0.3843686562134826, eval loss: 0.37971240282058716
Epoch: 48, loss: 0.38253141012566627, eval loss: 0.3331567049026489
Epoch: 49, loss: 0.3820338589608582, eval loss: 0.33141976594924927

Runtime:598.27
KL div untrained: 51856678343.7454
KL div trained: 0.0046
