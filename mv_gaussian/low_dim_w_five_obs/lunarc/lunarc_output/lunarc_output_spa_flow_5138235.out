Input args:
Dim: 2
seed: 5
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
[1.0, 0.6065306597126334, 0.36787944117144233, 0.22313016014842982, 0.1353352832366127, 0.0820849986238988, 0.049787068367863944, 0.0301973834223185, 0.01831563888873418, 0.011108996538242306]
start full training
Iteration: 1
optimizer_post_lr: [0.001]
prob_prior: 1.0
start update likelihood model
Epoch: 0, loss (training): 26.4341, loss (eval): 35.1911
Epoch: 1, loss (training): 20.0587, loss (eval): 21.7555
Epoch: 2, loss (training): 17.8132, loss (eval): 18.4211
Epoch: 3, loss (training): 16.4175, loss (eval): 17.2841
Epoch: 4, loss (training): 15.193, loss (eval): 15.7221
Epoch: 5, loss (training): 14.0731, loss (eval): 14.5854
Epoch: 6, loss (training): 13.0785, loss (eval): 13.4076
Epoch: 7, loss (training): 12.2713, loss (eval): 12.5565
Epoch: 8, loss (training): 11.6737, loss (eval): 11.893
Epoch: 9, loss (training): 11.3459, loss (eval): 11.4361
Epoch: 10, loss (training): 10.8812, loss (eval): 11.1418
Epoch: 11, loss (training): 10.7003, loss (eval): 10.7255
Epoch: 12, loss (training): 10.6241, loss (eval): 10.7134
Epoch: 13, loss (training): 10.5429, loss (eval): 10.8028
Epoch: 14, loss (training): 10.4437, loss (eval): 10.6805
Epoch: 15, loss (training): 10.39, loss (eval): 10.5836
Epoch: 16, loss (training): 10.4083, loss (eval): 10.7371
Epoch: 17, loss (training): 10.3148, loss (eval): 10.3758
Epoch: 18, loss (training): 10.3434, loss (eval): 10.6296
Epoch: 19, loss (training): 10.351, loss (eval): 10.7244
Epoch: 20, loss (training): 10.3674, loss (eval): 10.7373
Epoch: 21, loss (training): 10.2627, loss (eval): 10.4894
Epoch: 22, loss (training): 10.26, loss (eval): 10.5207
Epoch: 23, loss (training): 10.2193, loss (eval): 10.3153
Epoch: 24, loss (training): 10.1596, loss (eval): 10.3884
start update posterior model from prior pred - hot start
Epoch: 0, loss (training): 3.7621, loss (eval): 7.117
Epoch: 1, loss (training): 2.0174, loss (eval): 2.6201
Epoch: 2, loss (training): 1.3403, loss (eval): 1.5501
Epoch: 3, loss (training): 1.2149, loss (eval): 1.3422
Epoch: 4, loss (training): 0.9128, loss (eval): 1.1002
Epoch: 5, loss (training): 0.7471, loss (eval): 0.9331
Epoch: 6, loss (training): 0.7329, loss (eval): 0.7418
Epoch: 7, loss (training): 0.6526, loss (eval): 0.7545
Epoch: 8, loss (training): 0.7981, loss (eval): 1.0443
Epoch: 9, loss (training): 0.5481, loss (eval): 0.6717
start update posterior model
Epoch: 0, loss (training): 13.4288, loss (eval): 13.4849
Epoch: 1, loss (training): 13.4011, loss (eval): 13.3961
Epoch: 2, loss (training): 13.4282, loss (eval): 13.4131
Epoch: 3, loss (training): 13.3959, loss (eval): 13.393
Epoch: 4, loss (training): 13.4113, loss (eval): 13.3843
Epoch: 5, loss (training): 13.4031, loss (eval): 13.5256
Epoch: 6, loss (training): 13.3971, loss (eval): 13.3907
Epoch: 7, loss (training): 13.4056, loss (eval): 13.4787
Epoch: 8, loss (training): 13.399, loss (eval): 13.3924
Epoch: 9, loss (training): 13.4026, loss (eval): 13.3746
Epoch: 10, loss (training): 13.3967, loss (eval): 13.3772
Epoch: 11, loss (training): 13.3913, loss (eval): 13.38
Epoch: 12, loss (training): 13.3957, loss (eval): 13.4296
Epoch: 13, loss (training): 13.3958, loss (eval): 13.3657
Epoch: 14, loss (training): 13.3879, loss (eval): 13.3633
Epoch: 15, loss (training): 13.3907, loss (eval): 13.4339
Epoch: 16, loss (training): 13.4001, loss (eval): 13.399
Epoch: 17, loss (training): 13.3841, loss (eval): 13.3784
Epoch: 18, loss (training): 13.3982, loss (eval): 13.4214
Epoch: 19, loss (training): 13.3858, loss (eval): 13.3991
Epoch: 20, loss (training): 13.3899, loss (eval): 13.3789
Epoch: 21, loss (training): 13.3911, loss (eval): 13.4277
Epoch: 22, loss (training): 13.3823, loss (eval): 13.4022
Epoch: 23, loss (training): 13.3806, loss (eval): 13.3794
Epoch: 24, loss (training): 13.3845, loss (eval): 13.3764
Iteration: 2
optimizer_post_lr: [0.00099]
prob_prior: 0.6065306597126334
start update likelihood model
Epoch: 0, loss (training): 10.2516, loss (eval): 10.335
Epoch: 1, loss (training): 10.2055, loss (eval): 10.5047
Epoch: 2, loss (training): 10.2473, loss (eval): 10.3062
Epoch: 3, loss (training): 10.2483, loss (eval): 10.3813
Epoch: 4, loss (training): 10.1486, loss (eval): 10.2931
Epoch: 5, loss (training): 10.1573, loss (eval): 10.2938
Epoch: 6, loss (training): 10.2358, loss (eval): 10.4252
Epoch: 7, loss (training): 10.151, loss (eval): 10.4417
Epoch: 8, loss (training): 10.135, loss (eval): 10.4493
Epoch: 9, loss (training): 10.0936, loss (eval): 10.2601
Epoch: 10, loss (training): 10.1624, loss (eval): 10.3789
Epoch: 11, loss (training): 10.1422, loss (eval): 10.4798
Epoch: 12, loss (training): 10.1017, loss (eval): 10.3184
Epoch: 13, loss (training): 10.0931, loss (eval): 10.4097
Epoch: 14, loss (training): 10.1344, loss (eval): 10.4912
Epoch: 15, loss (training): 10.1541, loss (eval): 10.3231
Epoch: 16, loss (training): 10.0882, loss (eval): 10.387
Epoch: 17, loss (training): 10.1291, loss (eval): 10.2471
Epoch: 18, loss (training): 10.1127, loss (eval): 10.3879
Epoch: 19, loss (training): 10.0573, loss (eval): 10.2834
Epoch: 20, loss (training): 10.0792, loss (eval): 10.4429
Epoch: 21, loss (training): 10.076, loss (eval): 10.3457
Epoch: 22, loss (training): 10.0749, loss (eval): 10.2722
Epoch: 23, loss (training): 10.0413, loss (eval): 10.2784
Epoch: 24, loss (training): 10.0393, loss (eval): 10.1934
start update posterior model
Epoch: 0, loss (training): 13.9072, loss (eval): 13.9338
Epoch: 1, loss (training): 13.8964, loss (eval): 13.9073
Epoch: 2, loss (training): 13.9016, loss (eval): 13.8781
Epoch: 3, loss (training): 13.8946, loss (eval): 13.8782
Epoch: 4, loss (training): 13.8897, loss (eval): 13.9078
Epoch: 5, loss (training): 13.9024, loss (eval): 14.0295
Epoch: 6, loss (training): 13.8962, loss (eval): 13.8707
Epoch: 7, loss (training): 13.889, loss (eval): 13.8823
Epoch: 8, loss (training): 13.8927, loss (eval): 13.8786
Epoch: 9, loss (training): 13.8874, loss (eval): 13.878
Epoch: 10, loss (training): 13.9031, loss (eval): 13.8764
Epoch: 11, loss (training): 13.9077, loss (eval): 13.9175
Epoch: 12, loss (training): 13.8898, loss (eval): 13.8793
Epoch: 13, loss (training): 13.8877, loss (eval): 13.8732
Epoch: 14, loss (training): 13.8884, loss (eval): 13.8753
Epoch: 15, loss (training): 13.8837, loss (eval): 13.8908
Epoch: 16, loss (training): 13.8926, loss (eval): 13.8756
Epoch: 17, loss (training): 13.888, loss (eval): 13.8854
Epoch: 18, loss (training): 13.8862, loss (eval): 13.9007
Epoch: 19, loss (training): 13.887, loss (eval): 13.8801
Epoch: 20, loss (training): 13.8929, loss (eval): 13.889
Epoch: 21, loss (training): 13.8922, loss (eval): 13.9295
Epoch: 22, loss (training): 13.8874, loss (eval): 13.8779
Epoch: 23, loss (training): 13.8889, loss (eval): 13.9028
Epoch: 24, loss (training): 13.8929, loss (eval): 13.9189
Iteration: 3
optimizer_post_lr: [0.0009801]
prob_prior: 0.36787944117144233
start update likelihood model
Epoch: 0, loss (training): 10.2556, loss (eval): 10.0388
Epoch: 1, loss (training): 10.3311, loss (eval): 10.0432
Epoch: 2, loss (training): 10.2171, loss (eval): 10.0591
Epoch: 3, loss (training): 10.1832, loss (eval): 10.0102
Epoch: 4, loss (training): 10.1576, loss (eval): 10.0856
Epoch: 5, loss (training): 10.1533, loss (eval): 9.9836
Epoch: 6, loss (training): 10.1683, loss (eval): 10.0195
Epoch: 7, loss (training): 10.1351, loss (eval): 9.9801
Epoch: 8, loss (training): 10.1282, loss (eval): 10.0114
Epoch: 9, loss (training): 10.1426, loss (eval): 10.0266
Epoch: 10, loss (training): 10.1711, loss (eval): 10.0172
Epoch: 11, loss (training): 10.1346, loss (eval): 10.0768
Epoch: 12, loss (training): 10.1292, loss (eval): 10.0743
Epoch: 13, loss (training): 10.1401, loss (eval): 10.0197
Epoch: 14, loss (training): 10.1348, loss (eval): 9.9783
Epoch: 15, loss (training): 10.1093, loss (eval): 10.0433
Epoch: 16, loss (training): 10.0934, loss (eval): 10.0028
Epoch: 17, loss (training): 10.1297, loss (eval): 10.1628
Epoch: 18, loss (training): 10.0865, loss (eval): 9.9904
Epoch: 19, loss (training): 10.1153, loss (eval): 10.0027
Epoch: 20, loss (training): 10.138, loss (eval): 10.064
Epoch: 21, loss (training): 10.134, loss (eval): 10.0859
Epoch: 22, loss (training): 10.0883, loss (eval): 10.0708
Epoch: 23, loss (training): 10.1147, loss (eval): 10.0718
Epoch: 24, loss (training): 10.1027, loss (eval): 10.0242
start update posterior model
Epoch: 0, loss (training): 13.0972, loss (eval): 13.1202
Epoch: 1, loss (training): 13.1005, loss (eval): 13.0955
Epoch: 2, loss (training): 13.0963, loss (eval): 13.094
Epoch: 3, loss (training): 13.1017, loss (eval): 13.0929
Epoch: 4, loss (training): 13.097, loss (eval): 13.0876
Epoch: 5, loss (training): 13.1024, loss (eval): 13.1617
Epoch: 6, loss (training): 13.1027, loss (eval): 13.1046
Epoch: 7, loss (training): 13.0959, loss (eval): 13.0909
Epoch: 8, loss (training): 13.0998, loss (eval): 13.0871
Epoch: 9, loss (training): 13.097, loss (eval): 13.0977
Epoch: 10, loss (training): 13.0938, loss (eval): 13.107
Epoch: 11, loss (training): 13.0968, loss (eval): 13.0929
Epoch: 12, loss (training): 13.0987, loss (eval): 13.0821
Epoch: 13, loss (training): 13.0966, loss (eval): 13.0936
Epoch: 14, loss (training): 13.0983, loss (eval): 13.0832
Epoch: 15, loss (training): 13.0998, loss (eval): 13.1046
Epoch: 16, loss (training): 13.0985, loss (eval): 13.1048
Epoch: 17, loss (training): 13.0989, loss (eval): 13.1037
Epoch: 18, loss (training): 13.0936, loss (eval): 13.0876
Epoch: 19, loss (training): 13.0986, loss (eval): 13.1059
Epoch: 20, loss (training): 13.0965, loss (eval): 13.0949
Epoch: 21, loss (training): 13.0986, loss (eval): 13.1188
Epoch: 22, loss (training): 13.098, loss (eval): 13.1125
Epoch: 23, loss (training): 13.1067, loss (eval): 13.1039
Epoch: 24, loss (training): 13.0976, loss (eval): 13.1113
Iteration: 4
optimizer_post_lr: [0.000970299]
prob_prior: 0.22313016014842982
start update likelihood model
Epoch: 0, loss (training): 10.1798, loss (eval): 10.111
Epoch: 1, loss (training): 10.1436, loss (eval): 10.1447
Epoch: 2, loss (training): 10.1022, loss (eval): 10.2182
Epoch: 3, loss (training): 10.0685, loss (eval): 10.1183
Epoch: 4, loss (training): 10.0763, loss (eval): 10.1316
Epoch: 5, loss (training): 10.0486, loss (eval): 10.136
Epoch: 6, loss (training): 10.0838, loss (eval): 10.2029
Epoch: 7, loss (training): 10.0369, loss (eval): 10.1136
Epoch: 8, loss (training): 10.0729, loss (eval): 10.1515
Epoch: 9, loss (training): 10.0558, loss (eval): 10.0745
Epoch: 10, loss (training): 10.0146, loss (eval): 10.1349
Epoch: 11, loss (training): 10.0568, loss (eval): 10.165
Epoch: 12, loss (training): 10.0262, loss (eval): 10.1413
Epoch: 13, loss (training): 10.0232, loss (eval): 10.1648
Epoch: 14, loss (training): 10.0334, loss (eval): 10.245
Epoch: 15, loss (training): 10.0109, loss (eval): 10.121
Epoch: 16, loss (training): 10.0367, loss (eval): 10.181
Epoch: 17, loss (training): 10.0259, loss (eval): 10.2111
Epoch: 18, loss (training): 10.0248, loss (eval): 10.1564
Epoch: 19, loss (training): 10.0291, loss (eval): 10.1505
Epoch: 20, loss (training): 9.9935, loss (eval): 10.1244
Epoch: 21, loss (training): 10.0037, loss (eval): 10.1636
Epoch: 22, loss (training): 9.9716, loss (eval): 10.1391
Epoch: 23, loss (training): 10.0072, loss (eval): 10.1409
Epoch: 24, loss (training): 10.0016, loss (eval): 10.1969
start update posterior model
Epoch: 0, loss (training): 13.3526, loss (eval): 13.3474
Epoch: 1, loss (training): 13.3573, loss (eval): 13.3556
Epoch: 2, loss (training): 13.3508, loss (eval): 13.3567
Epoch: 3, loss (training): 13.3504, loss (eval): 13.3545
Epoch: 4, loss (training): 13.3531, loss (eval): 13.3476
Epoch: 5, loss (training): 13.3527, loss (eval): 13.343
Epoch: 6, loss (training): 13.3573, loss (eval): 13.3493
Epoch: 7, loss (training): 13.3552, loss (eval): 13.3438
Epoch: 8, loss (training): 13.3493, loss (eval): 13.3397
Epoch: 9, loss (training): 13.3516, loss (eval): 13.3496
Epoch: 10, loss (training): 13.3518, loss (eval): 13.3449
Epoch: 11, loss (training): 13.3549, loss (eval): 13.3731
Epoch: 12, loss (training): 13.3559, loss (eval): 13.3416
Epoch: 13, loss (training): 13.3572, loss (eval): 13.3519
Epoch: 14, loss (training): 13.3493, loss (eval): 13.3377
Epoch: 15, loss (training): 13.3557, loss (eval): 13.3378
Epoch: 16, loss (training): 13.3571, loss (eval): 13.3437
Epoch: 17, loss (training): 13.3475, loss (eval): 13.3468
Epoch: 18, loss (training): 13.3549, loss (eval): 13.345
Epoch: 19, loss (training): 13.353, loss (eval): 13.3498
Epoch: 20, loss (training): 13.3568, loss (eval): 13.347
Epoch: 21, loss (training): 13.3491, loss (eval): 13.3522
Epoch: 22, loss (training): 13.3531, loss (eval): 13.3538
Epoch: 23, loss (training): 13.3526, loss (eval): 13.35
Epoch: 24, loss (training): 13.3523, loss (eval): 13.3463
Iteration: 5
optimizer_post_lr: [0.0009605960099999999]
prob_prior: 0.1353352832366127
start update likelihood model
Epoch: 0, loss (training): 10.1992, loss (eval): 10.2348
Epoch: 1, loss (training): 10.0781, loss (eval): 10.1347
Epoch: 2, loss (training): 10.0697, loss (eval): 10.258
Epoch: 3, loss (training): 10.0548, loss (eval): 10.1773
Epoch: 4, loss (training): 10.0503, loss (eval): 10.2397
Epoch: 5, loss (training): 10.0596, loss (eval): 10.1608
Epoch: 6, loss (training): 10.0512, loss (eval): 10.3013
Epoch: 7, loss (training): 10.0765, loss (eval): 10.1624
Epoch: 8, loss (training): 10.0464, loss (eval): 10.1782
Epoch: 9, loss (training): 10.0224, loss (eval): 10.1611
Epoch: 10, loss (training): 10.0269, loss (eval): 10.2041
Epoch: 11, loss (training): 10.041, loss (eval): 10.1906
Epoch: 12, loss (training): 10.0364, loss (eval): 10.1503
Epoch: 13, loss (training): 10.0025, loss (eval): 10.2487
Epoch: 14, loss (training): 9.9888, loss (eval): 10.1682
Epoch: 15, loss (training): 9.9954, loss (eval): 10.2283
Epoch: 16, loss (training): 10.008, loss (eval): 10.1595
Epoch: 17, loss (training): 10.0187, loss (eval): 10.2983
Epoch: 18, loss (training): 9.996, loss (eval): 10.2057
Epoch: 19, loss (training): 10.0102, loss (eval): 10.2589
Epoch: 20, loss (training): 9.9954, loss (eval): 10.2206
Early-stopping. Training converged after 21 epochs.
start update posterior model
Epoch: 0, loss (training): 13.5742, loss (eval): 13.8008
Epoch: 1, loss (training): 13.5633, loss (eval): 13.5669
Epoch: 2, loss (training): 13.5656, loss (eval): 13.5561
Epoch: 3, loss (training): 13.5602, loss (eval): 13.5578
Epoch: 4, loss (training): 13.5604, loss (eval): 13.5623
Epoch: 5, loss (training): 13.5627, loss (eval): 13.5531
Epoch: 6, loss (training): 13.5628, loss (eval): 13.561
Epoch: 7, loss (training): 13.5654, loss (eval): 13.5552
Epoch: 8, loss (training): 13.5617, loss (eval): 13.557
Epoch: 9, loss (training): 13.5616, loss (eval): 13.5541
Epoch: 10, loss (training): 13.5656, loss (eval): 13.5571
Epoch: 11, loss (training): 13.5661, loss (eval): 13.5578
Epoch: 12, loss (training): 13.5638, loss (eval): 13.5791
Epoch: 13, loss (training): 13.5626, loss (eval): 13.5543
Epoch: 14, loss (training): 13.5614, loss (eval): 13.5555
Epoch: 15, loss (training): 13.5644, loss (eval): 13.5548
Epoch: 16, loss (training): 13.5634, loss (eval): 13.5781
Epoch: 17, loss (training): 13.5608, loss (eval): 13.5601
Epoch: 18, loss (training): 13.5616, loss (eval): 13.5616
Epoch: 19, loss (training): 13.5608, loss (eval): 13.5726
Epoch: 20, loss (training): 13.5661, loss (eval): 13.5607
Epoch: 21, loss (training): 13.563, loss (eval): 13.5877
Epoch: 22, loss (training): 13.5627, loss (eval): 13.5504
Epoch: 23, loss (training): 13.5593, loss (eval): 13.5531
Epoch: 24, loss (training): 13.5608, loss (eval): 13.5569
Iteration: 6
optimizer_post_lr: [0.0009509900498999999]
prob_prior: 0.0820849986238988
start update likelihood model
Epoch: 0, loss (training): 10.2134, loss (eval): 10.1866
Epoch: 1, loss (training): 10.1394, loss (eval): 10.1039
Epoch: 2, loss (training): 10.0903, loss (eval): 10.1042
Epoch: 3, loss (training): 10.1224, loss (eval): 10.1078
Epoch: 4, loss (training): 10.1345, loss (eval): 10.1994
Epoch: 5, loss (training): 10.0946, loss (eval): 10.1394
Epoch: 6, loss (training): 10.0823, loss (eval): 10.13
Epoch: 7, loss (training): 10.0977, loss (eval): 10.0872
Epoch: 8, loss (training): 10.0751, loss (eval): 10.2105
Epoch: 9, loss (training): 10.0665, loss (eval): 10.1684
Epoch: 10, loss (training): 10.0986, loss (eval): 10.2076
Epoch: 11, loss (training): 10.0573, loss (eval): 10.1226
Epoch: 12, loss (training): 10.114, loss (eval): 10.0767
Epoch: 13, loss (training): 10.0752, loss (eval): 10.1558
Epoch: 14, loss (training): 10.0938, loss (eval): 10.3055
Epoch: 15, loss (training): 10.0428, loss (eval): 10.2902
Epoch: 16, loss (training): 10.0658, loss (eval): 10.1511
Epoch: 17, loss (training): 10.0486, loss (eval): 10.1573
Epoch: 18, loss (training): 10.0866, loss (eval): 10.2293
Epoch: 19, loss (training): 10.0513, loss (eval): 10.0754
Epoch: 20, loss (training): 10.0419, loss (eval): 10.2161
Epoch: 21, loss (training): 10.0605, loss (eval): 10.2812
Epoch: 22, loss (training): 10.0634, loss (eval): 10.2202
Epoch: 23, loss (training): 10.0302, loss (eval): 10.1682
Epoch: 24, loss (training): 10.0528, loss (eval): 10.143
start update posterior model
Epoch: 0, loss (training): 12.7712, loss (eval): 12.9294
Epoch: 1, loss (training): 12.7697, loss (eval): 12.7607
Epoch: 2, loss (training): 12.771, loss (eval): 12.7632
Epoch: 3, loss (training): 12.7717, loss (eval): 12.7636
Epoch: 4, loss (training): 12.7767, loss (eval): 12.7775
Epoch: 5, loss (training): 12.7725, loss (eval): 12.7605
Epoch: 6, loss (training): 12.7688, loss (eval): 12.7623
Epoch: 7, loss (training): 12.7709, loss (eval): 12.7705
Epoch: 8, loss (training): 12.7696, loss (eval): 12.758
Epoch: 9, loss (training): 12.7692, loss (eval): 12.7652
Epoch: 10, loss (training): 12.7726, loss (eval): 12.7879
Epoch: 11, loss (training): 12.7697, loss (eval): 12.7793
Epoch: 12, loss (training): 12.7695, loss (eval): 12.776
Epoch: 13, loss (training): 12.772, loss (eval): 12.8045
Epoch: 14, loss (training): 12.7677, loss (eval): 12.7684
Epoch: 15, loss (training): 12.7691, loss (eval): 12.7568
Epoch: 16, loss (training): 12.7656, loss (eval): 12.7638
Epoch: 17, loss (training): 12.7686, loss (eval): 12.7855
Epoch: 18, loss (training): 12.7679, loss (eval): 12.7735
Epoch: 19, loss (training): 12.7713, loss (eval): 12.7652
Epoch: 20, loss (training): 12.7661, loss (eval): 12.7566
Epoch: 21, loss (training): 12.768, loss (eval): 12.799
Epoch: 22, loss (training): 12.7658, loss (eval): 12.766
Epoch: 23, loss (training): 12.7701, loss (eval): 12.797
Epoch: 24, loss (training): 12.7694, loss (eval): 12.7635
Iteration: 7
optimizer_post_lr: [0.0009414801494009999]
prob_prior: 0.049787068367863944
start update likelihood model
Epoch: 0, loss (training): 10.1922, loss (eval): 10.2812
Epoch: 1, loss (training): 10.1257, loss (eval): 10.2022
Epoch: 2, loss (training): 10.1231, loss (eval): 10.2916
Epoch: 3, loss (training): 10.1228, loss (eval): 10.155
Epoch: 4, loss (training): 10.1204, loss (eval): 10.2806
Epoch: 5, loss (training): 10.0894, loss (eval): 10.201
Epoch: 6, loss (training): 10.1223, loss (eval): 10.1968
Epoch: 7, loss (training): 10.0863, loss (eval): 10.1773
Epoch: 8, loss (training): 10.097, loss (eval): 10.2161
Epoch: 9, loss (training): 10.0816, loss (eval): 10.2084
Epoch: 10, loss (training): 10.0873, loss (eval): 10.2676
Epoch: 11, loss (training): 10.0676, loss (eval): 10.2023
Epoch: 12, loss (training): 10.093, loss (eval): 10.2458
Epoch: 13, loss (training): 10.0839, loss (eval): 10.2368
Epoch: 14, loss (training): 10.0476, loss (eval): 10.2056
Epoch: 15, loss (training): 10.0534, loss (eval): 10.227
Epoch: 16, loss (training): 10.0629, loss (eval): 10.2972
Epoch: 17, loss (training): 10.0696, loss (eval): 10.3569
Epoch: 18, loss (training): 10.0528, loss (eval): 10.2173
Epoch: 19, loss (training): 10.045, loss (eval): 10.2027
Epoch: 20, loss (training): 10.0372, loss (eval): 10.2353
Epoch: 21, loss (training): 10.0473, loss (eval): 10.197
Epoch: 22, loss (training): 10.0208, loss (eval): 10.2462
Early-stopping. Training converged after 23 epochs.
start update posterior model
Epoch: 0, loss (training): 13.5186, loss (eval): 13.5536
Epoch: 1, loss (training): 13.52, loss (eval): 13.519
Epoch: 2, loss (training): 13.5256, loss (eval): 13.5125
Epoch: 3, loss (training): 13.5192, loss (eval): 13.5116
Epoch: 4, loss (training): 13.5173, loss (eval): 13.5155
Epoch: 5, loss (training): 13.522, loss (eval): 13.5409
Epoch: 6, loss (training): 13.5164, loss (eval): 13.5029
Epoch: 7, loss (training): 13.5164, loss (eval): 13.5155
Epoch: 8, loss (training): 13.5207, loss (eval): 13.5109
Epoch: 9, loss (training): 13.5196, loss (eval): 13.5289
Epoch: 10, loss (training): 13.5226, loss (eval): 13.545
Epoch: 11, loss (training): 13.5166, loss (eval): 13.5289
Epoch: 12, loss (training): 13.5171, loss (eval): 13.512
Epoch: 13, loss (training): 13.5195, loss (eval): 13.5105
Epoch: 14, loss (training): 13.5162, loss (eval): 13.5141
Epoch: 15, loss (training): 13.5196, loss (eval): 13.5241
Epoch: 16, loss (training): 13.5201, loss (eval): 13.5248
Epoch: 17, loss (training): 13.5187, loss (eval): 13.5473
Epoch: 18, loss (training): 13.5184, loss (eval): 13.5104
Epoch: 19, loss (training): 13.5154, loss (eval): 13.5169
Epoch: 20, loss (training): 13.5173, loss (eval): 13.5144
Epoch: 21, loss (training): 13.5189, loss (eval): 13.5128
Epoch: 22, loss (training): 13.5154, loss (eval): 13.5149
Epoch: 23, loss (training): 13.5199, loss (eval): 13.5185
Epoch: 24, loss (training): 13.5173, loss (eval): 13.5118
Iteration: 8
optimizer_post_lr: [0.0009320653479069899]
prob_prior: 0.0301973834223185
start update likelihood model
Epoch: 0, loss (training): 10.1653, loss (eval): 10.3254
Epoch: 1, loss (training): 10.1031, loss (eval): 10.313
Epoch: 2, loss (training): 10.0867, loss (eval): 10.3152
Epoch: 3, loss (training): 10.0783, loss (eval): 10.3498
Epoch: 4, loss (training): 10.0572, loss (eval): 10.284
Epoch: 5, loss (training): 10.0698, loss (eval): 10.268
Epoch: 6, loss (training): 10.0585, loss (eval): 10.3025
Epoch: 7, loss (training): 10.064, loss (eval): 10.433
Epoch: 8, loss (training): 10.0366, loss (eval): 10.2939
Epoch: 9, loss (training): 10.0558, loss (eval): 10.3561
Epoch: 10, loss (training): 10.0762, loss (eval): 10.3718
Epoch: 11, loss (training): 10.0258, loss (eval): 10.4413
Epoch: 12, loss (training): 10.0108, loss (eval): 10.3271
Epoch: 13, loss (training): 10.0553, loss (eval): 10.3045
Epoch: 14, loss (training): 9.9957, loss (eval): 10.4034
Epoch: 15, loss (training): 10.0344, loss (eval): 10.3793
Epoch: 16, loss (training): 10.0441, loss (eval): 10.3505
Epoch: 17, loss (training): 10.0401, loss (eval): 10.4126
Epoch: 18, loss (training): 10.0264, loss (eval): 10.328
Epoch: 19, loss (training): 10.0139, loss (eval): 10.318
Epoch: 20, loss (training): 9.9954, loss (eval): 10.3422
Epoch: 21, loss (training): 10.0294, loss (eval): 10.2573
Epoch: 22, loss (training): 10.0176, loss (eval): 10.3378
Epoch: 23, loss (training): 10.015, loss (eval): 10.2994
Epoch: 24, loss (training): 9.9723, loss (eval): 10.3509
start update posterior model
Epoch: 0, loss (training): 14.103, loss (eval): 14.1373
Epoch: 1, loss (training): 14.0977, loss (eval): 14.0976
Epoch: 2, loss (training): 14.1014, loss (eval): 14.0879
Epoch: 3, loss (training): 14.0988, loss (eval): 14.0919
Epoch: 4, loss (training): 14.1011, loss (eval): 14.0939
Epoch: 5, loss (training): 14.0986, loss (eval): 14.0933
Epoch: 6, loss (training): 14.1011, loss (eval): 14.0981
Epoch: 7, loss (training): 14.0972, loss (eval): 14.1038
Epoch: 8, loss (training): 14.1056, loss (eval): 14.1039
Epoch: 9, loss (training): 14.0991, loss (eval): 14.1148
Epoch: 10, loss (training): 14.1045, loss (eval): 14.1074
Epoch: 11, loss (training): 14.101, loss (eval): 14.0945
Epoch: 12, loss (training): 14.0979, loss (eval): 14.0828
Epoch: 13, loss (training): 14.1022, loss (eval): 14.1131
Epoch: 14, loss (training): 14.1005, loss (eval): 14.0913
Epoch: 15, loss (training): 14.1015, loss (eval): 14.0966
Epoch: 16, loss (training): 14.0986, loss (eval): 14.0963
Epoch: 17, loss (training): 14.1011, loss (eval): 14.0981
Epoch: 18, loss (training): 14.0969, loss (eval): 14.0973
Epoch: 19, loss (training): 14.0996, loss (eval): 14.0948
Epoch: 20, loss (training): 14.0995, loss (eval): 14.1083
Epoch: 21, loss (training): 14.1018, loss (eval): 14.1066
Epoch: 22, loss (training): 14.0995, loss (eval): 14.0935
Epoch: 23, loss (training): 14.0979, loss (eval): 14.096
Epoch: 24, loss (training): 14.1006, loss (eval): 14.092
Iteration: 9
optimizer_post_lr: [0.00092274469442792]
prob_prior: 0.01831563888873418
start update likelihood model
Epoch: 0, loss (training): 10.2036, loss (eval): 10.0878
Epoch: 1, loss (training): 10.1458, loss (eval): 10.0786
Epoch: 2, loss (training): 10.1341, loss (eval): 10.1464
Epoch: 3, loss (training): 10.1649, loss (eval): 10.0728
Epoch: 4, loss (training): 10.118, loss (eval): 10.1966
Epoch: 5, loss (training): 10.1149, loss (eval): 10.175
Epoch: 6, loss (training): 10.1106, loss (eval): 10.1225
Epoch: 7, loss (training): 10.1203, loss (eval): 10.2254
Epoch: 8, loss (training): 10.0897, loss (eval): 10.1378
Epoch: 9, loss (training): 10.1019, loss (eval): 10.12
Epoch: 10, loss (training): 10.1, loss (eval): 10.1927
Epoch: 11, loss (training): 10.1169, loss (eval): 10.2541
Epoch: 12, loss (training): 10.0823, loss (eval): 10.0665
Epoch: 13, loss (training): 10.0991, loss (eval): 10.1585
Epoch: 14, loss (training): 10.0801, loss (eval): 10.1016
Epoch: 15, loss (training): 10.0765, loss (eval): 10.0805
Epoch: 16, loss (training): 10.0753, loss (eval): 10.0841
Epoch: 17, loss (training): 10.0789, loss (eval): 10.0419
Epoch: 18, loss (training): 10.0759, loss (eval): 10.0768
Epoch: 19, loss (training): 10.0616, loss (eval): 10.101
Epoch: 20, loss (training): 10.0677, loss (eval): 10.1007
Epoch: 21, loss (training): 10.0575, loss (eval): 10.1153
Epoch: 22, loss (training): 10.0613, loss (eval): 10.1184
Epoch: 23, loss (training): 10.0713, loss (eval): 10.1777
Epoch: 24, loss (training): 10.0548, loss (eval): 10.126
start update posterior model
Epoch: 0, loss (training): 13.5778, loss (eval): 13.6411
Epoch: 1, loss (training): 13.5718, loss (eval): 13.568
Epoch: 2, loss (training): 13.5737, loss (eval): 13.5712
Epoch: 3, loss (training): 13.5728, loss (eval): 13.5671
Epoch: 4, loss (training): 13.5753, loss (eval): 13.5712
Epoch: 5, loss (training): 13.5735, loss (eval): 13.5674
Epoch: 6, loss (training): 13.5731, loss (eval): 13.5796
Epoch: 7, loss (training): 13.5724, loss (eval): 13.5745
Epoch: 8, loss (training): 13.5727, loss (eval): 13.5828
Epoch: 9, loss (training): 13.5717, loss (eval): 13.5684
Epoch: 10, loss (training): 13.5738, loss (eval): 13.5739
Epoch: 11, loss (training): 13.573, loss (eval): 13.5671
Epoch: 12, loss (training): 13.574, loss (eval): 13.5737
Epoch: 13, loss (training): 13.5731, loss (eval): 13.5749
Epoch: 14, loss (training): 13.5726, loss (eval): 13.5745
Epoch: 15, loss (training): 13.5739, loss (eval): 13.5643
Epoch: 16, loss (training): 13.5761, loss (eval): 13.5649
Epoch: 17, loss (training): 13.5703, loss (eval): 13.5704
Epoch: 18, loss (training): 13.5729, loss (eval): 13.5716
Epoch: 19, loss (training): 13.5719, loss (eval): 13.5631
Epoch: 20, loss (training): 13.5711, loss (eval): 13.5677
Epoch: 21, loss (training): 13.5752, loss (eval): 13.569
Epoch: 22, loss (training): 13.5721, loss (eval): 13.5961
Epoch: 23, loss (training): 13.5756, loss (eval): 13.5738
Epoch: 24, loss (training): 13.5693, loss (eval): 13.5653
Iteration: 10
optimizer_post_lr: [0.0009135172474836408]
prob_prior: 0.011108996538242306
start update likelihood model
Epoch: 0, loss (training): 10.1194, loss (eval): 10.2321
Epoch: 1, loss (training): 10.0375, loss (eval): 10.2401
Epoch: 2, loss (training): 10.038, loss (eval): 10.2407
Epoch: 3, loss (training): 10.038, loss (eval): 10.2665
Epoch: 4, loss (training): 10.0814, loss (eval): 10.2973
Epoch: 5, loss (training): 10.013, loss (eval): 10.2721
Epoch: 6, loss (training): 9.9973, loss (eval): 10.2091
Epoch: 7, loss (training): 9.9877, loss (eval): 10.2259
Epoch: 8, loss (training): 9.9954, loss (eval): 10.2939
Epoch: 9, loss (training): 9.9976, loss (eval): 10.269
Epoch: 10, loss (training): 10.0126, loss (eval): 10.3433
Epoch: 11, loss (training): 9.9861, loss (eval): 10.3215
Epoch: 12, loss (training): 9.969, loss (eval): 10.3115
Epoch: 13, loss (training): 9.9721, loss (eval): 10.3027
Epoch: 14, loss (training): 9.9785, loss (eval): 10.343
Epoch: 15, loss (training): 9.9848, loss (eval): 10.2882
Epoch: 16, loss (training): 9.9938, loss (eval): 10.3344
Epoch: 17, loss (training): 9.9558, loss (eval): 10.3356
Epoch: 18, loss (training): 9.9631, loss (eval): 10.2906
Epoch: 19, loss (training): 9.985, loss (eval): 10.2461
Epoch: 20, loss (training): 9.9727, loss (eval): 10.2593
Epoch: 21, loss (training): 9.9631, loss (eval): 10.2889
Epoch: 22, loss (training): 9.936, loss (eval): 10.2703
Epoch: 23, loss (training): 9.9534, loss (eval): 10.3449
Epoch: 24, loss (training): 9.9341, loss (eval): 10.3143
start update posterior model
Epoch: 0, loss (training): 13.6229, loss (eval): 13.6957
Epoch: 1, loss (training): 13.6145, loss (eval): 13.6133
Epoch: 2, loss (training): 13.6181, loss (eval): 13.6159
Epoch: 3, loss (training): 13.6191, loss (eval): 13.6129
Epoch: 4, loss (training): 13.6188, loss (eval): 13.6141
Epoch: 5, loss (training): 13.6158, loss (eval): 13.6156
Epoch: 6, loss (training): 13.6176, loss (eval): 13.6179
Epoch: 7, loss (training): 13.616, loss (eval): 13.6147
Epoch: 8, loss (training): 13.6155, loss (eval): 13.6182
Epoch: 9, loss (training): 13.6152, loss (eval): 13.6125
Epoch: 10, loss (training): 13.618, loss (eval): 13.6311
Epoch: 11, loss (training): 13.6162, loss (eval): 13.6163
Epoch: 12, loss (training): 13.6172, loss (eval): 13.6246
Epoch: 13, loss (training): 13.6188, loss (eval): 13.6266
Epoch: 14, loss (training): 13.6136, loss (eval): 13.6179
Epoch: 15, loss (training): 13.6158, loss (eval): 13.6139
Epoch: 16, loss (training): 13.6145, loss (eval): 13.6241
Epoch: 17, loss (training): 13.6161, loss (eval): 13.6115
Epoch: 18, loss (training): 13.6154, loss (eval): 13.6386
Epoch: 19, loss (training): 13.6161, loss (eval): 13.6172
Epoch: 20, loss (training): 13.6167, loss (eval): 13.6079
Epoch: 21, loss (training): 13.6212, loss (eval): 13.6312
Epoch: 22, loss (training): 13.6139, loss (eval): 13.6121
Epoch: 23, loss (training): 13.6194, loss (eval): 13.6106
Epoch: 24, loss (training): 13.6162, loss (eval): 13.6211

Runtime:964.25
0
1
2
3
4
5
6
7
8
9
