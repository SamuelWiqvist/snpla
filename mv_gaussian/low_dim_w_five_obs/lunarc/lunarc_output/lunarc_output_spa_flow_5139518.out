Input args:
Dim: 2
seed: 2
seed_data: 10
/home/samwiq/spa/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/spa/seq-posterior-approx-w-nf-dev
[1.0, 0.4965853037914095, 0.2465969639416065, 0.12245642825298195, 0.06081006262521797, 0.0301973834223185, 0.014995576820477717, 0.007446583070924344, 0.003697863716482932, 0.0018363047770289071]
start full training
Iteration: 1
optimizer_post_lr: [0.001]
prob_prior: 1.0
start update likelihood model
Epoch: 0, loss (training): 26.858, loss (eval): 57.0604
Epoch: 1, loss (training): 20.3497, loss (eval): 22.3407
Epoch: 2, loss (training): 18.0086, loss (eval): 18.8113
Epoch: 3, loss (training): 16.6593, loss (eval): 17.2665
Epoch: 4, loss (training): 15.5837, loss (eval): 16.0882
Epoch: 5, loss (training): 14.5243, loss (eval): 15.0615
Epoch: 6, loss (training): 13.563, loss (eval): 14.0528
Epoch: 7, loss (training): 12.8108, loss (eval): 13.3823
Epoch: 8, loss (training): 12.0153, loss (eval): 12.5017
Epoch: 9, loss (training): 11.3866, loss (eval): 11.8427
Epoch: 10, loss (training): 11.1168, loss (eval): 11.6598
Epoch: 11, loss (training): 10.8427, loss (eval): 11.0178
Epoch: 12, loss (training): 10.7305, loss (eval): 10.8835
Epoch: 13, loss (training): 10.6872, loss (eval): 11.255
Epoch: 14, loss (training): 10.4869, loss (eval): 10.6652
Epoch: 15, loss (training): 10.5156, loss (eval): 10.5831
Epoch: 16, loss (training): 10.5059, loss (eval): 10.6995
Epoch: 17, loss (training): 10.3086, loss (eval): 10.6455
Epoch: 18, loss (training): 10.2971, loss (eval): 10.3338
Epoch: 19, loss (training): 10.257, loss (eval): 10.4893
Epoch: 20, loss (training): 10.2787, loss (eval): 10.3025
Epoch: 21, loss (training): 10.22, loss (eval): 10.4241
Epoch: 22, loss (training): 10.2756, loss (eval): 10.5179
Epoch: 23, loss (training): 10.1933, loss (eval): 10.2954
Epoch: 24, loss (training): 10.1791, loss (eval): 10.2981
Epoch: 25, loss (training): 10.2218, loss (eval): 10.4876
Epoch: 26, loss (training): 10.1866, loss (eval): 10.4091
Epoch: 27, loss (training): 10.1724, loss (eval): 10.549
Epoch: 28, loss (training): 10.1538, loss (eval): 10.2435
Epoch: 29, loss (training): 10.1342, loss (eval): 10.237
Epoch: 30, loss (training): 10.1702, loss (eval): 10.6966
Epoch: 31, loss (training): 10.1346, loss (eval): 10.271
Epoch: 32, loss (training): 10.135, loss (eval): 10.1772
Epoch: 33, loss (training): 10.1437, loss (eval): 10.3134
Epoch: 34, loss (training): 10.1919, loss (eval): 10.2777
Epoch: 35, loss (training): 10.1921, loss (eval): 10.5386
Epoch: 36, loss (training): 10.088, loss (eval): 10.3167
Epoch: 37, loss (training): 10.122, loss (eval): 10.2363
Epoch: 38, loss (training): 10.1415, loss (eval): 10.2802
Epoch: 39, loss (training): 10.1429, loss (eval): 10.3938
Epoch: 40, loss (training): 10.094, loss (eval): 10.1912
Epoch: 41, loss (training): 10.1176, loss (eval): 10.1878
Epoch: 42, loss (training): 10.1067, loss (eval): 10.1765
Epoch: 43, loss (training): 10.1067, loss (eval): 10.265
Epoch: 44, loss (training): 10.1011, loss (eval): 10.3115
Epoch: 45, loss (training): 10.0939, loss (eval): 10.1374
Epoch: 46, loss (training): 10.0539, loss (eval): 10.1588
Epoch: 47, loss (training): 10.0798, loss (eval): 10.2185
Epoch: 48, loss (training): 10.12, loss (eval): 10.375
Epoch: 49, loss (training): 10.0726, loss (eval): 10.301
Epoch: 50, loss (training): 10.0539, loss (eval): 10.3827
Epoch: 51, loss (training): 10.0743, loss (eval): 10.13
Epoch: 52, loss (training): 10.0173, loss (eval): 10.1893
Epoch: 53, loss (training): 10.0306, loss (eval): 10.3324
Epoch: 54, loss (training): 10.0066, loss (eval): 10.1669
Epoch: 55, loss (training): 10.0192, loss (eval): 10.2485
Epoch: 56, loss (training): 10.0821, loss (eval): 10.3596
Epoch: 57, loss (training): 10.0333, loss (eval): 10.3553
Epoch: 58, loss (training): 10.1061, loss (eval): 10.1758
Epoch: 59, loss (training): 10.0332, loss (eval): 10.4267
Epoch: 60, loss (training): 10.008, loss (eval): 10.2674
Epoch: 61, loss (training): 9.9949, loss (eval): 10.2339
Epoch: 62, loss (training): 10.0008, loss (eval): 10.2667
Epoch: 63, loss (training): 10.0051, loss (eval): 10.1527
Epoch: 64, loss (training): 10.0838, loss (eval): 10.1489
Epoch: 65, loss (training): 10.0484, loss (eval): 10.2449
Epoch: 66, loss (training): 9.9823, loss (eval): 10.1613
Epoch: 67, loss (training): 9.9798, loss (eval): 10.1151
Epoch: 68, loss (training): 9.9882, loss (eval): 10.125
Epoch: 69, loss (training): 10.0134, loss (eval): 10.3074
Epoch: 70, loss (training): 9.9547, loss (eval): 10.122
Epoch: 71, loss (training): 9.9831, loss (eval): 10.1489
Epoch: 72, loss (training): 9.9821, loss (eval): 10.2414
Epoch: 73, loss (training): 9.9336, loss (eval): 10.1603
Epoch: 74, loss (training): 9.9904, loss (eval): 10.2084
start update posterior model from prior pred - hot start
Epoch: 0, loss (training): 3.6323, loss (eval): 7.0133
Epoch: 1, loss (training): 2.1864, loss (eval): 2.7921
Epoch: 2, loss (training): 1.3807, loss (eval): 1.6953
Epoch: 3, loss (training): 1.0417, loss (eval): 1.1109
Epoch: 4, loss (training): 0.8676, loss (eval): 0.8416
Epoch: 5, loss (training): 0.9336, loss (eval): 0.6849
Epoch: 6, loss (training): 0.7896, loss (eval): 1.2827
Epoch: 7, loss (training): 0.6761, loss (eval): 0.759
Epoch: 8, loss (training): 0.6662, loss (eval): 1.1491
Epoch: 9, loss (training): 0.5681, loss (eval): 0.5825
start update posterior model
Epoch: 0, loss (training): 10.9369, loss (eval): 11.2525
Epoch: 1, loss (training): 10.9267, loss (eval): 10.9098
Epoch: 2, loss (training): 10.9237, loss (eval): 10.9183
Epoch: 3, loss (training): 10.9421, loss (eval): 10.9185
Epoch: 4, loss (training): 10.9188, loss (eval): 10.9628
Epoch: 5, loss (training): 10.9365, loss (eval): 10.9183
Epoch: 6, loss (training): 10.937, loss (eval): 10.9132
Epoch: 7, loss (training): 10.9225, loss (eval): 10.9152
Epoch: 8, loss (training): 10.9166, loss (eval): 10.9384
Epoch: 9, loss (training): 10.9241, loss (eval): 10.9062
Epoch: 10, loss (training): 10.9216, loss (eval): 10.9184
Epoch: 11, loss (training): 10.9196, loss (eval): 10.9273
Epoch: 12, loss (training): 10.9292, loss (eval): 10.9102
Epoch: 13, loss (training): 10.9169, loss (eval): 10.9179
Epoch: 14, loss (training): 10.9298, loss (eval): 10.9203
Epoch: 15, loss (training): 10.9163, loss (eval): 10.935
Epoch: 16, loss (training): 10.9242, loss (eval): 10.9294
Epoch: 17, loss (training): 10.9222, loss (eval): 10.9385
Epoch: 18, loss (training): 10.9205, loss (eval): 10.9058
Epoch: 19, loss (training): 10.9148, loss (eval): 10.9175
Epoch: 20, loss (training): 10.9199, loss (eval): 10.9228
Epoch: 21, loss (training): 10.9192, loss (eval): 10.9038
Epoch: 22, loss (training): 10.9171, loss (eval): 10.9279
Epoch: 23, loss (training): 10.9179, loss (eval): 10.9195
Epoch: 24, loss (training): 10.9135, loss (eval): 10.9056
Epoch: 25, loss (training): 10.9144, loss (eval): 10.9419
Epoch: 26, loss (training): 10.921, loss (eval): 10.9031
Epoch: 27, loss (training): 10.9173, loss (eval): 10.9061
Epoch: 28, loss (training): 10.9197, loss (eval): 10.9075
Epoch: 29, loss (training): 10.9124, loss (eval): 10.9162
Epoch: 30, loss (training): 10.9148, loss (eval): 10.9001
Epoch: 31, loss (training): 10.9177, loss (eval): 10.9461
Epoch: 32, loss (training): 10.9127, loss (eval): 10.9288
Epoch: 33, loss (training): 10.9163, loss (eval): 10.9023
Epoch: 34, loss (training): 10.9145, loss (eval): 10.9294
Epoch: 35, loss (training): 10.9157, loss (eval): 10.9112
Epoch: 36, loss (training): 10.912, loss (eval): 10.9011
Epoch: 37, loss (training): 10.9147, loss (eval): 10.929
Epoch: 38, loss (training): 10.9154, loss (eval): 10.916
Epoch: 39, loss (training): 10.9161, loss (eval): 10.9091
Epoch: 40, loss (training): 10.919, loss (eval): 10.9147
Epoch: 41, loss (training): 10.9124, loss (eval): 10.9179
Epoch: 42, loss (training): 10.9129, loss (eval): 10.9203
Epoch: 43, loss (training): 10.9115, loss (eval): 10.9035
Epoch: 44, loss (training): 10.9125, loss (eval): 10.9216
Epoch: 45, loss (training): 10.9136, loss (eval): 10.9163
Epoch: 46, loss (training): 10.9139, loss (eval): 10.8989
Epoch: 47, loss (training): 10.9135, loss (eval): 10.9163
Epoch: 48, loss (training): 10.9134, loss (eval): 10.9108
Epoch: 49, loss (training): 10.9144, loss (eval): 10.9353
Epoch: 50, loss (training): 10.9124, loss (eval): 10.9199
Epoch: 51, loss (training): 10.9131, loss (eval): 10.9159
Epoch: 52, loss (training): 10.9177, loss (eval): 10.9173
Epoch: 53, loss (training): 10.9116, loss (eval): 10.9127
Epoch: 54, loss (training): 10.9144, loss (eval): 10.9409
Epoch: 55, loss (training): 10.9088, loss (eval): 10.912
Epoch: 56, loss (training): 10.9134, loss (eval): 10.9009
Epoch: 57, loss (training): 10.9135, loss (eval): 10.9173
Epoch: 58, loss (training): 10.913, loss (eval): 10.9082
Epoch: 59, loss (training): 10.9093, loss (eval): 10.9069
Epoch: 60, loss (training): 10.9102, loss (eval): 10.9144
Epoch: 61, loss (training): 10.9149, loss (eval): 10.8994
Epoch: 62, loss (training): 10.9128, loss (eval): 10.9168
Epoch: 63, loss (training): 10.9102, loss (eval): 10.9442
Epoch: 64, loss (training): 10.9097, loss (eval): 10.9081
Epoch: 65, loss (training): 10.9065, loss (eval): 10.9175
Early-stopping. Training converged after 66 epochs.
Iteration: 2
optimizer_post_lr: [0.00099]
prob_prior: 0.4965853037914095
start update likelihood model
Epoch: 0, loss (training): 10.3222, loss (eval): 10.2908
Epoch: 1, loss (training): 10.2297, loss (eval): 10.3543
Epoch: 2, loss (training): 10.2317, loss (eval): 10.233
Epoch: 3, loss (training): 10.2021, loss (eval): 10.2329
Epoch: 4, loss (training): 10.1766, loss (eval): 10.2933
Epoch: 5, loss (training): 10.1599, loss (eval): 10.1349
Epoch: 6, loss (training): 10.1583, loss (eval): 10.172
Epoch: 7, loss (training): 10.1327, loss (eval): 10.2578
Epoch: 8, loss (training): 10.141, loss (eval): 10.24
Epoch: 9, loss (training): 10.1464, loss (eval): 10.18
Epoch: 10, loss (training): 10.191, loss (eval): 10.2189
Epoch: 11, loss (training): 10.1558, loss (eval): 10.2508
Epoch: 12, loss (training): 10.1237, loss (eval): 10.3155
Epoch: 13, loss (training): 10.1306, loss (eval): 10.2914
Epoch: 14, loss (training): 10.1277, loss (eval): 10.1942
Epoch: 15, loss (training): 10.1041, loss (eval): 10.1449
Epoch: 16, loss (training): 10.1228, loss (eval): 10.1635
Epoch: 17, loss (training): 10.1003, loss (eval): 10.2099
Epoch: 18, loss (training): 10.0591, loss (eval): 10.1585
Epoch: 19, loss (training): 10.0701, loss (eval): 10.2038
Epoch: 20, loss (training): 10.0877, loss (eval): 10.2595
Epoch: 21, loss (training): 10.0842, loss (eval): 10.2482
Epoch: 22, loss (training): 10.1179, loss (eval): 10.168
Epoch: 23, loss (training): 10.078, loss (eval): 10.1723
Epoch: 24, loss (training): 10.0838, loss (eval): 10.3488
Early-stopping. Training converged after 25 epochs.
start update posterior model
Epoch: 0, loss (training): 11.0553, loss (eval): 11.0789
Epoch: 1, loss (training): 11.0527, loss (eval): 11.0505
Epoch: 2, loss (training): 11.0568, loss (eval): 11.0515
Epoch: 3, loss (training): 11.0528, loss (eval): 11.0554
Epoch: 4, loss (training): 11.0525, loss (eval): 11.0896
Epoch: 5, loss (training): 11.0556, loss (eval): 11.0427
Epoch: 6, loss (training): 11.0506, loss (eval): 11.0488
Epoch: 7, loss (training): 11.056, loss (eval): 11.0508
Epoch: 8, loss (training): 11.0531, loss (eval): 11.0496
Epoch: 9, loss (training): 11.0508, loss (eval): 11.0727
Epoch: 10, loss (training): 11.0524, loss (eval): 11.0772
Epoch: 11, loss (training): 11.0529, loss (eval): 11.0439
Epoch: 12, loss (training): 11.0542, loss (eval): 11.0513
Epoch: 13, loss (training): 11.0499, loss (eval): 11.042
Epoch: 14, loss (training): 11.0545, loss (eval): 11.0475
Epoch: 15, loss (training): 11.0543, loss (eval): 11.0494
Epoch: 16, loss (training): 11.0528, loss (eval): 11.0539
Epoch: 17, loss (training): 11.0527, loss (eval): 11.0484
Epoch: 18, loss (training): 11.0477, loss (eval): 11.0481
Epoch: 19, loss (training): 11.053, loss (eval): 11.0716
Epoch: 20, loss (training): 11.0555, loss (eval): 11.0439
Epoch: 21, loss (training): 11.0556, loss (eval): 11.077
Epoch: 22, loss (training): 11.0502, loss (eval): 11.0609
Epoch: 23, loss (training): 11.0514, loss (eval): 11.0486
Epoch: 24, loss (training): 11.0517, loss (eval): 11.0491
Epoch: 25, loss (training): 11.0517, loss (eval): 11.074
Epoch: 26, loss (training): 11.0515, loss (eval): 11.0436
Epoch: 27, loss (training): 11.0523, loss (eval): 11.0617
Epoch: 28, loss (training): 11.0504, loss (eval): 11.0517
Epoch: 29, loss (training): 11.0529, loss (eval): 11.0571
Epoch: 30, loss (training): 11.0525, loss (eval): 11.0704
Epoch: 31, loss (training): 11.0512, loss (eval): 11.044
Epoch: 32, loss (training): 11.0525, loss (eval): 11.047
Early-stopping. Training converged after 33 epochs.
Iteration: 3
optimizer_post_lr: [0.0009801]
prob_prior: 0.2465969639416065
start update likelihood model
Epoch: 0, loss (training): 10.2954, loss (eval): 10.0439
Epoch: 1, loss (training): 10.1082, loss (eval): 10.0825
Epoch: 2, loss (training): 10.0668, loss (eval): 10.0444
Epoch: 3, loss (training): 10.064, loss (eval): 10.0739
Epoch: 4, loss (training): 10.041, loss (eval): 10.074
Epoch: 5, loss (training): 10.0262, loss (eval): 10.0342
Epoch: 6, loss (training): 10.0072, loss (eval): 10.0655
Epoch: 7, loss (training): 10.0214, loss (eval): 10.1054
Epoch: 8, loss (training): 10.0239, loss (eval): 10.1391
Epoch: 9, loss (training): 10.0628, loss (eval): 10.1635
Epoch: 10, loss (training): 10.0225, loss (eval): 10.1663
Epoch: 11, loss (training): 10.0134, loss (eval): 10.0591
Epoch: 12, loss (training): 10.0217, loss (eval): 10.1163
Epoch: 13, loss (training): 10.0531, loss (eval): 10.0752
Epoch: 14, loss (training): 10.0176, loss (eval): 10.2163
Epoch: 15, loss (training): 10.0043, loss (eval): 10.1119
Epoch: 16, loss (training): 10.0132, loss (eval): 10.0898
Epoch: 17, loss (training): 10.0092, loss (eval): 10.1568
Epoch: 18, loss (training): 9.9672, loss (eval): 10.0763
Epoch: 19, loss (training): 9.9942, loss (eval): 10.0624
Epoch: 20, loss (training): 9.9964, loss (eval): 10.1483
Epoch: 21, loss (training): 9.9683, loss (eval): 10.1574
Epoch: 22, loss (training): 9.9969, loss (eval): 10.1053
Epoch: 23, loss (training): 10.0097, loss (eval): 10.2376
Epoch: 24, loss (training): 9.9665, loss (eval): 10.2033
Early-stopping. Training converged after 25 epochs.
start update posterior model
Epoch: 0, loss (training): 10.6948, loss (eval): 10.8573
Epoch: 1, loss (training): 10.6871, loss (eval): 10.701
Epoch: 2, loss (training): 10.6872, loss (eval): 10.6845
Epoch: 3, loss (training): 10.6834, loss (eval): 10.6974
Epoch: 4, loss (training): 10.684, loss (eval): 10.6888
Epoch: 5, loss (training): 10.6846, loss (eval): 10.6823
Epoch: 6, loss (training): 10.6866, loss (eval): 10.6851
Epoch: 7, loss (training): 10.6874, loss (eval): 10.682
Epoch: 8, loss (training): 10.6856, loss (eval): 10.6828
Epoch: 9, loss (training): 10.6835, loss (eval): 10.6905
Epoch: 10, loss (training): 10.6849, loss (eval): 10.6798
Epoch: 11, loss (training): 10.6891, loss (eval): 10.6909
Epoch: 12, loss (training): 10.6848, loss (eval): 10.6762
Epoch: 13, loss (training): 10.6863, loss (eval): 10.6806
Epoch: 14, loss (training): 10.6845, loss (eval): 10.6827
Epoch: 15, loss (training): 10.6847, loss (eval): 10.6771
Epoch: 16, loss (training): 10.6828, loss (eval): 10.6885
Epoch: 17, loss (training): 10.6862, loss (eval): 10.6829
Epoch: 18, loss (training): 10.6839, loss (eval): 10.6862
Epoch: 19, loss (training): 10.6875, loss (eval): 10.69
Epoch: 20, loss (training): 10.6887, loss (eval): 10.6803
Epoch: 21, loss (training): 10.6856, loss (eval): 10.6805
Epoch: 22, loss (training): 10.6872, loss (eval): 10.6992
Epoch: 23, loss (training): 10.6853, loss (eval): 10.6794
Epoch: 24, loss (training): 10.6869, loss (eval): 10.7202
Epoch: 25, loss (training): 10.6826, loss (eval): 10.6783
Epoch: 26, loss (training): 10.6846, loss (eval): 10.6849
Epoch: 27, loss (training): 10.6892, loss (eval): 10.6854
Epoch: 28, loss (training): 10.6889, loss (eval): 10.6878
Epoch: 29, loss (training): 10.6873, loss (eval): 10.6784
Epoch: 30, loss (training): 10.6901, loss (eval): 10.688
Epoch: 31, loss (training): 10.6859, loss (eval): 10.6833
Early-stopping. Training converged after 32 epochs.
Iteration: 4
optimizer_post_lr: [0.000970299]
prob_prior: 0.12245642825298195
start update likelihood model
Epoch: 0, loss (training): 10.2322, loss (eval): 10.027
Epoch: 1, loss (training): 10.1929, loss (eval): 10.0213
Epoch: 2, loss (training): 10.2068, loss (eval): 10.1114
Epoch: 3, loss (training): 10.1857, loss (eval): 10.1608
Epoch: 4, loss (training): 10.1307, loss (eval): 10.087
Epoch: 5, loss (training): 10.1218, loss (eval): 10.0852
Epoch: 6, loss (training): 10.1136, loss (eval): 10.0722
Epoch: 7, loss (training): 10.1254, loss (eval): 10.082
Epoch: 8, loss (training): 10.0835, loss (eval): 10.1088
Epoch: 9, loss (training): 10.1, loss (eval): 10.1081
Epoch: 10, loss (training): 10.0876, loss (eval): 10.1002
Epoch: 11, loss (training): 10.0898, loss (eval): 10.1274
Epoch: 12, loss (training): 10.0647, loss (eval): 10.0728
Epoch: 13, loss (training): 10.0693, loss (eval): 10.0904
Epoch: 14, loss (training): 10.0896, loss (eval): 10.0975
Epoch: 15, loss (training): 10.0672, loss (eval): 10.1289
Epoch: 16, loss (training): 10.0745, loss (eval): 10.1401
Epoch: 17, loss (training): 10.0865, loss (eval): 10.121
Epoch: 18, loss (training): 10.0778, loss (eval): 10.0751
Epoch: 19, loss (training): 10.0677, loss (eval): 10.0871
Epoch: 20, loss (training): 10.0463, loss (eval): 10.0759
Early-stopping. Training converged after 21 epochs.
start update posterior model
Epoch: 0, loss (training): 11.1696, loss (eval): 11.3158
Epoch: 1, loss (training): 11.1644, loss (eval): 11.1615
Epoch: 2, loss (training): 11.1629, loss (eval): 11.1694
Epoch: 3, loss (training): 11.164, loss (eval): 11.1647
Epoch: 4, loss (training): 11.1654, loss (eval): 11.1721
Epoch: 5, loss (training): 11.1619, loss (eval): 11.1559
Epoch: 6, loss (training): 11.1647, loss (eval): 11.1601
Epoch: 7, loss (training): 11.1616, loss (eval): 11.1577
Epoch: 8, loss (training): 11.1629, loss (eval): 11.1594
Epoch: 9, loss (training): 11.1639, loss (eval): 11.1691
Epoch: 10, loss (training): 11.1643, loss (eval): 11.1629
Epoch: 11, loss (training): 11.1665, loss (eval): 11.1661
Epoch: 12, loss (training): 11.163, loss (eval): 11.1678
Epoch: 13, loss (training): 11.1609, loss (eval): 11.163
Epoch: 14, loss (training): 11.1621, loss (eval): 11.1568
Epoch: 15, loss (training): 11.1652, loss (eval): 11.1651
Epoch: 16, loss (training): 11.163, loss (eval): 11.1608
Epoch: 17, loss (training): 11.1624, loss (eval): 11.1609
Epoch: 18, loss (training): 11.1619, loss (eval): 11.1609
Epoch: 19, loss (training): 11.1637, loss (eval): 11.1617
Epoch: 20, loss (training): 11.1649, loss (eval): 11.1695
Epoch: 21, loss (training): 11.1609, loss (eval): 11.153
Epoch: 22, loss (training): 11.1648, loss (eval): 11.1776
Epoch: 23, loss (training): 11.1651, loss (eval): 11.158
Epoch: 24, loss (training): 11.1614, loss (eval): 11.1569
Epoch: 25, loss (training): 11.1614, loss (eval): 11.1602
Epoch: 26, loss (training): 11.1644, loss (eval): 11.1616
Epoch: 27, loss (training): 11.1628, loss (eval): 11.2144
Epoch: 28, loss (training): 11.164, loss (eval): 11.151
Epoch: 29, loss (training): 11.1629, loss (eval): 11.1675
Epoch: 30, loss (training): 11.1622, loss (eval): 11.1646
Epoch: 31, loss (training): 11.1632, loss (eval): 11.1618
Epoch: 32, loss (training): 11.1616, loss (eval): 11.1587
Epoch: 33, loss (training): 11.1595, loss (eval): 11.156
Epoch: 34, loss (training): 11.1655, loss (eval): 11.1553
Epoch: 35, loss (training): 11.1613, loss (eval): 11.1452
Epoch: 36, loss (training): 11.1623, loss (eval): 11.164
Epoch: 37, loss (training): 11.1593, loss (eval): 11.1566
Epoch: 38, loss (training): 11.1624, loss (eval): 11.1599
Epoch: 39, loss (training): 11.1637, loss (eval): 11.1609
Epoch: 40, loss (training): 11.164, loss (eval): 11.1684
Epoch: 41, loss (training): 11.1626, loss (eval): 11.161
Epoch: 42, loss (training): 11.1604, loss (eval): 11.171
Epoch: 43, loss (training): 11.1607, loss (eval): 11.17
Epoch: 44, loss (training): 11.1606, loss (eval): 11.1597
Epoch: 45, loss (training): 11.1637, loss (eval): 11.1592
Epoch: 46, loss (training): 11.1633, loss (eval): 11.1569
Epoch: 47, loss (training): 11.162, loss (eval): 11.1673
Epoch: 48, loss (training): 11.1619, loss (eval): 11.1631
Epoch: 49, loss (training): 11.1639, loss (eval): 11.1589
Epoch: 50, loss (training): 11.1635, loss (eval): 11.1604
Epoch: 51, loss (training): 11.161, loss (eval): 11.1661
Epoch: 52, loss (training): 11.1587, loss (eval): 11.1798
Epoch: 53, loss (training): 11.167, loss (eval): 11.1616
Epoch: 54, loss (training): 11.163, loss (eval): 11.1659
Early-stopping. Training converged after 55 epochs.
Iteration: 5
optimizer_post_lr: [0.0009605960099999999]
prob_prior: 0.06081006262521797
start update likelihood model
Epoch: 0, loss (training): 10.231, loss (eval): 10.2493
Epoch: 1, loss (training): 10.2229, loss (eval): 10.2657
Epoch: 2, loss (training): 10.1961, loss (eval): 10.2755
Epoch: 3, loss (training): 10.1782, loss (eval): 10.2692
Epoch: 4, loss (training): 10.1871, loss (eval): 10.2347
Epoch: 5, loss (training): 10.1517, loss (eval): 10.1976
Epoch: 6, loss (training): 10.154, loss (eval): 10.2207
Epoch: 7, loss (training): 10.1635, loss (eval): 10.2582
Epoch: 8, loss (training): 10.1329, loss (eval): 10.2241
Epoch: 9, loss (training): 10.1496, loss (eval): 10.1995
Epoch: 10, loss (training): 10.1668, loss (eval): 10.3394
Epoch: 11, loss (training): 10.1493, loss (eval): 10.238
Epoch: 12, loss (training): 10.135, loss (eval): 10.2105
Epoch: 13, loss (training): 10.1394, loss (eval): 10.2554
Epoch: 14, loss (training): 10.1354, loss (eval): 10.2657
Epoch: 15, loss (training): 10.1334, loss (eval): 10.3088
Epoch: 16, loss (training): 10.1364, loss (eval): 10.237
Epoch: 17, loss (training): 10.1175, loss (eval): 10.3458
Epoch: 18, loss (training): 10.1157, loss (eval): 10.2118
Epoch: 19, loss (training): 10.1038, loss (eval): 10.2741
Epoch: 20, loss (training): 10.1169, loss (eval): 10.2477
Epoch: 21, loss (training): 10.1078, loss (eval): 10.2796
Epoch: 22, loss (training): 10.0998, loss (eval): 10.2992
Epoch: 23, loss (training): 10.1023, loss (eval): 10.2974
Epoch: 24, loss (training): 10.105, loss (eval): 10.2553
Early-stopping. Training converged after 25 epochs.
start update posterior model
Epoch: 0, loss (training): 11.0586, loss (eval): 11.0697
Epoch: 1, loss (training): 11.06, loss (eval): 11.0552
Epoch: 2, loss (training): 11.0608, loss (eval): 11.0706
Epoch: 3, loss (training): 11.0587, loss (eval): 11.0572
Epoch: 4, loss (training): 11.0606, loss (eval): 11.0725
Epoch: 5, loss (training): 11.0606, loss (eval): 11.0579
Epoch: 6, loss (training): 11.0604, loss (eval): 11.0674
Epoch: 7, loss (training): 11.0585, loss (eval): 11.051
Epoch: 8, loss (training): 11.0602, loss (eval): 11.0535
Epoch: 9, loss (training): 11.0603, loss (eval): 11.063
Epoch: 10, loss (training): 11.0605, loss (eval): 11.0682
Epoch: 11, loss (training): 11.0614, loss (eval): 11.0505
Epoch: 12, loss (training): 11.0568, loss (eval): 11.0538
Epoch: 13, loss (training): 11.0589, loss (eval): 11.0573
Epoch: 14, loss (training): 11.0584, loss (eval): 11.0873
Epoch: 15, loss (training): 11.0591, loss (eval): 11.0617
Epoch: 16, loss (training): 11.0609, loss (eval): 11.0548
Epoch: 17, loss (training): 11.0588, loss (eval): 11.0594
Epoch: 18, loss (training): 11.0587, loss (eval): 11.0639
Epoch: 19, loss (training): 11.0595, loss (eval): 11.0685
Epoch: 20, loss (training): 11.0593, loss (eval): 11.0601
Epoch: 21, loss (training): 11.0572, loss (eval): 11.0603
Epoch: 22, loss (training): 11.0596, loss (eval): 11.0583
Epoch: 23, loss (training): 11.0614, loss (eval): 11.0685
Epoch: 24, loss (training): 11.0587, loss (eval): 11.0567
Epoch: 25, loss (training): 11.058, loss (eval): 11.0576
Epoch: 26, loss (training): 11.0613, loss (eval): 11.0549
Epoch: 27, loss (training): 11.0612, loss (eval): 11.0525
Epoch: 28, loss (training): 11.0592, loss (eval): 11.0576
Epoch: 29, loss (training): 11.0578, loss (eval): 11.0556
Epoch: 30, loss (training): 11.0593, loss (eval): 11.053
Early-stopping. Training converged after 31 epochs.
Iteration: 6
optimizer_post_lr: [0.0009509900498999999]
prob_prior: 0.0301973834223185
start update likelihood model
Epoch: 0, loss (training): 10.1865, loss (eval): 10.3091
Epoch: 1, loss (training): 10.138, loss (eval): 10.3385
Epoch: 2, loss (training): 10.1722, loss (eval): 10.3022
Epoch: 3, loss (training): 10.1217, loss (eval): 10.308
Epoch: 4, loss (training): 10.1183, loss (eval): 10.2936
Epoch: 5, loss (training): 10.0987, loss (eval): 10.3223
Epoch: 6, loss (training): 10.0863, loss (eval): 10.3297
Epoch: 7, loss (training): 10.0781, loss (eval): 10.3582
Epoch: 8, loss (training): 10.0716, loss (eval): 10.271
Epoch: 9, loss (training): 10.0656, loss (eval): 10.3213
Epoch: 10, loss (training): 10.0711, loss (eval): 10.2976
Epoch: 11, loss (training): 10.0727, loss (eval): 10.2977
Epoch: 12, loss (training): 10.072, loss (eval): 10.3148
Epoch: 13, loss (training): 10.0654, loss (eval): 10.3017
Epoch: 14, loss (training): 10.0547, loss (eval): 10.3255
Epoch: 15, loss (training): 10.0554, loss (eval): 10.3071
Epoch: 16, loss (training): 10.051, loss (eval): 10.2727
Epoch: 17, loss (training): 10.0471, loss (eval): 10.3835
Epoch: 18, loss (training): 10.0464, loss (eval): 10.3112
Epoch: 19, loss (training): 10.0442, loss (eval): 10.2686
Epoch: 20, loss (training): 10.0406, loss (eval): 10.334
Epoch: 21, loss (training): 10.0344, loss (eval): 10.3093
Epoch: 22, loss (training): 10.0477, loss (eval): 10.3088
Epoch: 23, loss (training): 10.0395, loss (eval): 10.3917
Epoch: 24, loss (training): 10.0315, loss (eval): 10.3058
Epoch: 25, loss (training): 10.0408, loss (eval): 10.2853
Epoch: 26, loss (training): 10.0326, loss (eval): 10.287
Epoch: 27, loss (training): 10.0354, loss (eval): 10.3104
Epoch: 28, loss (training): 10.0432, loss (eval): 10.2945
Epoch: 29, loss (training): 10.0512, loss (eval): 10.4263
Epoch: 30, loss (training): 10.039, loss (eval): 10.3562
Epoch: 31, loss (training): 10.0251, loss (eval): 10.3015
Epoch: 32, loss (training): 10.0355, loss (eval): 10.3665
Epoch: 33, loss (training): 10.046, loss (eval): 10.2667
Epoch: 34, loss (training): 10.0129, loss (eval): 10.358
Epoch: 35, loss (training): 10.0147, loss (eval): 10.3757
Epoch: 36, loss (training): 10.0063, loss (eval): 10.3627
Epoch: 37, loss (training): 10.0114, loss (eval): 10.3186
Epoch: 38, loss (training): 10.0123, loss (eval): 10.3218
Epoch: 39, loss (training): 10.0123, loss (eval): 10.3106
Epoch: 40, loss (training): 9.9919, loss (eval): 10.3537
Epoch: 41, loss (training): 9.9926, loss (eval): 10.3206
Epoch: 42, loss (training): 10.0391, loss (eval): 10.451
Epoch: 43, loss (training): 10.0054, loss (eval): 10.2967
Epoch: 44, loss (training): 10.012, loss (eval): 10.3258
Epoch: 45, loss (training): 9.996, loss (eval): 10.3662
Epoch: 46, loss (training): 9.9932, loss (eval): 10.3804
Epoch: 47, loss (training): 9.9679, loss (eval): 10.333
Epoch: 48, loss (training): 9.9851, loss (eval): 10.3283
Epoch: 49, loss (training): 10.0028, loss (eval): 10.3932
Epoch: 50, loss (training): 9.9984, loss (eval): 10.402
Epoch: 51, loss (training): 9.9716, loss (eval): 10.403
Epoch: 52, loss (training): 9.9783, loss (eval): 10.3802
Early-stopping. Training converged after 53 epochs.
start update posterior model
Epoch: 0, loss (training): 10.8088, loss (eval): 10.822
Epoch: 1, loss (training): 10.8035, loss (eval): 10.8008
Epoch: 2, loss (training): 10.804, loss (eval): 10.8159
Epoch: 3, loss (training): 10.805, loss (eval): 10.8202
Epoch: 4, loss (training): 10.8014, loss (eval): 10.8043
Epoch: 5, loss (training): 10.8057, loss (eval): 10.7896
Epoch: 6, loss (training): 10.8046, loss (eval): 10.8054
Epoch: 7, loss (training): 10.8029, loss (eval): 10.7969
Epoch: 8, loss (training): 10.8062, loss (eval): 10.8006
Epoch: 9, loss (training): 10.8018, loss (eval): 10.7996
Epoch: 10, loss (training): 10.8039, loss (eval): 10.7974
Epoch: 11, loss (training): 10.8036, loss (eval): 10.8133
Epoch: 12, loss (training): 10.8043, loss (eval): 10.8085
Epoch: 13, loss (training): 10.8013, loss (eval): 10.7927
Epoch: 14, loss (training): 10.8021, loss (eval): 10.8053
Epoch: 15, loss (training): 10.8022, loss (eval): 10.8075
Epoch: 16, loss (training): 10.8025, loss (eval): 10.7985
Epoch: 17, loss (training): 10.8019, loss (eval): 10.8016
Epoch: 18, loss (training): 10.8029, loss (eval): 10.7932
Epoch: 19, loss (training): 10.8013, loss (eval): 10.7963
Epoch: 20, loss (training): 10.8027, loss (eval): 10.7946
Epoch: 21, loss (training): 10.8045, loss (eval): 10.7978
Epoch: 22, loss (training): 10.8005, loss (eval): 10.7967
Epoch: 23, loss (training): 10.8029, loss (eval): 10.8086
Epoch: 24, loss (training): 10.8035, loss (eval): 10.8129
Early-stopping. Training converged after 25 epochs.
Iteration: 7
optimizer_post_lr: [0.0009414801494009999]
prob_prior: 0.014995576820477717
start update likelihood model
Epoch: 0, loss (training): 10.2582, loss (eval): 10.0407
Epoch: 1, loss (training): 10.2081, loss (eval): 9.9832
Epoch: 2, loss (training): 10.1125, loss (eval): 9.944
Epoch: 3, loss (training): 10.0806, loss (eval): 9.923
Epoch: 4, loss (training): 10.1015, loss (eval): 9.9054
Epoch: 5, loss (training): 10.0543, loss (eval): 9.9079
Epoch: 6, loss (training): 10.0514, loss (eval): 9.8873
Epoch: 7, loss (training): 10.0544, loss (eval): 9.9299
Epoch: 8, loss (training): 10.0365, loss (eval): 9.8902
Epoch: 9, loss (training): 10.0387, loss (eval): 9.8796
Epoch: 10, loss (training): 10.0217, loss (eval): 9.8855
Epoch: 11, loss (training): 10.0268, loss (eval): 9.9233
Epoch: 12, loss (training): 10.012, loss (eval): 9.9062
Epoch: 13, loss (training): 10.0032, loss (eval): 9.9047
Epoch: 14, loss (training): 10.0299, loss (eval): 9.9107
Epoch: 15, loss (training): 10.0211, loss (eval): 9.91
Epoch: 16, loss (training): 10.026, loss (eval): 9.8685
Epoch: 17, loss (training): 10.0163, loss (eval): 9.9391
Epoch: 18, loss (training): 10.0115, loss (eval): 9.9284
Epoch: 19, loss (training): 10.0125, loss (eval): 9.9303
Epoch: 20, loss (training): 10.0125, loss (eval): 9.8775
Epoch: 21, loss (training): 10.0011, loss (eval): 9.8857
Epoch: 22, loss (training): 9.9857, loss (eval): 9.8865
Epoch: 23, loss (training): 9.9851, loss (eval): 9.9083
Epoch: 24, loss (training): 9.977, loss (eval): 9.9368
Epoch: 25, loss (training): 9.9868, loss (eval): 9.9244
Epoch: 26, loss (training): 9.9995, loss (eval): 9.9405
Epoch: 27, loss (training): 10.0196, loss (eval): 9.8752
Epoch: 28, loss (training): 9.993, loss (eval): 9.9295
Epoch: 29, loss (training): 9.9828, loss (eval): 9.8894
Epoch: 30, loss (training): 9.9622, loss (eval): 9.8872
Epoch: 31, loss (training): 9.9828, loss (eval): 9.9438
Epoch: 32, loss (training): 9.9586, loss (eval): 9.8921
Epoch: 33, loss (training): 9.9608, loss (eval): 9.9186
Epoch: 34, loss (training): 9.9497, loss (eval): 9.9252
Epoch: 35, loss (training): 9.9623, loss (eval): 9.9624
Early-stopping. Training converged after 36 epochs.
start update posterior model
Epoch: 0, loss (training): 10.6237, loss (eval): 10.665
Epoch: 1, loss (training): 10.6238, loss (eval): 10.6248
Epoch: 2, loss (training): 10.6193, loss (eval): 10.6157
Epoch: 3, loss (training): 10.6207, loss (eval): 10.6109
Epoch: 4, loss (training): 10.6191, loss (eval): 10.6174
Epoch: 5, loss (training): 10.619, loss (eval): 10.6251
Epoch: 6, loss (training): 10.6191, loss (eval): 10.6184
Epoch: 7, loss (training): 10.6202, loss (eval): 10.6174
Epoch: 8, loss (training): 10.6192, loss (eval): 10.6332
Epoch: 9, loss (training): 10.619, loss (eval): 10.6217
Epoch: 10, loss (training): 10.6232, loss (eval): 10.6172
Epoch: 11, loss (training): 10.6179, loss (eval): 10.6145
Epoch: 12, loss (training): 10.6187, loss (eval): 10.6188
Epoch: 13, loss (training): 10.619, loss (eval): 10.6273
Epoch: 14, loss (training): 10.6183, loss (eval): 10.6149
Epoch: 15, loss (training): 10.6215, loss (eval): 10.623
Epoch: 16, loss (training): 10.618, loss (eval): 10.6151
Epoch: 17, loss (training): 10.6205, loss (eval): 10.6205
Epoch: 18, loss (training): 10.6219, loss (eval): 10.6186
Epoch: 19, loss (training): 10.621, loss (eval): 10.6198
Epoch: 20, loss (training): 10.6179, loss (eval): 10.615
Epoch: 21, loss (training): 10.6211, loss (eval): 10.614
Epoch: 22, loss (training): 10.6197, loss (eval): 10.6256
Early-stopping. Training converged after 23 epochs.
Iteration: 8
optimizer_post_lr: [0.0009320653479069899]
prob_prior: 0.007446583070924344
start update likelihood model
Epoch: 0, loss (training): 10.1784, loss (eval): 9.9882
Epoch: 1, loss (training): 10.1494, loss (eval): 9.9991
Epoch: 2, loss (training): 10.1079, loss (eval): 10.004
Epoch: 3, loss (training): 10.0787, loss (eval): 9.941
Epoch: 4, loss (training): 10.0787, loss (eval): 9.969
Epoch: 5, loss (training): 10.0777, loss (eval): 9.9802
Epoch: 6, loss (training): 10.047, loss (eval): 9.9368
Epoch: 7, loss (training): 10.0653, loss (eval): 9.971
Epoch: 8, loss (training): 10.0511, loss (eval): 9.963
Epoch: 9, loss (training): 10.0524, loss (eval): 9.9112
Epoch: 10, loss (training): 10.0383, loss (eval): 9.9845
Epoch: 11, loss (training): 10.0277, loss (eval): 9.9424
Epoch: 12, loss (training): 10.0121, loss (eval): 9.9856
Epoch: 13, loss (training): 10.0283, loss (eval): 9.9022
Epoch: 14, loss (training): 10.045, loss (eval): 10.047
Epoch: 15, loss (training): 10.0518, loss (eval): 9.9996
Epoch: 16, loss (training): 10.0109, loss (eval): 9.8923
Epoch: 17, loss (training): 10.0226, loss (eval): 9.911
Epoch: 18, loss (training): 10.0051, loss (eval): 9.9274
Epoch: 19, loss (training): 10.0131, loss (eval): 9.9408
Epoch: 20, loss (training): 10.0156, loss (eval): 9.9229
Epoch: 21, loss (training): 9.9905, loss (eval): 9.9245
Epoch: 22, loss (training): 10.0099, loss (eval): 9.9149
Epoch: 23, loss (training): 9.9787, loss (eval): 9.9309
Epoch: 24, loss (training): 9.9939, loss (eval): 9.9416
Epoch: 25, loss (training): 9.9962, loss (eval): 9.9232
Epoch: 26, loss (training): 9.9659, loss (eval): 9.949
Epoch: 27, loss (training): 9.9747, loss (eval): 9.9802
Epoch: 28, loss (training): 9.9749, loss (eval): 9.9439
Epoch: 29, loss (training): 9.9801, loss (eval): 9.9464
Epoch: 30, loss (training): 9.992, loss (eval): 9.9726
Epoch: 31, loss (training): 9.9778, loss (eval): 9.968
Epoch: 32, loss (training): 9.9527, loss (eval): 9.9584
Epoch: 33, loss (training): 9.9552, loss (eval): 9.9008
Epoch: 34, loss (training): 9.9408, loss (eval): 9.9468
Epoch: 35, loss (training): 9.9548, loss (eval): 9.9517
Early-stopping. Training converged after 36 epochs.
start update posterior model
Epoch: 0, loss (training): 11.1174, loss (eval): 11.137
Epoch: 1, loss (training): 11.1192, loss (eval): 11.1222
Epoch: 2, loss (training): 11.1208, loss (eval): 11.1285
Epoch: 3, loss (training): 11.119, loss (eval): 11.1135
Epoch: 4, loss (training): 11.1164, loss (eval): 11.1172
Epoch: 5, loss (training): 11.1176, loss (eval): 11.1115
Epoch: 6, loss (training): 11.1143, loss (eval): 11.115
Epoch: 7, loss (training): 11.1159, loss (eval): 11.1198
Epoch: 8, loss (training): 11.1169, loss (eval): 11.1112
Epoch: 9, loss (training): 11.1182, loss (eval): 11.1122
Epoch: 10, loss (training): 11.1154, loss (eval): 11.119
Epoch: 11, loss (training): 11.1139, loss (eval): 11.1147
Epoch: 12, loss (training): 11.1152, loss (eval): 11.1137
Epoch: 13, loss (training): 11.119, loss (eval): 11.1249
Epoch: 14, loss (training): 11.119, loss (eval): 11.1157
Epoch: 15, loss (training): 11.1151, loss (eval): 11.1156
Epoch: 16, loss (training): 11.1197, loss (eval): 11.1076
Epoch: 17, loss (training): 11.1176, loss (eval): 11.1106
Epoch: 18, loss (training): 11.116, loss (eval): 11.1126
Epoch: 19, loss (training): 11.1177, loss (eval): 11.1151
Epoch: 20, loss (training): 11.1186, loss (eval): 11.1205
Epoch: 21, loss (training): 11.1161, loss (eval): 11.1206
Epoch: 22, loss (training): 11.1156, loss (eval): 11.1137
Epoch: 23, loss (training): 11.116, loss (eval): 11.1151
Epoch: 24, loss (training): 11.1171, loss (eval): 11.1058
Epoch: 25, loss (training): 11.1165, loss (eval): 11.1204
Epoch: 26, loss (training): 11.1203, loss (eval): 11.1116
Epoch: 27, loss (training): 11.1167, loss (eval): 11.1165
Epoch: 28, loss (training): 11.1167, loss (eval): 11.1099
Epoch: 29, loss (training): 11.1172, loss (eval): 11.1177
Epoch: 30, loss (training): 11.117, loss (eval): 11.1096
Epoch: 31, loss (training): 11.1174, loss (eval): 11.1222
Epoch: 32, loss (training): 11.1182, loss (eval): 11.1115
Epoch: 33, loss (training): 11.1171, loss (eval): 11.1089
Epoch: 34, loss (training): 11.1165, loss (eval): 11.1144
Epoch: 35, loss (training): 11.1163, loss (eval): 11.1099
Epoch: 36, loss (training): 11.116, loss (eval): 11.1142
Epoch: 37, loss (training): 11.1173, loss (eval): 11.1131
Epoch: 38, loss (training): 11.1149, loss (eval): 11.1106
Epoch: 39, loss (training): 11.1169, loss (eval): 11.1221
Epoch: 40, loss (training): 11.1166, loss (eval): 11.1121
Epoch: 41, loss (training): 11.1182, loss (eval): 11.1223
Epoch: 42, loss (training): 11.117, loss (eval): 11.1208
Epoch: 43, loss (training): 11.1165, loss (eval): 11.1351
Early-stopping. Training converged after 44 epochs.
Iteration: 9
optimizer_post_lr: [0.00092274469442792]
prob_prior: 0.003697863716482932
start update likelihood model
Epoch: 0, loss (training): 10.1842, loss (eval): 10.3763
Epoch: 1, loss (training): 10.1307, loss (eval): 10.3253
Epoch: 2, loss (training): 10.0824, loss (eval): 10.3051
Epoch: 3, loss (training): 10.0646, loss (eval): 10.3471
Epoch: 4, loss (training): 10.0618, loss (eval): 10.2867
Epoch: 5, loss (training): 10.0525, loss (eval): 10.3499
Epoch: 6, loss (training): 10.0153, loss (eval): 10.3301
Epoch: 7, loss (training): 10.002, loss (eval): 10.3129
Epoch: 8, loss (training): 10.0101, loss (eval): 10.3304
Epoch: 9, loss (training): 9.9963, loss (eval): 10.3289
Epoch: 10, loss (training): 9.9805, loss (eval): 10.4498
Epoch: 11, loss (training): 9.9959, loss (eval): 10.4004
Epoch: 12, loss (training): 9.9666, loss (eval): 10.3207
Epoch: 13, loss (training): 9.9839, loss (eval): 10.3803
Epoch: 14, loss (training): 9.9874, loss (eval): 10.3822
Epoch: 15, loss (training): 9.9722, loss (eval): 10.3573
Epoch: 16, loss (training): 9.9585, loss (eval): 10.3212
Epoch: 17, loss (training): 9.9674, loss (eval): 10.3146
Epoch: 18, loss (training): 9.9659, loss (eval): 10.3561
Epoch: 19, loss (training): 9.9652, loss (eval): 10.3642
Epoch: 20, loss (training): 9.9783, loss (eval): 10.3801
Epoch: 21, loss (training): 9.9605, loss (eval): 10.3087
Epoch: 22, loss (training): 9.9427, loss (eval): 10.3239
Epoch: 23, loss (training): 9.9335, loss (eval): 10.3535
Early-stopping. Training converged after 24 epochs.
start update posterior model
Epoch: 0, loss (training): 10.9838, loss (eval): 10.992
Epoch: 1, loss (training): 10.9851, loss (eval): 10.973
Epoch: 2, loss (training): 10.9818, loss (eval): 10.9832
Epoch: 3, loss (training): 10.9837, loss (eval): 10.9844
Epoch: 4, loss (training): 10.9844, loss (eval): 11.0022
Epoch: 5, loss (training): 10.9829, loss (eval): 10.9832
Epoch: 6, loss (training): 10.9824, loss (eval): 10.9789
Epoch: 7, loss (training): 10.983, loss (eval): 10.9802
Epoch: 8, loss (training): 10.9806, loss (eval): 10.9798
Epoch: 9, loss (training): 10.9838, loss (eval): 10.9832
Epoch: 10, loss (training): 10.9846, loss (eval): 10.9817
Epoch: 11, loss (training): 10.9831, loss (eval): 10.9838
Epoch: 12, loss (training): 10.9848, loss (eval): 10.9847
Epoch: 13, loss (training): 10.9838, loss (eval): 10.9829
Epoch: 14, loss (training): 10.9827, loss (eval): 10.9773
Epoch: 15, loss (training): 10.9835, loss (eval): 10.9854
Epoch: 16, loss (training): 10.9829, loss (eval): 10.9854
Epoch: 17, loss (training): 10.9838, loss (eval): 10.9902
Epoch: 18, loss (training): 10.9825, loss (eval): 10.9785
Epoch: 19, loss (training): 10.9814, loss (eval): 10.9847
Epoch: 20, loss (training): 10.9822, loss (eval): 10.9826
Early-stopping. Training converged after 21 epochs.
Iteration: 10
optimizer_post_lr: [0.0009135172474836408]
prob_prior: 0.0018363047770289071
start update likelihood model
Epoch: 0, loss (training): 10.1306, loss (eval): 9.8707
Epoch: 1, loss (training): 10.1622, loss (eval): 9.9501
Epoch: 2, loss (training): 10.0955, loss (eval): 9.9418
Epoch: 3, loss (training): 10.0447, loss (eval): 9.882
Epoch: 4, loss (training): 10.0453, loss (eval): 9.915
Epoch: 5, loss (training): 10.0245, loss (eval): 9.876
Epoch: 6, loss (training): 10.0029, loss (eval): 9.9466
Epoch: 7, loss (training): 10.0143, loss (eval): 9.8943
Epoch: 8, loss (training): 9.9829, loss (eval): 9.9428
Epoch: 9, loss (training): 9.9818, loss (eval): 9.925
Epoch: 10, loss (training): 9.9806, loss (eval): 9.9278
Epoch: 11, loss (training): 9.982, loss (eval): 9.9055
Epoch: 12, loss (training): 9.9802, loss (eval): 9.9372
Epoch: 13, loss (training): 9.9817, loss (eval): 9.9094
Epoch: 14, loss (training): 9.9656, loss (eval): 9.8928
Epoch: 15, loss (training): 9.9596, loss (eval): 9.9244
Epoch: 16, loss (training): 9.9497, loss (eval): 9.9116
Epoch: 17, loss (training): 9.9531, loss (eval): 9.9274
Epoch: 18, loss (training): 9.9534, loss (eval): 9.923
Epoch: 19, loss (training): 9.9846, loss (eval): 9.9685
Early-stopping. Training converged after 20 epochs.
start update posterior model
Epoch: 0, loss (training): 11.1586, loss (eval): 11.1886
Epoch: 1, loss (training): 11.1535, loss (eval): 11.1529
Epoch: 2, loss (training): 11.1539, loss (eval): 11.1512
Epoch: 3, loss (training): 11.1539, loss (eval): 11.1501
Epoch: 4, loss (training): 11.1515, loss (eval): 11.1495
Epoch: 5, loss (training): 11.157, loss (eval): 11.1513
Epoch: 6, loss (training): 11.1548, loss (eval): 11.1445
Epoch: 7, loss (training): 11.1557, loss (eval): 11.1546
Epoch: 8, loss (training): 11.1513, loss (eval): 11.152
Epoch: 9, loss (training): 11.1504, loss (eval): 11.1398
Epoch: 10, loss (training): 11.1554, loss (eval): 11.1555
Epoch: 11, loss (training): 11.1524, loss (eval): 11.1523
Epoch: 12, loss (training): 11.1545, loss (eval): 11.1449
Epoch: 13, loss (training): 11.1538, loss (eval): 11.1488
Epoch: 14, loss (training): 11.1528, loss (eval): 11.1468
Epoch: 15, loss (training): 11.1546, loss (eval): 11.1587
Epoch: 16, loss (training): 11.1534, loss (eval): 11.1495
Epoch: 17, loss (training): 11.1534, loss (eval): 11.1527
Epoch: 18, loss (training): 11.1533, loss (eval): 11.1533
Epoch: 19, loss (training): 11.1536, loss (eval): 11.1555
Epoch: 20, loss (training): 11.156, loss (eval): 11.1483
Epoch: 21, loss (training): 11.1548, loss (eval): 11.1523
Epoch: 22, loss (training): 11.153, loss (eval): 11.1482
Epoch: 23, loss (training): 11.154, loss (eval): 11.1491
Epoch: 24, loss (training): 11.1539, loss (eval): 11.1531
Epoch: 25, loss (training): 11.1546, loss (eval): 11.1557
Epoch: 26, loss (training): 11.1517, loss (eval): 11.1636
Epoch: 27, loss (training): 11.1516, loss (eval): 11.1538
Epoch: 28, loss (training): 11.1531, loss (eval): 11.1514
Early-stopping. Training converged after 29 epochs.

Runtime:1454.26
0
1
2
3
4
5
6
7
8
9
