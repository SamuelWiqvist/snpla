Input args:
Dim: 2
seed: 3
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/2d w 5 obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.7940673764515668, eval loss: 5.505701541900635
Epoch: 1, loss: 0.501196002359502, eval loss: 0.6042125821113586
Epoch: 2, loss: 0.46532599316211415, eval loss: 0.5226006507873535
Epoch: 3, loss: 0.4469320743205026, eval loss: 0.5721959471702576
Epoch: 4, loss: 0.43614854841434864, eval loss: 0.47680115699768066
Epoch: 5, loss: 0.42441794619662687, eval loss: 0.48611506819725037
Epoch: 6, loss: 0.4160002565738978, eval loss: 0.4237053096294403
Epoch: 7, loss: 0.40880417688282933, eval loss: 0.4060359299182892
Epoch: 8, loss: 0.4061340729263611, eval loss: 0.40485867857933044
Epoch: 9, loss: 0.40454844690626485, eval loss: 0.4675392806529999
Epoch: 10, loss: 0.39626299929455855, eval loss: 0.3994887173175812
Epoch: 11, loss: 0.3961102187179495, eval loss: 0.40826645493507385
Epoch: 12, loss: 0.3967497958151216, eval loss: 0.3726903796195984
Epoch: 13, loss: 0.3932820098212687, eval loss: 0.41417598724365234
Epoch: 14, loss: 0.3937164365494391, eval loss: 0.38356342911720276
Epoch: 15, loss: 0.39129059962418977, eval loss: 0.3942229151725769
Epoch: 16, loss: 0.39072566633054523, eval loss: 0.38864487409591675
Epoch: 17, loss: 0.38704087749356403, eval loss: 0.4368770718574524
Epoch: 18, loss: 0.3922138066915795, eval loss: 0.4118284583091736
Epoch: 19, loss: 0.38717518471064977, eval loss: 0.3851099908351898
Epoch: 20, loss: 0.3872496826818679, eval loss: 0.431057870388031
Epoch: 21, loss: 0.3877909561546403, eval loss: 0.4464757442474365
Epoch: 22, loss: 0.38456997930887155, eval loss: 0.4253610670566559
Epoch: 23, loss: 0.38562641461903696, eval loss: 0.4116967022418976
Epoch: 24, loss: 0.38411640779013395, eval loss: 0.421783983707428
Epoch: 25, loss: 0.3849601722107036, eval loss: 0.4207686185836792
Epoch: 26, loss: 0.38524345425314094, eval loss: 0.42622557282447815
Epoch: 27, loss: 0.3848587485999451, eval loss: 0.39149966835975647
Epoch: 28, loss: 0.3834993648053205, eval loss: 0.3997929096221924
Epoch: 29, loss: 0.3840473119987291, eval loss: 0.3847557604312897
Epoch: 30, loss: 0.3828711517371994, eval loss: 0.3932998478412628
Epoch: 31, loss: 0.3823374587480794, eval loss: 0.38712698221206665
Epoch: 32, loss: 0.385522029750864, eval loss: 0.43052563071250916
Epoch: 33, loss: 0.3818746983021265, eval loss: 0.4157777428627014
Epoch: 34, loss: 0.3828258135000942, eval loss: 0.3850526213645935
Epoch: 35, loss: 0.38144526700139975, eval loss: 0.3875163495540619
Epoch: 36, loss: 0.3806125033604985, eval loss: 0.38921770453453064
Epoch: 37, loss: 0.3813610937408521, eval loss: 0.3959731459617615
Epoch: 38, loss: 0.3821917968319758, eval loss: 0.41139721870422363
Epoch: 39, loss: 0.381492865071632, eval loss: 0.401525616645813
Epoch: 40, loss: 0.3816468359256578, eval loss: 0.3841073215007782
Epoch: 41, loss: 0.3826684470274631, eval loss: 0.3844490647315979
Epoch: 42, loss: 0.3829284590833686, eval loss: 0.38503944873809814
Epoch: 43, loss: 0.38482781599625016, eval loss: 0.39497315883636475
Epoch: 44, loss: 0.3827874219077057, eval loss: 0.39299312233924866
Epoch: 45, loss: 0.3834234489620576, eval loss: 0.40111690759658813
Epoch: 46, loss: 0.38163526384450963, eval loss: 0.3802638351917267
Epoch: 47, loss: 0.3828835005456698, eval loss: 0.3900584280490875
Epoch: 48, loss: 0.38219625129117046, eval loss: 0.3912724554538727
Epoch: 49, loss: 0.3835132266324945, eval loss: 0.39474567770957947

Runtime:607.75
KL div untrained: 50371380394.1514
KL div trained: 0.006
