Input args:
Dim: 2
seed: 48
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.8169200006173923, eval loss: 7.061954021453857
Epoch: 1, loss: 0.48621539992047474, eval loss: 0.45286673307418823
Epoch: 2, loss: 0.4568376108747907, eval loss: 0.4178486764431
Epoch: 3, loss: 0.44406025437038804, eval loss: 0.4050290584564209
Epoch: 4, loss: 0.4241416412775925, eval loss: 0.4770052134990692
Epoch: 5, loss: 0.4255705849803053, eval loss: 0.39500972628593445
Epoch: 6, loss: 0.4143383422464831, eval loss: 0.40116792917251587
Epoch: 7, loss: 0.4071830719732679, eval loss: 0.4554809033870697
Epoch: 8, loss: 0.4072664860321675, eval loss: 0.38327616453170776
Epoch: 9, loss: 0.40180426650185835, eval loss: 0.3378358781337738
Epoch: 10, loss: 0.3977594405907439, eval loss: 0.3859894871711731
Epoch: 11, loss: 0.3959426288027316, eval loss: 0.41175225377082825
Epoch: 12, loss: 0.39640135078923777, eval loss: 0.35594290494918823
Epoch: 13, loss: 0.39381010328739646, eval loss: 0.36686480045318604
Epoch: 14, loss: 0.39129587086848916, eval loss: 0.3662310242652893
Epoch: 15, loss: 0.3915667155734263, eval loss: 0.3436225652694702
Epoch: 16, loss: 0.39405430730315855, eval loss: 0.36976358294487
Epoch: 17, loss: 0.3915002371544688, eval loss: 0.36579862236976624
Epoch: 18, loss: 0.38707045482005925, eval loss: 0.361850380897522
Epoch: 19, loss: 0.388095707045577, eval loss: 0.38173750042915344
Epoch: 20, loss: 0.386109662054514, eval loss: 0.33101707696914673
Epoch: 21, loss: 0.3856447477289475, eval loss: 0.3494172990322113
Epoch: 22, loss: 0.3847921900896108, eval loss: 0.34679561853408813
Epoch: 23, loss: 0.38787186156812825, eval loss: 0.34332165122032166
Epoch: 24, loss: 0.3854593080765335, eval loss: 0.37845736742019653
Epoch: 25, loss: 0.3817202600033488, eval loss: 0.37247568368911743
Epoch: 26, loss: 0.38478057988279035, eval loss: 0.3459274470806122
Epoch: 27, loss: 0.38438503917448996, eval loss: 0.34143486618995667
Epoch: 28, loss: 0.38339611343224533, eval loss: 0.34081602096557617
Epoch: 29, loss: 0.38171793485220407, eval loss: 0.331340491771698
Epoch: 30, loss: 0.3840313172404649, eval loss: 0.37559059262275696
Epoch: 31, loss: 0.38330010929130365, eval loss: 0.3711206018924713
Epoch: 32, loss: 0.38356682696641653, eval loss: 0.35966479778289795
Epoch: 33, loss: 0.38357364774885355, eval loss: 0.33677756786346436
Epoch: 34, loss: 0.3831403221726214, eval loss: 0.3700500726699829
Epoch: 35, loss: 0.3828698523780622, eval loss: 0.34458595514297485
Epoch: 36, loss: 0.38428290438940166, eval loss: 0.3332294821739197
Epoch: 37, loss: 0.38292905741773436, eval loss: 0.3326026201248169
Epoch: 38, loss: 0.3832448403460148, eval loss: 0.33328625559806824
Epoch: 39, loss: 0.3848869640409248, eval loss: 0.36416035890579224
Epoch: 40, loss: 0.38518690645607423, eval loss: 0.3233253061771393
Epoch: 41, loss: 0.38312807665702164, eval loss: 0.34055063128471375
Epoch: 42, loss: 0.38559840561007147, eval loss: 0.3315370976924896
Epoch: 43, loss: 0.3844437109756167, eval loss: 0.3652195632457733
Epoch: 44, loss: 0.3838054330922023, eval loss: 0.3204481303691864
Epoch: 45, loss: 0.38460382406083227, eval loss: 0.3448399603366852
Epoch: 46, loss: 0.3857337991989334, eval loss: 0.33422818779945374
Epoch: 47, loss: 0.38508213242886996, eval loss: 0.34602394700050354
Epoch: 48, loss: 0.38522730520464393, eval loss: 0.35562559962272644
Epoch: 49, loss: 0.38654549481617323, eval loss: 0.3439581096172333

Runtime:712.18
KL div untrained: 1.1462936323636011e+23
KL div trained: 0.0263
