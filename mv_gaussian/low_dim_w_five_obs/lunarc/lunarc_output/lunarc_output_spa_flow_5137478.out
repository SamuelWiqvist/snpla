Input args:
Dim: 2
seed: 6
seed_data: 10
/home/samwiq/spa/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/spa/seq-posterior-approx-w-nf-dev
[1.0, 0.44932896411722156, 0.20189651799465538, 0.09071795328941247, 0.04076220397836621, 0.01831563888873418, 0.008229747049020023, 0.003697863716482929, 0.001661557273173934, 0.0007465858083766792]
start full training
Iteration: 1
optimizer_post_lr: [0.001]
prob_prior: 1.0
start update likelihood model
Epoch: 0, loss (training): 26.4197, loss (eval): 43.7012
Epoch: 1, loss (training): 20.0091, loss (eval): 22.1685
Epoch: 2, loss (training): 17.8889, loss (eval): 19.4466
Epoch: 3, loss (training): 16.6286, loss (eval): 17.8542
Epoch: 4, loss (training): 15.5412, loss (eval): 16.6507
Epoch: 5, loss (training): 14.5246, loss (eval): 15.5993
Epoch: 6, loss (training): 13.551, loss (eval): 14.3993
Epoch: 7, loss (training): 12.7877, loss (eval): 13.4592
Epoch: 8, loss (training): 12.2793, loss (eval): 12.8481
Epoch: 9, loss (training): 11.7107, loss (eval): 12.2133
Epoch: 10, loss (training): 11.3348, loss (eval): 11.7104
Epoch: 11, loss (training): 11.0656, loss (eval): 11.4431
Epoch: 12, loss (training): 10.8535, loss (eval): 11.2202
Epoch: 13, loss (training): 10.6978, loss (eval): 10.9686
Epoch: 14, loss (training): 10.5911, loss (eval): 10.8012
Epoch: 15, loss (training): 10.454, loss (eval): 10.728
Epoch: 16, loss (training): 10.4147, loss (eval): 10.7589
Epoch: 17, loss (training): 10.4394, loss (eval): 10.5861
Epoch: 18, loss (training): 10.3845, loss (eval): 10.7332
Epoch: 19, loss (training): 10.3296, loss (eval): 10.5739
Epoch: 20, loss (training): 10.4124, loss (eval): 10.7191
Epoch: 21, loss (training): 10.2976, loss (eval): 10.7195
Epoch: 22, loss (training): 10.2825, loss (eval): 10.5789
Epoch: 23, loss (training): 10.287, loss (eval): 10.5387
Epoch: 24, loss (training): 10.2529, loss (eval): 10.7641
start update posterior model from prior pred - hot start
Epoch: 0, loss (training): 3.8219, loss (eval): 7.0626
Epoch: 1, loss (training): 2.2152, loss (eval): 2.8934
Epoch: 2, loss (training): 1.5192, loss (eval): 1.8581
Epoch: 3, loss (training): 1.0859, loss (eval): 1.3699
Epoch: 4, loss (training): 0.9231, loss (eval): 1.1474
Epoch: 5, loss (training): 0.8267, loss (eval): 1.1228
Epoch: 6, loss (training): 0.809, loss (eval): 0.9366
Epoch: 7, loss (training): 0.6347, loss (eval): 0.7797
Epoch: 8, loss (training): 0.5774, loss (eval): 0.982
Epoch: 9, loss (training): 0.7773, loss (eval): 0.8036
start update posterior model
Epoch: 0, loss (training): 19.0394, loss (eval): 21.6427
Epoch: 1, loss (training): 18.7162, loss (eval): 18.6702
Epoch: 2, loss (training): 18.7365, loss (eval): 18.7157
Epoch: 3, loss (training): 18.7248, loss (eval): 18.7688
Epoch: 4, loss (training): 18.7183, loss (eval): 18.668
Epoch: 5, loss (training): 18.7028, loss (eval): 18.7009
Epoch: 6, loss (training): 18.715, loss (eval): 18.6826
Epoch: 7, loss (training): 18.7135, loss (eval): 18.7248
Epoch: 8, loss (training): 18.7704, loss (eval): 18.6994
Epoch: 9, loss (training): 18.692, loss (eval): 18.6753
Epoch: 10, loss (training): 18.7014, loss (eval): 18.7315
Epoch: 11, loss (training): 18.7113, loss (eval): 18.6673
Epoch: 12, loss (training): 18.7165, loss (eval): 18.6739
Epoch: 13, loss (training): 18.7183, loss (eval): 18.6658
Epoch: 14, loss (training): 18.7165, loss (eval): 18.704
Epoch: 15, loss (training): 18.7353, loss (eval): 18.7237
Epoch: 16, loss (training): 18.6996, loss (eval): 18.6684
Epoch: 17, loss (training): 18.7068, loss (eval): 18.6921
Epoch: 18, loss (training): 18.7301, loss (eval): 18.684
Epoch: 19, loss (training): 18.7117, loss (eval): 18.8877
Epoch: 20, loss (training): 18.7044, loss (eval): 18.7167
Epoch: 21, loss (training): 18.6958, loss (eval): 18.7248
Epoch: 22, loss (training): 18.7029, loss (eval): 18.683
Epoch: 23, loss (training): 18.7115, loss (eval): 18.7161
Epoch: 24, loss (training): 18.6904, loss (eval): 18.675
Iteration: 2
optimizer_post_lr: [0.001]
prob_prior: 0.44932896411722156
start update likelihood model
Epoch: 0, loss (training): 10.4389, loss (eval): 10.5014
Epoch: 1, loss (training): 10.4482, loss (eval): 10.416
Epoch: 2, loss (training): 10.3672, loss (eval): 10.4107
Epoch: 3, loss (training): 10.2, loss (eval): 10.2837
Epoch: 4, loss (training): 10.2808, loss (eval): 10.1363
Epoch: 5, loss (training): 10.2701, loss (eval): 10.3145
Epoch: 6, loss (training): 10.2925, loss (eval): 10.3024
Epoch: 7, loss (training): 10.2014, loss (eval): 10.1859
Epoch: 8, loss (training): 10.1704, loss (eval): 10.3047
Epoch: 9, loss (training): 10.2337, loss (eval): 10.2005
Epoch: 10, loss (training): 10.1726, loss (eval): 10.2581
Epoch: 11, loss (training): 10.1689, loss (eval): 10.1864
Epoch: 12, loss (training): 10.171, loss (eval): 10.1633
Epoch: 13, loss (training): 10.1661, loss (eval): 10.1959
Epoch: 14, loss (training): 10.1952, loss (eval): 10.3819
Epoch: 15, loss (training): 10.1149, loss (eval): 10.2158
Epoch: 16, loss (training): 10.1956, loss (eval): 10.2261
Epoch: 17, loss (training): 10.1662, loss (eval): 10.3332
Epoch: 18, loss (training): 10.2569, loss (eval): 10.4946
Epoch: 19, loss (training): 10.1396, loss (eval): 10.24
Epoch: 20, loss (training): 10.1118, loss (eval): 10.2472
Epoch: 21, loss (training): 10.1478, loss (eval): 10.1789
Epoch: 22, loss (training): 10.1387, loss (eval): 10.2744
Epoch: 23, loss (training): 10.1954, loss (eval): 10.3242
Early-stopping. Training converged after 24 epochs.
start update posterior model
Epoch: 0, loss (training): 19.4077, loss (eval): 21.1336
Epoch: 1, loss (training): 19.3614, loss (eval): 19.4416
Epoch: 2, loss (training): 19.3726, loss (eval): 19.3488
Epoch: 3, loss (training): 19.3536, loss (eval): 19.3369
Epoch: 4, loss (training): 19.3678, loss (eval): 19.3255
Epoch: 5, loss (training): 19.3536, loss (eval): 19.3536
Epoch: 6, loss (training): 19.3496, loss (eval): 19.3858
Epoch: 7, loss (training): 19.3631, loss (eval): 19.38
Epoch: 8, loss (training): 19.3608, loss (eval): 19.3276
Epoch: 9, loss (training): 19.3574, loss (eval): 19.3319
Epoch: 10, loss (training): 19.367, loss (eval): 19.3364
Epoch: 11, loss (training): 19.3702, loss (eval): 19.3231
Epoch: 12, loss (training): 19.3713, loss (eval): 19.3435
Epoch: 13, loss (training): 19.3667, loss (eval): 19.4162
Epoch: 14, loss (training): 19.3444, loss (eval): 19.349
Epoch: 15, loss (training): 19.3521, loss (eval): 19.3342
Epoch: 16, loss (training): 19.3616, loss (eval): 19.3502
Epoch: 17, loss (training): 19.3674, loss (eval): 19.3432
Epoch: 18, loss (training): 19.3598, loss (eval): 19.3409
Epoch: 19, loss (training): 19.3637, loss (eval): 19.3364
Epoch: 20, loss (training): 19.3572, loss (eval): 19.3608
Epoch: 21, loss (training): 19.3648, loss (eval): 19.3451
Epoch: 22, loss (training): 19.3535, loss (eval): 19.3757
Epoch: 23, loss (training): 19.3594, loss (eval): 19.3475
Epoch: 24, loss (training): 19.3562, loss (eval): 19.3438
Iteration: 3
optimizer_post_lr: [0.001]
prob_prior: 0.20189651799465538
start update likelihood model
Epoch: 0, loss (training): 10.3602, loss (eval): 10.3938
Epoch: 1, loss (training): 10.2904, loss (eval): 10.1363
Epoch: 2, loss (training): 10.2862, loss (eval): 10.2235
Epoch: 3, loss (training): 10.2276, loss (eval): 10.0623
Epoch: 4, loss (training): 10.1888, loss (eval): 10.1398
Epoch: 5, loss (training): 10.1998, loss (eval): 10.2966
Epoch: 6, loss (training): 10.2114, loss (eval): 10.1923
Epoch: 7, loss (training): 10.1641, loss (eval): 10.1068
Epoch: 8, loss (training): 10.1465, loss (eval): 10.1915
Epoch: 9, loss (training): 10.1623, loss (eval): 10.089
Epoch: 10, loss (training): 10.1802, loss (eval): 10.0468
Epoch: 11, loss (training): 10.1876, loss (eval): 10.1288
Epoch: 12, loss (training): 10.2196, loss (eval): 10.077
Epoch: 13, loss (training): 10.1488, loss (eval): 10.1766
Epoch: 14, loss (training): 10.1513, loss (eval): 10.1515
Epoch: 15, loss (training): 10.1352, loss (eval): 10.1157
Epoch: 16, loss (training): 10.1672, loss (eval): 10.2246
Epoch: 17, loss (training): 10.2034, loss (eval): 10.0635
Epoch: 18, loss (training): 10.1638, loss (eval): 10.1873
Epoch: 19, loss (training): 10.1539, loss (eval): 10.1325
Epoch: 20, loss (training): 10.1293, loss (eval): 10.0855
Epoch: 21, loss (training): 10.1382, loss (eval): 10.1832
Epoch: 22, loss (training): 10.1452, loss (eval): 10.1365
Epoch: 23, loss (training): 10.137, loss (eval): 10.0687
Epoch: 24, loss (training): 10.109, loss (eval): 10.1339
start update posterior model
Epoch: 0, loss (training): 18.7462, loss (eval): 19.2245
Epoch: 1, loss (training): 18.7378, loss (eval): 18.7132
Epoch: 2, loss (training): 18.7333, loss (eval): 18.7115
Epoch: 3, loss (training): 18.7279, loss (eval): 18.7084
Epoch: 4, loss (training): 18.7211, loss (eval): 18.7156
Epoch: 5, loss (training): 18.7321, loss (eval): 18.7195
Epoch: 6, loss (training): 18.7322, loss (eval): 18.7673
Epoch: 7, loss (training): 18.7325, loss (eval): 18.7164
Epoch: 8, loss (training): 18.7343, loss (eval): 18.7342
Epoch: 9, loss (training): 18.7329, loss (eval): 18.7698
Epoch: 10, loss (training): 18.7354, loss (eval): 18.7336
Epoch: 11, loss (training): 18.7217, loss (eval): 18.7196
Epoch: 12, loss (training): 18.7395, loss (eval): 18.7179
Epoch: 13, loss (training): 18.7325, loss (eval): 18.7783
Epoch: 14, loss (training): 18.7301, loss (eval): 18.7213
Epoch: 15, loss (training): 18.7282, loss (eval): 18.7483
Epoch: 16, loss (training): 18.7245, loss (eval): 18.7042
Epoch: 17, loss (training): 18.7271, loss (eval): 18.7641
Epoch: 18, loss (training): 18.7323, loss (eval): 18.723
Epoch: 19, loss (training): 18.7241, loss (eval): 18.7243
Epoch: 20, loss (training): 18.7328, loss (eval): 18.7435
Epoch: 21, loss (training): 18.7295, loss (eval): 18.7212
Epoch: 22, loss (training): 18.7269, loss (eval): 18.7337
Epoch: 23, loss (training): 18.726, loss (eval): 18.789
Epoch: 24, loss (training): 18.7331, loss (eval): 18.7556
Iteration: 4
optimizer_post_lr: [0.001]
prob_prior: 0.09071795328941247
start update likelihood model
Epoch: 0, loss (training): 10.2203, loss (eval): 10.1184
Epoch: 1, loss (training): 10.1665, loss (eval): 10.0804
Epoch: 2, loss (training): 10.1778, loss (eval): 10.0756
Epoch: 3, loss (training): 10.209, loss (eval): 10.0383
Epoch: 4, loss (training): 10.1339, loss (eval): 10.1681
Epoch: 5, loss (training): 10.1722, loss (eval): 10.1863
Epoch: 6, loss (training): 10.1577, loss (eval): 10.1437
Epoch: 7, loss (training): 10.1458, loss (eval): 10.1926
Epoch: 8, loss (training): 10.1356, loss (eval): 10.1886
Epoch: 9, loss (training): 10.1508, loss (eval): 10.2348
Epoch: 10, loss (training): 10.1116, loss (eval): 10.0714
Epoch: 11, loss (training): 10.0846, loss (eval): 10.0878
Epoch: 12, loss (training): 10.1045, loss (eval): 10.1089
Epoch: 13, loss (training): 10.1188, loss (eval): 10.2797
Epoch: 14, loss (training): 10.1231, loss (eval): 10.1394
Epoch: 15, loss (training): 10.0997, loss (eval): 10.0866
Epoch: 16, loss (training): 10.0992, loss (eval): 10.2366
Epoch: 17, loss (training): 10.0669, loss (eval): 10.0673
Epoch: 18, loss (training): 10.1081, loss (eval): 10.0984
Epoch: 19, loss (training): 10.111, loss (eval): 10.1934
Epoch: 20, loss (training): 10.0413, loss (eval): 10.037
Epoch: 21, loss (training): 10.0718, loss (eval): 10.2371
Epoch: 22, loss (training): 10.0339, loss (eval): 10.0745
Epoch: 23, loss (training): 10.1003, loss (eval): 10.1627
Epoch: 24, loss (training): 10.0216, loss (eval): 10.1526
start update posterior model
Epoch: 0, loss (training): 18.6985, loss (eval): 18.7139
Epoch: 1, loss (training): 18.7092, loss (eval): 18.6746
Epoch: 2, loss (training): 18.69, loss (eval): 18.7348
Epoch: 3, loss (training): 18.6938, loss (eval): 18.6723
Epoch: 4, loss (training): 18.6937, loss (eval): 18.6853
Epoch: 5, loss (training): 18.6889, loss (eval): 18.6693
Epoch: 6, loss (training): 18.6871, loss (eval): 18.6771
Epoch: 7, loss (training): 18.6906, loss (eval): 18.6768
Epoch: 8, loss (training): 18.7055, loss (eval): 18.6866
Epoch: 9, loss (training): 18.6999, loss (eval): 18.6909
Epoch: 10, loss (training): 18.6912, loss (eval): 18.6684
Epoch: 11, loss (training): 18.6895, loss (eval): 18.6757
Epoch: 12, loss (training): 18.6922, loss (eval): 18.7125
Epoch: 13, loss (training): 18.6914, loss (eval): 18.8066
Epoch: 14, loss (training): 18.693, loss (eval): 18.6812
Epoch: 15, loss (training): 18.6833, loss (eval): 18.7291
Epoch: 16, loss (training): 18.6874, loss (eval): 18.669
Epoch: 17, loss (training): 18.7037, loss (eval): 18.7194
Epoch: 18, loss (training): 18.7, loss (eval): 18.725
Epoch: 19, loss (training): 18.6892, loss (eval): 18.692
Epoch: 20, loss (training): 18.6922, loss (eval): 18.6703
Epoch: 21, loss (training): 18.6864, loss (eval): 18.6644
Epoch: 22, loss (training): 18.6816, loss (eval): 18.6777
Epoch: 23, loss (training): 18.6872, loss (eval): 18.7448
Epoch: 24, loss (training): 18.6864, loss (eval): 18.6757
Iteration: 5
optimizer_post_lr: [0.001]
prob_prior: 0.04076220397836621
start update likelihood model
Epoch: 0, loss (training): 10.1695, loss (eval): 9.8676
Epoch: 1, loss (training): 10.099, loss (eval): 10.0778
Epoch: 2, loss (training): 10.1035, loss (eval): 9.9011
Epoch: 3, loss (training): 10.0516, loss (eval): 9.9084
Epoch: 4, loss (training): 10.0751, loss (eval): 9.9314
Epoch: 5, loss (training): 10.0793, loss (eval): 9.9188
Epoch: 6, loss (training): 10.0776, loss (eval): 9.8838
Epoch: 7, loss (training): 10.0428, loss (eval): 9.8717
Epoch: 8, loss (training): 10.0327, loss (eval): 9.8747
Epoch: 9, loss (training): 10.0333, loss (eval): 9.9467
Epoch: 10, loss (training): 10.1197, loss (eval): 9.8832
Epoch: 11, loss (training): 10.0178, loss (eval): 9.9336
Epoch: 12, loss (training): 10.0523, loss (eval): 9.8735
Epoch: 13, loss (training): 10.0328, loss (eval): 9.9492
Epoch: 14, loss (training): 10.0146, loss (eval): 9.9955
Epoch: 15, loss (training): 10.0073, loss (eval): 10.021
Epoch: 16, loss (training): 10.0333, loss (eval): 9.9225
Epoch: 17, loss (training): 10.024, loss (eval): 9.8678
Epoch: 18, loss (training): 9.9979, loss (eval): 9.9124
Epoch: 19, loss (training): 10.0454, loss (eval): 9.95
Early-stopping. Training converged after 20 epochs.
start update posterior model
Epoch: 0, loss (training): 18.5097, loss (eval): 18.5819
Epoch: 1, loss (training): 18.5125, loss (eval): 18.4986
Epoch: 2, loss (training): 18.5127, loss (eval): 18.5074
Epoch: 3, loss (training): 18.5092, loss (eval): 18.4978
Epoch: 4, loss (training): 18.5123, loss (eval): 18.556
Epoch: 5, loss (training): 18.5204, loss (eval): 18.5061
Epoch: 6, loss (training): 18.5117, loss (eval): 18.5092
Epoch: 7, loss (training): 18.5007, loss (eval): 18.4899
Epoch: 8, loss (training): 18.5079, loss (eval): 18.5033
Epoch: 9, loss (training): 18.5137, loss (eval): 18.4922
Epoch: 10, loss (training): 18.5081, loss (eval): 18.5327
Epoch: 11, loss (training): 18.5185, loss (eval): 18.4903
Epoch: 12, loss (training): 18.5139, loss (eval): 18.4865
Epoch: 13, loss (training): 18.5165, loss (eval): 18.4907
Epoch: 14, loss (training): 18.5217, loss (eval): 18.5142
Epoch: 15, loss (training): 18.5035, loss (eval): 18.5006
Epoch: 16, loss (training): 18.5059, loss (eval): 18.5042
Epoch: 17, loss (training): 18.5129, loss (eval): 18.493
Epoch: 18, loss (training): 18.5193, loss (eval): 18.5039
Epoch: 19, loss (training): 18.511, loss (eval): 18.5169
Epoch: 20, loss (training): 18.5166, loss (eval): 18.5132
Epoch: 21, loss (training): 18.5042, loss (eval): 18.4919
Epoch: 22, loss (training): 18.5259, loss (eval): 18.4947
Epoch: 23, loss (training): 18.527, loss (eval): 18.4893
Epoch: 24, loss (training): 18.511, loss (eval): 18.4924
Iteration: 6
optimizer_post_lr: [0.001]
prob_prior: 0.01831563888873418
start update likelihood model
Epoch: 0, loss (training): 10.2626, loss (eval): 10.2731
Epoch: 1, loss (training): 10.189, loss (eval): 10.2417
Epoch: 2, loss (training): 10.1662, loss (eval): 10.2693
Epoch: 3, loss (training): 10.1814, loss (eval): 10.239
Epoch: 4, loss (training): 10.1587, loss (eval): 10.1533
Epoch: 5, loss (training): 10.1506, loss (eval): 10.1877
Epoch: 6, loss (training): 10.1544, loss (eval): 10.4414
Epoch: 7, loss (training): 10.1154, loss (eval): 10.2323
Epoch: 8, loss (training): 10.12, loss (eval): 10.1576
Epoch: 9, loss (training): 10.1746, loss (eval): 10.4135
Epoch: 10, loss (training): 10.1864, loss (eval): 10.2928
Epoch: 11, loss (training): 10.1073, loss (eval): 10.3302
Epoch: 12, loss (training): 10.142, loss (eval): 10.2551
Epoch: 13, loss (training): 10.1283, loss (eval): 10.1812
Epoch: 14, loss (training): 10.1749, loss (eval): 10.1612
Epoch: 15, loss (training): 10.1188, loss (eval): 10.2679
Epoch: 16, loss (training): 10.1072, loss (eval): 10.2615
Epoch: 17, loss (training): 10.1101, loss (eval): 10.2441
Epoch: 18, loss (training): 10.1322, loss (eval): 10.2401
Epoch: 19, loss (training): 10.0722, loss (eval): 10.2197
Epoch: 20, loss (training): 10.1228, loss (eval): 10.3269
Epoch: 21, loss (training): 10.1043, loss (eval): 10.2994
Epoch: 22, loss (training): 10.1392, loss (eval): 10.2607
Epoch: 23, loss (training): 10.1092, loss (eval): 10.3025
Early-stopping. Training converged after 24 epochs.
start update posterior model
Epoch: 0, loss (training): 18.6945, loss (eval): 18.7533
Epoch: 1, loss (training): 18.6861, loss (eval): 18.6773
Epoch: 2, loss (training): 18.6971, loss (eval): 18.6703
Epoch: 3, loss (training): 18.6915, loss (eval): 18.6978
Epoch: 4, loss (training): 18.6929, loss (eval): 18.6986
Epoch: 5, loss (training): 18.6943, loss (eval): 18.6774
Epoch: 6, loss (training): 18.6953, loss (eval): 18.6991
Epoch: 7, loss (training): 18.686, loss (eval): 18.6883
Epoch: 8, loss (training): 18.6925, loss (eval): 18.6891
Epoch: 9, loss (training): 18.6924, loss (eval): 18.6704
Epoch: 10, loss (training): 18.6903, loss (eval): 18.6741
Epoch: 11, loss (training): 18.6827, loss (eval): 18.6745
Epoch: 12, loss (training): 18.6915, loss (eval): 18.6868
Epoch: 13, loss (training): 18.6907, loss (eval): 18.7501
Epoch: 14, loss (training): 18.6968, loss (eval): 18.6899
Epoch: 15, loss (training): 18.6912, loss (eval): 18.6923
Epoch: 16, loss (training): 18.6932, loss (eval): 18.6737
Epoch: 17, loss (training): 18.6956, loss (eval): 18.6692
Epoch: 18, loss (training): 18.6835, loss (eval): 18.7192
Epoch: 19, loss (training): 18.6885, loss (eval): 18.745
Epoch: 20, loss (training): 18.6948, loss (eval): 18.6733
Epoch: 21, loss (training): 18.6933, loss (eval): 18.6816
Epoch: 22, loss (training): 18.6857, loss (eval): 18.6787
Epoch: 23, loss (training): 18.6893, loss (eval): 18.6767
Epoch: 24, loss (training): 18.6968, loss (eval): 18.719
Iteration: 7
optimizer_post_lr: [0.001]
prob_prior: 0.008229747049020023
start update likelihood model
Epoch: 0, loss (training): 10.1855, loss (eval): 10.0644
Epoch: 1, loss (training): 10.1483, loss (eval): 10.0014
Epoch: 2, loss (training): 10.1346, loss (eval): 9.9959
Epoch: 3, loss (training): 10.1056, loss (eval): 9.9577
Epoch: 4, loss (training): 10.1426, loss (eval): 9.9844
Epoch: 5, loss (training): 10.1067, loss (eval): 10.1193
Epoch: 6, loss (training): 10.077, loss (eval): 9.9256
Epoch: 7, loss (training): 10.1065, loss (eval): 9.9688
Epoch: 8, loss (training): 10.0586, loss (eval): 10.0912
Epoch: 9, loss (training): 10.1091, loss (eval): 9.9711
Epoch: 10, loss (training): 10.151, loss (eval): 9.9909
Epoch: 11, loss (training): 10.0968, loss (eval): 10.0002
Epoch: 12, loss (training): 10.0775, loss (eval): 10.0626
Epoch: 13, loss (training): 10.0676, loss (eval): 10.0232
Epoch: 14, loss (training): 10.0536, loss (eval): 9.9593
Epoch: 15, loss (training): 10.0654, loss (eval): 10.0959
Epoch: 16, loss (training): 10.0769, loss (eval): 10.0556
Epoch: 17, loss (training): 10.0614, loss (eval): 10.0194
Epoch: 18, loss (training): 10.0601, loss (eval): 9.9714
Epoch: 19, loss (training): 10.0866, loss (eval): 10.034
Epoch: 20, loss (training): 10.0538, loss (eval): 10.0672
Epoch: 21, loss (training): 10.054, loss (eval): 10.1535
Epoch: 22, loss (training): 10.0788, loss (eval): 10.1447
Epoch: 23, loss (training): 10.0474, loss (eval): 10.1102
Epoch: 24, loss (training): 10.0617, loss (eval): 10.0122
start update posterior model
Epoch: 0, loss (training): 19.7047, loss (eval): 19.7389
Epoch: 1, loss (training): 19.7076, loss (eval): 19.6973
Epoch: 2, loss (training): 19.7051, loss (eval): 19.7099
Epoch: 3, loss (training): 19.6959, loss (eval): 19.6832
Epoch: 4, loss (training): 19.7003, loss (eval): 19.6908
Epoch: 5, loss (training): 19.6982, loss (eval): 19.7196
Epoch: 6, loss (training): 19.7034, loss (eval): 19.8462
Epoch: 7, loss (training): 19.7037, loss (eval): 19.6972
Epoch: 8, loss (training): 19.7098, loss (eval): 19.6967
Epoch: 9, loss (training): 19.7016, loss (eval): 19.7015
Epoch: 10, loss (training): 19.7021, loss (eval): 19.7113
Epoch: 11, loss (training): 19.6969, loss (eval): 19.6829
Epoch: 12, loss (training): 19.7108, loss (eval): 19.6959
Epoch: 13, loss (training): 19.7077, loss (eval): 19.727
Epoch: 14, loss (training): 19.7023, loss (eval): 19.6946
Epoch: 15, loss (training): 19.7, loss (eval): 19.6915
Epoch: 16, loss (training): 19.7052, loss (eval): 19.7018
Epoch: 17, loss (training): 19.7063, loss (eval): 19.6835
Epoch: 18, loss (training): 19.7048, loss (eval): 19.7126
Epoch: 19, loss (training): 19.7031, loss (eval): 19.7453
Epoch: 20, loss (training): 19.7077, loss (eval): 19.7328
Epoch: 21, loss (training): 19.7023, loss (eval): 19.6959
Epoch: 22, loss (training): 19.7126, loss (eval): 19.7707
Epoch: 23, loss (training): 19.6999, loss (eval): 19.6863
Epoch: 24, loss (training): 19.7117, loss (eval): 19.7223
Iteration: 8
optimizer_post_lr: [0.001]
prob_prior: 0.003697863716482929
start update likelihood model
Epoch: 0, loss (training): 10.2333, loss (eval): 10.3523
Epoch: 1, loss (training): 10.1709, loss (eval): 10.1741
Epoch: 2, loss (training): 10.1459, loss (eval): 10.1974
Epoch: 3, loss (training): 10.143, loss (eval): 10.249
Epoch: 4, loss (training): 10.146, loss (eval): 10.2455
Epoch: 5, loss (training): 10.0948, loss (eval): 10.1232
Epoch: 6, loss (training): 10.1206, loss (eval): 10.2237
Epoch: 7, loss (training): 10.1702, loss (eval): 10.3628
Epoch: 8, loss (training): 10.1345, loss (eval): 10.1819
Epoch: 9, loss (training): 10.0968, loss (eval): 10.2583
Epoch: 10, loss (training): 10.1046, loss (eval): 10.1624
Epoch: 11, loss (training): 10.1273, loss (eval): 10.2464
Epoch: 12, loss (training): 10.1229, loss (eval): 10.3081
Epoch: 13, loss (training): 10.0996, loss (eval): 10.2756
Epoch: 14, loss (training): 10.117, loss (eval): 10.164
Epoch: 15, loss (training): 10.1098, loss (eval): 10.2557
Epoch: 16, loss (training): 10.1195, loss (eval): 10.2072
Epoch: 17, loss (training): 10.1367, loss (eval): 10.267
Epoch: 18, loss (training): 10.1027, loss (eval): 10.3629
Epoch: 19, loss (training): 10.1222, loss (eval): 10.2457
Epoch: 20, loss (training): 10.0846, loss (eval): 10.2247
Epoch: 21, loss (training): 10.1006, loss (eval): 10.244
Epoch: 22, loss (training): 10.134, loss (eval): 10.2888
Epoch: 23, loss (training): 10.0844, loss (eval): 10.2378
Epoch: 24, loss (training): 10.1045, loss (eval): 10.3034
start update posterior model
Epoch: 0, loss (training): 18.6117, loss (eval): 18.6763
Epoch: 1, loss (training): 18.6014, loss (eval): 18.5928
Epoch: 2, loss (training): 18.6099, loss (eval): 18.6231
Epoch: 3, loss (training): 18.6084, loss (eval): 18.6138
Epoch: 4, loss (training): 18.6099, loss (eval): 18.6217
Epoch: 5, loss (training): 18.6066, loss (eval): 18.6003
Epoch: 6, loss (training): 18.6019, loss (eval): 18.6115
Epoch: 7, loss (training): 18.6089, loss (eval): 18.6213
Epoch: 8, loss (training): 18.6069, loss (eval): 18.5928
Epoch: 9, loss (training): 18.6028, loss (eval): 18.5918
Epoch: 10, loss (training): 18.5999, loss (eval): 18.612
Epoch: 11, loss (training): 18.6098, loss (eval): 18.5929
Epoch: 12, loss (training): 18.604, loss (eval): 18.5968
Epoch: 13, loss (training): 18.6079, loss (eval): 18.5986
Epoch: 14, loss (training): 18.6041, loss (eval): 18.5945
Epoch: 15, loss (training): 18.612, loss (eval): 18.6022
Epoch: 16, loss (training): 18.6027, loss (eval): 18.5962
Epoch: 17, loss (training): 18.6117, loss (eval): 18.6084
Epoch: 18, loss (training): 18.6037, loss (eval): 18.5892
Epoch: 19, loss (training): 18.6006, loss (eval): 18.5945
Epoch: 20, loss (training): 18.6024, loss (eval): 18.634
Epoch: 21, loss (training): 18.6071, loss (eval): 18.5841
Epoch: 22, loss (training): 18.6052, loss (eval): 18.5955
Epoch: 23, loss (training): 18.6044, loss (eval): 18.5898
Epoch: 24, loss (training): 18.6052, loss (eval): 18.6222
Iteration: 9
optimizer_post_lr: [0.001]
prob_prior: 0.001661557273173934
start update likelihood model
Epoch: 0, loss (training): 10.097, loss (eval): 10.0959
Epoch: 1, loss (training): 10.0777, loss (eval): 10.0946
Epoch: 2, loss (training): 10.0959, loss (eval): 10.057
Epoch: 3, loss (training): 10.0319, loss (eval): 10.056
Epoch: 4, loss (training): 10.0735, loss (eval): 10.0219
Epoch: 5, loss (training): 10.1048, loss (eval): 10.1738
Epoch: 6, loss (training): 10.0426, loss (eval): 10.1619
Epoch: 7, loss (training): 10.0255, loss (eval): 10.0623
Epoch: 8, loss (training): 10.0463, loss (eval): 10.0711
Epoch: 9, loss (training): 10.0571, loss (eval): 10.1413
Epoch: 10, loss (training): 10.0637, loss (eval): 10.0833
Epoch: 11, loss (training): 10.042, loss (eval): 10.0436
Epoch: 12, loss (training): 10.0582, loss (eval): 10.0818
Epoch: 13, loss (training): 9.9962, loss (eval): 10.1098
Epoch: 14, loss (training): 10.0286, loss (eval): 10.1789
Epoch: 15, loss (training): 10.0319, loss (eval): 10.1008
Epoch: 16, loss (training): 10.0277, loss (eval): 10.0945
Epoch: 17, loss (training): 10.018, loss (eval): 10.1039
Epoch: 18, loss (training): 10.0193, loss (eval): 10.037
Epoch: 19, loss (training): 10.007, loss (eval): 10.0617
Epoch: 20, loss (training): 9.9951, loss (eval): 10.0623
Epoch: 21, loss (training): 10.0219, loss (eval): 10.0537
Epoch: 22, loss (training): 10.005, loss (eval): 10.0506
Epoch: 23, loss (training): 9.9946, loss (eval): 10.0393
Early-stopping. Training converged after 24 epochs.
start update posterior model
Epoch: 0, loss (training): 17.8484, loss (eval): 18.0017
Epoch: 1, loss (training): 17.849, loss (eval): 17.8309
Epoch: 2, loss (training): 17.8357, loss (eval): 17.8394
Epoch: 3, loss (training): 17.8434, loss (eval): 17.8282
Epoch: 4, loss (training): 17.839, loss (eval): 17.8316
Epoch: 5, loss (training): 17.8398, loss (eval): 17.8181
Epoch: 6, loss (training): 17.8414, loss (eval): 17.8864
Epoch: 7, loss (training): 17.846, loss (eval): 17.8301
Epoch: 8, loss (training): 17.8355, loss (eval): 17.8293
Epoch: 9, loss (training): 17.8441, loss (eval): 17.855
Epoch: 10, loss (training): 17.8358, loss (eval): 17.8237
Epoch: 11, loss (training): 17.8404, loss (eval): 17.8312
Epoch: 12, loss (training): 17.8402, loss (eval): 17.8293
Epoch: 13, loss (training): 17.8435, loss (eval): 17.8262
Epoch: 14, loss (training): 17.837, loss (eval): 17.8291
Epoch: 15, loss (training): 17.8365, loss (eval): 17.8258
Epoch: 16, loss (training): 17.841, loss (eval): 17.8726
Epoch: 17, loss (training): 17.8403, loss (eval): 17.8393
Epoch: 18, loss (training): 17.8364, loss (eval): 17.825
Epoch: 19, loss (training): 17.8359, loss (eval): 17.8228
Epoch: 20, loss (training): 17.8349, loss (eval): 17.8962
Epoch: 21, loss (training): 17.8341, loss (eval): 17.8317
Epoch: 22, loss (training): 17.8464, loss (eval): 17.9261
Epoch: 23, loss (training): 17.8371, loss (eval): 17.8327
Epoch: 24, loss (training): 17.8434, loss (eval): 17.9405
Iteration: 10
optimizer_post_lr: [0.001]
prob_prior: 0.0007465858083766792
start update likelihood model
Epoch: 0, loss (training): 10.1502, loss (eval): 10.2481
Epoch: 1, loss (training): 10.1362, loss (eval): 10.2668
Epoch: 2, loss (training): 10.115, loss (eval): 10.2535
Epoch: 3, loss (training): 10.1006, loss (eval): 10.2947
Epoch: 4, loss (training): 10.0749, loss (eval): 10.2729
Epoch: 5, loss (training): 10.088, loss (eval): 10.2367
Epoch: 6, loss (training): 10.0667, loss (eval): 10.2315
Epoch: 7, loss (training): 10.0972, loss (eval): 10.2782
Epoch: 8, loss (training): 10.0618, loss (eval): 10.2245
Epoch: 9, loss (training): 10.033, loss (eval): 10.2188
Epoch: 10, loss (training): 10.0222, loss (eval): 10.2596
Epoch: 11, loss (training): 10.0424, loss (eval): 10.2425
Epoch: 12, loss (training): 10.0714, loss (eval): 10.2063
Epoch: 13, loss (training): 10.0789, loss (eval): 10.3348
Epoch: 14, loss (training): 10.0911, loss (eval): 10.3604
Epoch: 15, loss (training): 10.0373, loss (eval): 10.3447
Epoch: 16, loss (training): 10.0587, loss (eval): 10.268
Epoch: 17, loss (training): 10.0728, loss (eval): 10.2517
Epoch: 18, loss (training): 10.0554, loss (eval): 10.294
Epoch: 19, loss (training): 10.062, loss (eval): 10.2285
Epoch: 20, loss (training): 10.0364, loss (eval): 10.3275
Epoch: 21, loss (training): 10.0425, loss (eval): 10.252
Epoch: 22, loss (training): 10.0371, loss (eval): 10.2522
Epoch: 23, loss (training): 10.0249, loss (eval): 10.1566
Epoch: 24, loss (training): 10.0283, loss (eval): 10.1877
start update posterior model
Epoch: 0, loss (training): 18.6892, loss (eval): 18.7124
Epoch: 1, loss (training): 18.6888, loss (eval): 18.6934
Epoch: 2, loss (training): 18.697, loss (eval): 18.6761
Epoch: 3, loss (training): 18.6929, loss (eval): 18.7416
Epoch: 4, loss (training): 18.6902, loss (eval): 18.7185
Epoch: 5, loss (training): 18.6922, loss (eval): 18.7073
Epoch: 6, loss (training): 18.694, loss (eval): 18.693
Epoch: 7, loss (training): 18.6969, loss (eval): 18.6877
Epoch: 8, loss (training): 18.6896, loss (eval): 18.7208
Epoch: 9, loss (training): 18.6868, loss (eval): 18.7032
Epoch: 10, loss (training): 18.6935, loss (eval): 18.6872
Epoch: 11, loss (training): 18.6967, loss (eval): 18.6991
Epoch: 12, loss (training): 18.6922, loss (eval): 18.705
Epoch: 13, loss (training): 18.6871, loss (eval): 18.6996
Epoch: 14, loss (training): 18.6936, loss (eval): 18.6899
Epoch: 15, loss (training): 18.6969, loss (eval): 18.6944
Epoch: 16, loss (training): 18.6941, loss (eval): 18.714
Epoch: 17, loss (training): 18.6893, loss (eval): 18.6852
Epoch: 18, loss (training): 18.6908, loss (eval): 18.687
Epoch: 19, loss (training): 18.6994, loss (eval): 18.6846
Epoch: 20, loss (training): 18.6939, loss (eval): 18.6878
Epoch: 21, loss (training): 18.6874, loss (eval): 18.6918
Early-stopping. Training converged after 22 epochs.

Runtime:992.25
0
1
2
3
4
5
6
7
8
9
