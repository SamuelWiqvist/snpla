Input args:
Dim: 2
seed: 8
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.8019723876193166, eval loss: 7.014806747436523
Epoch: 1, loss: 0.4934884193423204, eval loss: 0.46619102358818054
Epoch: 2, loss: 0.45724300370085985, eval loss: 0.5990198254585266
Epoch: 3, loss: 0.44023388186004014, eval loss: 0.40657946467399597
Epoch: 4, loss: 0.4242743583433912, eval loss: 0.4039960205554962
Epoch: 5, loss: 0.42146575622959065, eval loss: 0.4186404347419739
Epoch: 6, loss: 0.4121306696161628, eval loss: 0.3609670102596283
Epoch: 7, loss: 0.40624369683966505, eval loss: 0.3480854332447052
Epoch: 8, loss: 0.402880269610323, eval loss: 0.3660224676132202
Epoch: 9, loss: 0.4021308177744504, eval loss: 0.38493871688842773
Epoch: 10, loss: 0.39837055550480727, eval loss: 0.36753249168395996
Epoch: 11, loss: 0.3977445128611907, eval loss: 0.4059998095035553
Epoch: 12, loss: 0.39563140632002614, eval loss: 0.3637508749961853
Epoch: 13, loss: 0.391234323673998, eval loss: 0.5034701824188232
Epoch: 14, loss: 0.3922317257305258, eval loss: 0.3700362741947174
Epoch: 15, loss: 0.3890877677615481, eval loss: 0.3504759669303894
Epoch: 16, loss: 0.3873076252673491, eval loss: 0.34963491559028625
Epoch: 17, loss: 0.38459238052455474, eval loss: 0.3680035471916199
Epoch: 18, loss: 0.38554254588962067, eval loss: 0.3485642671585083
Epoch: 19, loss: 0.3841848685167497, eval loss: 0.3250780701637268
Epoch: 20, loss: 0.38388523606350644, eval loss: 0.3540080189704895
Epoch: 21, loss: 0.3808974065707298, eval loss: 0.3577110171318054
Epoch: 22, loss: 0.38241112109157255, eval loss: 0.34642529487609863
Epoch: 23, loss: 0.37928072161157617, eval loss: 0.3568181097507477
Epoch: 24, loss: 0.38212436745408923, eval loss: 0.3399367928504944
Epoch: 25, loss: 0.3817037399180117, eval loss: 0.34706878662109375
Epoch: 26, loss: 0.3807401495455997, eval loss: 0.3469946086406708
Epoch: 27, loss: 0.37965173992939527, eval loss: 0.33031368255615234
Epoch: 28, loss: 0.38034476337372325, eval loss: 0.35577356815338135
Epoch: 29, loss: 0.38048402983645246, eval loss: 0.34819743037223816
Epoch: 30, loss: 0.3794305514474399, eval loss: 0.3323286473751068
Epoch: 31, loss: 0.37888657181116286, eval loss: 0.3464047610759735
Epoch: 32, loss: 0.38017315170247457, eval loss: 0.3477247953414917
Epoch: 33, loss: 0.3803438267735328, eval loss: 0.33124303817749023
Epoch: 34, loss: 0.3806605866563041, eval loss: 0.3378329575061798
Epoch: 35, loss: 0.3812724376226106, eval loss: 0.3575456142425537
Epoch: 36, loss: 0.3802090958491317, eval loss: 0.33989205956459045
Epoch: 37, loss: 0.3788775900861947, eval loss: 0.3558477461338043
Epoch: 38, loss: 0.379741940167587, eval loss: 0.3778533637523651
Epoch: 39, loss: 0.38149828563677146, eval loss: 0.33762645721435547
Epoch: 40, loss: 0.3804763034312055, eval loss: 0.3408747911453247
Epoch: 41, loss: 0.38243319175962825, eval loss: 0.3557581901550293
Epoch: 42, loss: 0.38192005308395893, eval loss: 0.33464065194129944
Epoch: 43, loss: 0.38127175021923904, eval loss: 0.3334345817565918
Epoch: 44, loss: 0.3801863903409685, eval loss: 0.3348689079284668
Epoch: 45, loss: 0.3836505929575651, eval loss: 0.3456200063228607
Epoch: 46, loss: 0.3826567873300519, eval loss: 0.3334272801876068
Epoch: 47, loss: 0.38284103885805965, eval loss: 0.33627066016197205
Epoch: 48, loss: 0.38321108937845566, eval loss: 0.33693185448646545
Epoch: 49, loss: 0.38140358036747785, eval loss: 0.3334111273288727

Runtime:601.81
KL div untrained: 7.2814509121785545e+19
KL div trained: 0.0105
