Input args:
Dim: 2
seed: 26
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.8252184796705841, eval loss: 7.004626750946045
Epoch: 1, loss: 0.4859214516589418, eval loss: 0.5711096525192261
Epoch: 2, loss: 0.4526656401343644, eval loss: 0.4800828695297241
Epoch: 3, loss: 0.43639150269351373, eval loss: 0.44848138093948364
Epoch: 4, loss: 0.4303078638114675, eval loss: 0.48707276582717896
Epoch: 5, loss: 0.4223317684044014, eval loss: 0.44898346066474915
Epoch: 6, loss: 0.4109942405430047, eval loss: 0.4994193911552429
Epoch: 7, loss: 0.41005213048541916, eval loss: 0.4956872761249542
Epoch: 8, loss: 0.4070792723595514, eval loss: 0.5075486302375793
Epoch: 9, loss: 0.4012943242740585, eval loss: 0.5108383297920227
Epoch: 10, loss: 0.39545245944638735, eval loss: 0.4807756245136261
Epoch: 11, loss: 0.3974154172524868, eval loss: 0.45253321528434753
Epoch: 12, loss: 0.39096680208778706, eval loss: 0.47047853469848633
Epoch: 13, loss: 0.39418874437695195, eval loss: 0.46851155161857605
Epoch: 14, loss: 0.38863122440227016, eval loss: 0.43729257583618164
Epoch: 15, loss: 0.3893404468940571, eval loss: 0.4537784457206726
Epoch: 16, loss: 0.39035990193369796, eval loss: 0.4747893810272217
Epoch: 17, loss: 0.3840912513856892, eval loss: 0.491771399974823
Epoch: 18, loss: 0.38561505495555176, eval loss: 0.46019458770751953
Epoch: 19, loss: 0.3861902701330837, eval loss: 0.4428618550300598
Epoch: 20, loss: 0.38619708783051465, eval loss: 0.4445533752441406
Epoch: 21, loss: 0.3830180458520772, eval loss: 0.43866845965385437
Epoch: 22, loss: 0.3840406005358091, eval loss: 0.4369887411594391
Epoch: 23, loss: 0.3802331554586999, eval loss: 0.4404333531856537
Epoch: 24, loss: 0.38211716096207965, eval loss: 0.43416228890419006
Epoch: 25, loss: 0.3813354739738861, eval loss: 0.47330865263938904
Epoch: 26, loss: 0.3838745995158388, eval loss: 0.4360489249229431
Epoch: 27, loss: 0.38052651216501543, eval loss: 0.47348451614379883
Epoch: 28, loss: 0.3808104190306767, eval loss: 0.4514784514904022
Epoch: 29, loss: 0.38112695842108224, eval loss: 0.43997061252593994
Epoch: 30, loss: 0.38070667097723343, eval loss: 0.4447081983089447
Epoch: 31, loss: 0.38113124850264285, eval loss: 0.43872788548469543
Epoch: 32, loss: 0.38003869327483697, eval loss: 0.4460877478122711
Epoch: 33, loss: 0.37759014148614367, eval loss: 0.4372779130935669
Epoch: 34, loss: 0.38113288336826373, eval loss: 0.43268123269081116
Epoch: 35, loss: 0.3782228428755145, eval loss: 0.4262566566467285
Epoch: 36, loss: 0.3779587394738337, eval loss: 0.4246251583099365
Epoch: 37, loss: 0.37928192068495264, eval loss: 0.42173367738723755
Epoch: 38, loss: 0.3811883077013772, eval loss: 0.4550350606441498
Epoch: 39, loss: 0.37759162093512716, eval loss: 0.4348658621311188
Epoch: 40, loss: 0.3799351306800963, eval loss: 0.45943784713745117
Epoch: 41, loss: 0.37876207155874, eval loss: 0.4291449785232544
Epoch: 42, loss: 0.37928059852099977, eval loss: 0.4574986398220062
Epoch: 43, loss: 0.38029041672998576, eval loss: 0.44009456038475037
Epoch: 44, loss: 0.3812509515388228, eval loss: 0.4263382852077484
Epoch: 45, loss: 0.38033891470724485, eval loss: 0.42750421166419983
Epoch: 46, loss: 0.3783230511395959, eval loss: 0.4390566945075989
Epoch: 47, loss: 0.3798541550559457, eval loss: 0.43325275182724
Epoch: 48, loss: 0.37844607383129186, eval loss: 0.4427100121974945
Epoch: 49, loss: 0.3799293127472629, eval loss: 0.41557732224464417

Runtime:653.34
KL div untrained: 3.5433021934751186e+18
KL div trained: 0.0026
