Input args:
Dim: 2
seed: 4
seed_data: 10
/home/samwiq/spa/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/spa/seq-posterior-approx-w-nf-dev
[1.0, 0.4965853037914095, 0.2465969639416065, 0.12245642825298195, 0.06081006262521797, 0.0301973834223185, 0.014995576820477717, 0.007446583070924344, 0.003697863716482932, 0.0018363047770289071]
start full training
Iteration: 1
optimizer_post_lr: [0.002]
prob_prior: 1.0
start update likelihood model
Epoch: 0, loss (training): 26.8709, loss (eval): 40.3438
Epoch: 1, loss (training): 20.3957, loss (eval): 22.3937
Epoch: 2, loss (training): 18.1227, loss (eval): 19.1273
Epoch: 3, loss (training): 16.7033, loss (eval): 17.6208
Epoch: 4, loss (training): 15.6151, loss (eval): 16.2941
Epoch: 5, loss (training): 14.5472, loss (eval): 15.0854
Epoch: 6, loss (training): 13.5769, loss (eval): 14.059
Epoch: 7, loss (training): 13.0226, loss (eval): 13.1872
Epoch: 8, loss (training): 12.3179, loss (eval): 12.8852
Epoch: 9, loss (training): 11.8189, loss (eval): 12.1151
Epoch: 10, loss (training): 11.4392, loss (eval): 11.5737
Epoch: 11, loss (training): 11.1135, loss (eval): 11.4144
Epoch: 12, loss (training): 10.8294, loss (eval): 10.7932
Epoch: 13, loss (training): 10.8353, loss (eval): 10.881
Epoch: 14, loss (training): 10.7009, loss (eval): 10.7799
Epoch: 15, loss (training): 10.5872, loss (eval): 10.7674
Epoch: 16, loss (training): 10.4634, loss (eval): 10.6556
Epoch: 17, loss (training): 10.5805, loss (eval): 10.6797
Epoch: 18, loss (training): 10.5193, loss (eval): 10.8563
Epoch: 19, loss (training): 10.3796, loss (eval): 10.4643
Epoch: 20, loss (training): 10.4855, loss (eval): 10.4322
Epoch: 21, loss (training): 10.3758, loss (eval): 10.6162
Epoch: 22, loss (training): 10.3033, loss (eval): 10.4722
Epoch: 23, loss (training): 10.3518, loss (eval): 10.6691
Epoch: 24, loss (training): 10.323, loss (eval): 10.456
Epoch: 25, loss (training): 10.3452, loss (eval): 10.4574
Epoch: 26, loss (training): 10.346, loss (eval): 10.4251
Epoch: 27, loss (training): 10.2818, loss (eval): 10.4625
Epoch: 28, loss (training): 10.2649, loss (eval): 10.4248
Epoch: 29, loss (training): 10.2987, loss (eval): 10.4999
Epoch: 30, loss (training): 10.3098, loss (eval): 10.5077
Epoch: 31, loss (training): 10.2425, loss (eval): 10.457
Epoch: 32, loss (training): 10.4007, loss (eval): 10.535
Epoch: 33, loss (training): 10.2599, loss (eval): 10.7195
Epoch: 34, loss (training): 10.2145, loss (eval): 10.5292
Epoch: 35, loss (training): 10.2336, loss (eval): 10.5458
Epoch: 36, loss (training): 10.2618, loss (eval): 10.4901
Epoch: 37, loss (training): 10.2482, loss (eval): 10.5501
Epoch: 38, loss (training): 10.2648, loss (eval): 10.4042
Epoch: 39, loss (training): 10.2415, loss (eval): 10.5546
Epoch: 40, loss (training): 10.1697, loss (eval): 10.4812
Epoch: 41, loss (training): 10.2841, loss (eval): 10.5156
Epoch: 42, loss (training): 10.1864, loss (eval): 10.5245
Epoch: 43, loss (training): 10.1505, loss (eval): 10.4488
Epoch: 44, loss (training): 10.1951, loss (eval): 10.539
Epoch: 45, loss (training): 10.2087, loss (eval): 10.456
Epoch: 46, loss (training): 10.1762, loss (eval): 10.431
Epoch: 47, loss (training): 10.1856, loss (eval): 10.4761
Epoch: 48, loss (training): 10.1652, loss (eval): 10.5581
Epoch: 49, loss (training): 10.1524, loss (eval): 10.4999
Epoch: 50, loss (training): 10.203, loss (eval): 10.4337
Epoch: 51, loss (training): 10.1377, loss (eval): 10.4196
Epoch: 52, loss (training): 10.1537, loss (eval): 10.4452
Epoch: 53, loss (training): 10.1682, loss (eval): 10.4464
Epoch: 54, loss (training): 10.1837, loss (eval): 10.5507
Epoch: 55, loss (training): 10.203, loss (eval): 10.5983
Epoch: 56, loss (training): 10.0965, loss (eval): 10.4485
Epoch: 57, loss (training): 10.1582, loss (eval): 10.5235
Early-stopping. Training converged after 58 epochs.
start update posterior model from prior pred - hot start
Epoch: 0, loss (training): 4.138, loss (eval): 6.8591
Epoch: 1, loss (training): 2.1115, loss (eval): 2.2943
Epoch: 2, loss (training): 1.5545, loss (eval): 1.6039
Epoch: 3, loss (training): 1.1132, loss (eval): 1.2699
Epoch: 4, loss (training): 0.9668, loss (eval): 1.0516
Epoch: 5, loss (training): 0.8313, loss (eval): 0.7792
Epoch: 6, loss (training): 0.9586, loss (eval): 0.6952
Epoch: 7, loss (training): 0.6899, loss (eval): 0.684
Epoch: 8, loss (training): 0.7487, loss (eval): 0.6866
Epoch: 9, loss (training): 0.6568, loss (eval): 0.7445
start update posterior model
Epoch: 0, loss (training): 17.1986, loss (eval): 18.397
Epoch: 1, loss (training): 16.7447, loss (eval): 16.7162
Epoch: 2, loss (training): 16.761, loss (eval): 16.694
Epoch: 3, loss (training): 16.7334, loss (eval): 16.8177
Epoch: 4, loss (training): 16.7358, loss (eval): 16.6818
Epoch: 5, loss (training): 16.7373, loss (eval): 16.6855
Epoch: 6, loss (training): 16.7251, loss (eval): 16.7104
Epoch: 7, loss (training): 16.7243, loss (eval): 16.7049
Epoch: 8, loss (training): 16.7451, loss (eval): 16.7055
Epoch: 9, loss (training): 16.7281, loss (eval): 16.7722
Epoch: 10, loss (training): 16.7254, loss (eval): 16.7186
Epoch: 11, loss (training): 16.7352, loss (eval): 16.6984
Epoch: 12, loss (training): 16.733, loss (eval): 16.7264
Epoch: 13, loss (training): 16.7174, loss (eval): 16.7002
Epoch: 14, loss (training): 16.7101, loss (eval): 16.6966
Epoch: 15, loss (training): 16.7342, loss (eval): 16.7804
Epoch: 16, loss (training): 16.715, loss (eval): 16.6936
Epoch: 17, loss (training): 16.7199, loss (eval): 16.7793
Epoch: 18, loss (training): 16.7414, loss (eval): 16.7005
Epoch: 19, loss (training): 16.7184, loss (eval): 16.711
Epoch: 20, loss (training): 16.7268, loss (eval): 16.6865
Epoch: 21, loss (training): 16.7194, loss (eval): 16.6959
Epoch: 22, loss (training): 16.7139, loss (eval): 16.7897
Epoch: 23, loss (training): 16.7248, loss (eval): 16.7064
Early-stopping. Training converged after 24 epochs.
Iteration: 2
optimizer_post_lr: [0.0019]
prob_prior: 0.4965853037914095
start update likelihood model
Epoch: 0, loss (training): 10.322, loss (eval): 10.0633
Epoch: 1, loss (training): 10.2526, loss (eval): 9.857
Epoch: 2, loss (training): 10.315, loss (eval): 9.8578
Epoch: 3, loss (training): 10.2158, loss (eval): 9.8951
Epoch: 4, loss (training): 10.2225, loss (eval): 10.0173
Epoch: 5, loss (training): 10.2605, loss (eval): 9.8469
Epoch: 6, loss (training): 10.1668, loss (eval): 9.7882
Epoch: 7, loss (training): 10.1819, loss (eval): 9.9182
Epoch: 8, loss (training): 10.1393, loss (eval): 9.9103
Epoch: 9, loss (training): 10.1469, loss (eval): 9.8488
Epoch: 10, loss (training): 10.1257, loss (eval): 9.8944
Epoch: 11, loss (training): 10.1757, loss (eval): 9.8688
Epoch: 12, loss (training): 10.1057, loss (eval): 9.957
Epoch: 13, loss (training): 10.1199, loss (eval): 9.869
Epoch: 14, loss (training): 10.1439, loss (eval): 9.9704
Epoch: 15, loss (training): 10.1698, loss (eval): 9.9999
Epoch: 16, loss (training): 10.0985, loss (eval): 9.8844
Epoch: 17, loss (training): 10.1332, loss (eval): 9.8471
Epoch: 18, loss (training): 10.1055, loss (eval): 9.8975
Epoch: 19, loss (training): 10.0723, loss (eval): 9.9952
Epoch: 20, loss (training): 10.0769, loss (eval): 9.8685
Epoch: 21, loss (training): 10.1602, loss (eval): 9.8956
Epoch: 22, loss (training): 10.0903, loss (eval): 9.8893
Epoch: 23, loss (training): 10.1152, loss (eval): 9.9721
Epoch: 24, loss (training): 10.0916, loss (eval): 9.8904
Epoch: 25, loss (training): 10.1061, loss (eval): 9.8335
Early-stopping. Training converged after 26 epochs.
start update posterior model
Epoch: 0, loss (training): 17.6499, loss (eval): 17.75
Epoch: 1, loss (training): 17.6454, loss (eval): 17.6916
Epoch: 2, loss (training): 17.6381, loss (eval): 17.6195
Epoch: 3, loss (training): 17.6403, loss (eval): 17.6488
Epoch: 4, loss (training): 17.6383, loss (eval): 17.6269
Epoch: 5, loss (training): 17.6569, loss (eval): 17.6624
Epoch: 6, loss (training): 17.6416, loss (eval): 17.7279
Epoch: 7, loss (training): 17.6424, loss (eval): 17.6406
Epoch: 8, loss (training): 17.6365, loss (eval): 17.6335
Epoch: 9, loss (training): 17.6397, loss (eval): 17.616
Epoch: 10, loss (training): 17.6486, loss (eval): 17.6407
Epoch: 11, loss (training): 17.6386, loss (eval): 17.6432
Epoch: 12, loss (training): 17.6447, loss (eval): 17.622
Epoch: 13, loss (training): 17.6417, loss (eval): 17.606
Epoch: 14, loss (training): 17.6513, loss (eval): 17.6121
Epoch: 15, loss (training): 17.6527, loss (eval): 17.6174
Epoch: 16, loss (training): 17.6308, loss (eval): 17.6105
Epoch: 17, loss (training): 17.6462, loss (eval): 17.6316
Epoch: 18, loss (training): 17.6331, loss (eval): 17.6059
Epoch: 19, loss (training): 17.6236, loss (eval): 17.6164
Epoch: 20, loss (training): 17.6347, loss (eval): 17.6177
Epoch: 21, loss (training): 17.6317, loss (eval): 17.6092
Epoch: 22, loss (training): 17.638, loss (eval): 17.6057
Epoch: 23, loss (training): 17.6461, loss (eval): 17.6153
Epoch: 24, loss (training): 17.6366, loss (eval): 17.6181
Epoch: 25, loss (training): 17.636, loss (eval): 17.6233
Epoch: 26, loss (training): 17.6379, loss (eval): 17.6099
Epoch: 27, loss (training): 17.6303, loss (eval): 17.6388
Epoch: 28, loss (training): 17.638, loss (eval): 17.611
Epoch: 29, loss (training): 17.6414, loss (eval): 17.6196
Epoch: 30, loss (training): 17.6301, loss (eval): 17.6484
Epoch: 31, loss (training): 17.6405, loss (eval): 17.6901
Epoch: 32, loss (training): 17.6308, loss (eval): 17.618
Epoch: 33, loss (training): 17.6325, loss (eval): 17.6048
Epoch: 34, loss (training): 17.654, loss (eval): 17.6604
Epoch: 35, loss (training): 17.6216, loss (eval): 17.6054
Epoch: 36, loss (training): 17.6338, loss (eval): 17.6233
Epoch: 37, loss (training): 17.6275, loss (eval): 17.6592
Epoch: 38, loss (training): 17.6365, loss (eval): 17.6239
Epoch: 39, loss (training): 17.6293, loss (eval): 17.6103
Epoch: 40, loss (training): 17.6291, loss (eval): 17.6078
Epoch: 41, loss (training): 17.6207, loss (eval): 17.6796
Epoch: 42, loss (training): 17.6399, loss (eval): 17.6133
Epoch: 43, loss (training): 17.6272, loss (eval): 17.6456
Epoch: 44, loss (training): 17.6276, loss (eval): 17.6053
Epoch: 45, loss (training): 17.6271, loss (eval): 17.6026
Epoch: 46, loss (training): 17.6215, loss (eval): 17.6154
Epoch: 47, loss (training): 17.6235, loss (eval): 17.6097
Epoch: 48, loss (training): 17.6286, loss (eval): 17.6058
Epoch: 49, loss (training): 17.6303, loss (eval): 17.6266
Epoch: 50, loss (training): 17.6207, loss (eval): 17.6105
Epoch: 51, loss (training): 17.6308, loss (eval): 17.6201
Epoch: 52, loss (training): 17.6223, loss (eval): 17.6207
Epoch: 53, loss (training): 17.6226, loss (eval): 17.6285
Epoch: 54, loss (training): 17.6342, loss (eval): 17.6135
Epoch: 55, loss (training): 17.6244, loss (eval): 17.6863
Epoch: 56, loss (training): 17.624, loss (eval): 17.6105
Epoch: 57, loss (training): 17.6231, loss (eval): 17.6115
Epoch: 58, loss (training): 17.6302, loss (eval): 17.6046
Epoch: 59, loss (training): 17.6262, loss (eval): 17.6226
Epoch: 60, loss (training): 17.6331, loss (eval): 17.6233
Epoch: 61, loss (training): 17.6191, loss (eval): 17.6238
Epoch: 62, loss (training): 17.6236, loss (eval): 17.625
Epoch: 63, loss (training): 17.6224, loss (eval): 17.6515
Epoch: 64, loss (training): 17.6261, loss (eval): 17.6401
Early-stopping. Training converged after 65 epochs.
Iteration: 3
optimizer_post_lr: [0.001805]
prob_prior: 0.2465969639416065
start update likelihood model
Epoch: 0, loss (training): 10.2893, loss (eval): 10.4673
Epoch: 1, loss (training): 10.2244, loss (eval): 10.264
Epoch: 2, loss (training): 10.2007, loss (eval): 10.3526
Epoch: 3, loss (training): 10.1719, loss (eval): 10.4069
Epoch: 4, loss (training): 10.1359, loss (eval): 10.2236
Epoch: 5, loss (training): 10.1805, loss (eval): 10.4465
Epoch: 6, loss (training): 10.108, loss (eval): 10.2064
Epoch: 7, loss (training): 10.1331, loss (eval): 10.2138
Epoch: 8, loss (training): 10.1005, loss (eval): 10.2783
Epoch: 9, loss (training): 10.1165, loss (eval): 10.2242
Epoch: 10, loss (training): 10.1058, loss (eval): 10.3307
Epoch: 11, loss (training): 10.0927, loss (eval): 10.3199
Epoch: 12, loss (training): 10.0932, loss (eval): 10.3041
Epoch: 13, loss (training): 10.0851, loss (eval): 10.3108
Epoch: 14, loss (training): 10.0901, loss (eval): 10.1511
Epoch: 15, loss (training): 10.0867, loss (eval): 10.2298
Epoch: 16, loss (training): 10.102, loss (eval): 10.3486
Epoch: 17, loss (training): 10.0714, loss (eval): 10.2716
Epoch: 18, loss (training): 10.0873, loss (eval): 10.2958
Epoch: 19, loss (training): 10.0861, loss (eval): 10.3009
Epoch: 20, loss (training): 10.0259, loss (eval): 10.167
Epoch: 21, loss (training): 10.0604, loss (eval): 10.277
Epoch: 22, loss (training): 10.0985, loss (eval): 10.2038
Epoch: 23, loss (training): 10.0504, loss (eval): 10.3103
Epoch: 24, loss (training): 10.0832, loss (eval): 10.3039
Epoch: 25, loss (training): 10.0697, loss (eval): 10.3474
Epoch: 26, loss (training): 10.0237, loss (eval): 10.1778
Epoch: 27, loss (training): 10.0703, loss (eval): 10.2333
Epoch: 28, loss (training): 10.0399, loss (eval): 10.262
Epoch: 29, loss (training): 10.0538, loss (eval): 10.2939
Epoch: 30, loss (training): 10.0019, loss (eval): 10.2991
Epoch: 31, loss (training): 10.0517, loss (eval): 10.22
Epoch: 32, loss (training): 10.0526, loss (eval): 10.287
Epoch: 33, loss (training): 10.0264, loss (eval): 10.3416
Early-stopping. Training converged after 34 epochs.
start update posterior model
Epoch: 0, loss (training): 16.8669, loss (eval): 17.1862
Epoch: 1, loss (training): 16.8659, loss (eval): 16.8338
Epoch: 2, loss (training): 16.8534, loss (eval): 16.8398
Epoch: 3, loss (training): 16.8643, loss (eval): 16.9455
Epoch: 4, loss (training): 16.8493, loss (eval): 16.8738
Epoch: 5, loss (training): 16.8479, loss (eval): 16.8351
Epoch: 6, loss (training): 16.8548, loss (eval): 16.8503
Epoch: 7, loss (training): 16.8491, loss (eval): 16.8504
Epoch: 8, loss (training): 16.8568, loss (eval): 16.8466
Epoch: 9, loss (training): 16.854, loss (eval): 16.8443
Epoch: 10, loss (training): 16.8529, loss (eval): 16.8531
Epoch: 11, loss (training): 16.8487, loss (eval): 16.841
Epoch: 12, loss (training): 16.8514, loss (eval): 16.8461
Epoch: 13, loss (training): 16.8691, loss (eval): 16.912
Epoch: 14, loss (training): 16.8538, loss (eval): 16.8379
Epoch: 15, loss (training): 16.8573, loss (eval): 16.845
Epoch: 16, loss (training): 16.8593, loss (eval): 16.9052
Epoch: 17, loss (training): 16.854, loss (eval): 16.866
Epoch: 18, loss (training): 16.8465, loss (eval): 16.8553
Epoch: 19, loss (training): 16.8533, loss (eval): 16.878
Epoch: 20, loss (training): 16.8609, loss (eval): 16.8387
Early-stopping. Training converged after 21 epochs.
Iteration: 4
optimizer_post_lr: [0.00171475]
prob_prior: 0.12245642825298195
start update likelihood model
Epoch: 0, loss (training): 10.1404, loss (eval): 10.283
Epoch: 1, loss (training): 10.1745, loss (eval): 10.4637
Epoch: 2, loss (training): 10.0758, loss (eval): 10.3046
Epoch: 3, loss (training): 10.0527, loss (eval): 10.2838
Epoch: 4, loss (training): 10.1252, loss (eval): 10.3904
Epoch: 5, loss (training): 10.0382, loss (eval): 10.3701
Epoch: 6, loss (training): 10.0758, loss (eval): 10.3553
Epoch: 7, loss (training): 10.0346, loss (eval): 10.3773
Epoch: 8, loss (training): 10.0099, loss (eval): 10.2845
Epoch: 9, loss (training): 10.009, loss (eval): 10.2937
Epoch: 10, loss (training): 10.0242, loss (eval): 10.258
Epoch: 11, loss (training): 10.0077, loss (eval): 10.3302
Epoch: 12, loss (training): 10.0117, loss (eval): 10.3071
Epoch: 13, loss (training): 10.021, loss (eval): 10.4309
Epoch: 14, loss (training): 10.0021, loss (eval): 10.4468
Epoch: 15, loss (training): 10.0253, loss (eval): 10.3728
Epoch: 16, loss (training): 10.0284, loss (eval): 10.484
Epoch: 17, loss (training): 10.0069, loss (eval): 10.3415
Epoch: 18, loss (training): 10.0146, loss (eval): 10.4106
Epoch: 19, loss (training): 10.0005, loss (eval): 10.3144
Epoch: 20, loss (training): 9.9772, loss (eval): 10.368
Epoch: 21, loss (training): 9.9486, loss (eval): 10.3043
Epoch: 22, loss (training): 9.9989, loss (eval): 10.3445
Epoch: 23, loss (training): 9.9995, loss (eval): 10.3404
Epoch: 24, loss (training): 9.996, loss (eval): 10.2635
Epoch: 25, loss (training): 10.0139, loss (eval): 10.2923
Epoch: 26, loss (training): 9.9974, loss (eval): 10.6066
Epoch: 27, loss (training): 9.9753, loss (eval): 10.3514
Epoch: 28, loss (training): 9.9593, loss (eval): 10.3371
Epoch: 29, loss (training): 9.9561, loss (eval): 10.3579
Early-stopping. Training converged after 30 epochs.
start update posterior model
Epoch: 0, loss (training): 16.9452, loss (eval): 16.9526
Epoch: 1, loss (training): 16.9394, loss (eval): 16.9277
Epoch: 2, loss (training): 16.9385, loss (eval): 16.9428
Epoch: 3, loss (training): 16.9368, loss (eval): 16.9565
Epoch: 4, loss (training): 16.9309, loss (eval): 16.9228
Epoch: 5, loss (training): 16.9377, loss (eval): 16.9291
Epoch: 6, loss (training): 16.9362, loss (eval): 16.951
Epoch: 7, loss (training): 16.9351, loss (eval): 16.9367
Epoch: 8, loss (training): 16.936, loss (eval): 16.9394
Epoch: 9, loss (training): 16.9392, loss (eval): 16.9704
Epoch: 10, loss (training): 16.9387, loss (eval): 16.9277
Epoch: 11, loss (training): 16.9384, loss (eval): 16.9359
Epoch: 12, loss (training): 16.9353, loss (eval): 16.9405
Epoch: 13, loss (training): 16.9401, loss (eval): 16.9301
Epoch: 14, loss (training): 16.9347, loss (eval): 16.9602
Epoch: 15, loss (training): 16.9348, loss (eval): 16.9281
Epoch: 16, loss (training): 16.9394, loss (eval): 16.9237
Epoch: 17, loss (training): 16.9392, loss (eval): 16.9195
Epoch: 18, loss (training): 16.9371, loss (eval): 16.9652
Epoch: 19, loss (training): 16.9363, loss (eval): 16.9253
Epoch: 20, loss (training): 16.9359, loss (eval): 16.9326
Epoch: 21, loss (training): 16.9378, loss (eval): 16.9253
Epoch: 22, loss (training): 16.9341, loss (eval): 16.9325
Epoch: 23, loss (training): 16.9371, loss (eval): 16.9218
Epoch: 24, loss (training): 16.9355, loss (eval): 16.926
Epoch: 25, loss (training): 16.9299, loss (eval): 16.944
Epoch: 26, loss (training): 16.934, loss (eval): 16.9253
Epoch: 27, loss (training): 16.9349, loss (eval): 16.9219
Epoch: 28, loss (training): 16.9314, loss (eval): 16.9232
Epoch: 29, loss (training): 16.943, loss (eval): 16.9411
Epoch: 30, loss (training): 16.9364, loss (eval): 16.9295
Epoch: 31, loss (training): 16.9324, loss (eval): 16.9398
Epoch: 32, loss (training): 16.9445, loss (eval): 16.9239
Epoch: 33, loss (training): 16.9349, loss (eval): 16.9223
Epoch: 34, loss (training): 16.9342, loss (eval): 16.9418
Epoch: 35, loss (training): 16.9367, loss (eval): 16.9302
Epoch: 36, loss (training): 16.9311, loss (eval): 16.9212
Epoch: 37, loss (training): 16.9347, loss (eval): 16.9195
Epoch: 38, loss (training): 16.9456, loss (eval): 16.9252
Epoch: 39, loss (training): 16.9329, loss (eval): 16.9487
Epoch: 40, loss (training): 16.9357, loss (eval): 16.9522
Epoch: 41, loss (training): 16.9323, loss (eval): 16.9269
Epoch: 42, loss (training): 16.9312, loss (eval): 16.9406
Epoch: 43, loss (training): 16.9326, loss (eval): 16.9332
Epoch: 44, loss (training): 16.9381, loss (eval): 16.9212
Epoch: 45, loss (training): 16.9387, loss (eval): 16.9225
Epoch: 46, loss (training): 16.9348, loss (eval): 16.9304
Epoch: 47, loss (training): 16.9294, loss (eval): 16.9199
Epoch: 48, loss (training): 16.9419, loss (eval): 16.9316
Epoch: 49, loss (training): 16.9374, loss (eval): 16.9277
Epoch: 50, loss (training): 16.9423, loss (eval): 16.9405
Epoch: 51, loss (training): 16.9364, loss (eval): 16.9239
Epoch: 52, loss (training): 16.9359, loss (eval): 16.9361
Epoch: 53, loss (training): 16.9433, loss (eval): 16.9296
Epoch: 54, loss (training): 16.9344, loss (eval): 16.9202
Epoch: 55, loss (training): 16.9299, loss (eval): 16.9424
Epoch: 56, loss (training): 16.9368, loss (eval): 16.9434
Early-stopping. Training converged after 57 epochs.
Iteration: 5
optimizer_post_lr: [0.0016290124999999997]
prob_prior: 0.06081006262521797
start update likelihood model
Epoch: 0, loss (training): 10.2831, loss (eval): 10.0506
Epoch: 1, loss (training): 10.2186, loss (eval): 10.087
Epoch: 2, loss (training): 10.1951, loss (eval): 10.1475
Epoch: 3, loss (training): 10.1321, loss (eval): 10.0414
Epoch: 4, loss (training): 10.1477, loss (eval): 10.0089
Epoch: 5, loss (training): 10.1842, loss (eval): 10.1445
Epoch: 6, loss (training): 10.1518, loss (eval): 10.0486
Epoch: 7, loss (training): 10.1393, loss (eval): 9.9897
Epoch: 8, loss (training): 10.1356, loss (eval): 10.0284
Epoch: 9, loss (training): 10.1004, loss (eval): 10.0613
Epoch: 10, loss (training): 10.1204, loss (eval): 10.0605
Epoch: 11, loss (training): 10.08, loss (eval): 10.0338
Epoch: 12, loss (training): 10.1009, loss (eval): 10.0693
Epoch: 13, loss (training): 10.1011, loss (eval): 9.9956
Epoch: 14, loss (training): 10.1861, loss (eval): 10.0849
Epoch: 15, loss (training): 10.1128, loss (eval): 10.1117
Epoch: 16, loss (training): 10.0731, loss (eval): 10.0114
Epoch: 17, loss (training): 10.0725, loss (eval): 10.0536
Epoch: 18, loss (training): 10.0761, loss (eval): 10.0853
Epoch: 19, loss (training): 10.107, loss (eval): 10.1974
Epoch: 20, loss (training): 10.0722, loss (eval): 9.9661
Epoch: 21, loss (training): 10.0823, loss (eval): 10.1316
Epoch: 22, loss (training): 10.0825, loss (eval): 10.0301
Epoch: 23, loss (training): 10.14, loss (eval): 10.2173
Epoch: 24, loss (training): 10.0806, loss (eval): 10.0032
Epoch: 25, loss (training): 10.0595, loss (eval): 9.9747
Epoch: 26, loss (training): 10.0951, loss (eval): 10.0892
Epoch: 27, loss (training): 10.0797, loss (eval): 10.0747
Epoch: 28, loss (training): 10.0585, loss (eval): 10.0192
Epoch: 29, loss (training): 10.0588, loss (eval): 10.0592
Epoch: 30, loss (training): 10.0747, loss (eval): 9.9763
Epoch: 31, loss (training): 10.0682, loss (eval): 10.1184
Epoch: 32, loss (training): 10.0725, loss (eval): 10.0223
Epoch: 33, loss (training): 10.0551, loss (eval): 10.0902
Epoch: 34, loss (training): 10.0911, loss (eval): 10.1957
Epoch: 35, loss (training): 10.0306, loss (eval): 10.022
Epoch: 36, loss (training): 10.0493, loss (eval): 10.0282
Epoch: 37, loss (training): 10.0473, loss (eval): 10.0221
Epoch: 38, loss (training): 10.103, loss (eval): 10.0288
Epoch: 39, loss (training): 10.0727, loss (eval): 10.0906
Early-stopping. Training converged after 40 epochs.
start update posterior model
Epoch: 0, loss (training): 16.6479, loss (eval): 16.6902
Epoch: 1, loss (training): 16.64, loss (eval): 16.6384
Epoch: 2, loss (training): 16.6457, loss (eval): 16.6326
Epoch: 3, loss (training): 16.6404, loss (eval): 16.6527
Epoch: 4, loss (training): 16.6418, loss (eval): 16.6544
Epoch: 5, loss (training): 16.6445, loss (eval): 16.6515
Epoch: 6, loss (training): 16.6499, loss (eval): 16.6544
Epoch: 7, loss (training): 16.6406, loss (eval): 16.6336
Epoch: 8, loss (training): 16.6447, loss (eval): 16.6745
Epoch: 9, loss (training): 16.6406, loss (eval): 16.6397
Epoch: 10, loss (training): 16.6434, loss (eval): 16.6499
Epoch: 11, loss (training): 16.6464, loss (eval): 16.6322
Epoch: 12, loss (training): 16.6439, loss (eval): 16.6329
Epoch: 13, loss (training): 16.6422, loss (eval): 16.6425
Epoch: 14, loss (training): 16.6444, loss (eval): 16.6325
Epoch: 15, loss (training): 16.6414, loss (eval): 16.6433
Epoch: 16, loss (training): 16.6432, loss (eval): 16.6335
Epoch: 17, loss (training): 16.647, loss (eval): 16.648
Epoch: 18, loss (training): 16.6412, loss (eval): 16.6829
Epoch: 19, loss (training): 16.64, loss (eval): 16.6608
Epoch: 20, loss (training): 16.6392, loss (eval): 16.6484
Epoch: 21, loss (training): 16.6428, loss (eval): 16.6772
Epoch: 22, loss (training): 16.6408, loss (eval): 16.6317
Epoch: 23, loss (training): 16.6405, loss (eval): 16.6677
Epoch: 24, loss (training): 16.6442, loss (eval): 16.6634
Epoch: 25, loss (training): 16.6452, loss (eval): 16.637
Epoch: 26, loss (training): 16.6372, loss (eval): 16.6364
Epoch: 27, loss (training): 16.6425, loss (eval): 16.6323
Epoch: 28, loss (training): 16.6407, loss (eval): 16.6326
Epoch: 29, loss (training): 16.6412, loss (eval): 16.64
Epoch: 30, loss (training): 16.6417, loss (eval): 16.6376
Epoch: 31, loss (training): 16.6446, loss (eval): 16.6375
Epoch: 32, loss (training): 16.6443, loss (eval): 16.6589
Epoch: 33, loss (training): 16.6459, loss (eval): 16.6464
Epoch: 34, loss (training): 16.6479, loss (eval): 16.6473
Epoch: 35, loss (training): 16.641, loss (eval): 16.6294
Epoch: 36, loss (training): 16.6393, loss (eval): 16.6331
Epoch: 37, loss (training): 16.6409, loss (eval): 16.6229
Epoch: 38, loss (training): 16.641, loss (eval): 16.6356
Epoch: 39, loss (training): 16.6445, loss (eval): 16.6257
Epoch: 40, loss (training): 16.6418, loss (eval): 16.6354
Epoch: 41, loss (training): 16.6436, loss (eval): 16.6436
Epoch: 42, loss (training): 16.6416, loss (eval): 16.633
Epoch: 43, loss (training): 16.6411, loss (eval): 16.6341
Epoch: 44, loss (training): 16.6464, loss (eval): 16.6368
Epoch: 45, loss (training): 16.6439, loss (eval): 16.638
Epoch: 46, loss (training): 16.6447, loss (eval): 16.6338
Epoch: 47, loss (training): 16.6403, loss (eval): 16.6416
Epoch: 48, loss (training): 16.6468, loss (eval): 16.6407
Epoch: 49, loss (training): 16.6431, loss (eval): 16.6382
Epoch: 50, loss (training): 16.6415, loss (eval): 16.6325
Epoch: 51, loss (training): 16.6384, loss (eval): 16.638
Epoch: 52, loss (training): 16.6439, loss (eval): 16.6372
Epoch: 53, loss (training): 16.6449, loss (eval): 16.6642
Epoch: 54, loss (training): 16.6419, loss (eval): 16.6491
Epoch: 55, loss (training): 16.6443, loss (eval): 16.6351
Epoch: 56, loss (training): 16.6401, loss (eval): 16.6658
Early-stopping. Training converged after 57 epochs.
Iteration: 6
optimizer_post_lr: [0.0015475618749999996]
prob_prior: 0.0301973834223185
start update likelihood model
Epoch: 0, loss (training): 10.1505, loss (eval): 10.0497
Epoch: 1, loss (training): 10.1092, loss (eval): 10.0314
Epoch: 2, loss (training): 10.125, loss (eval): 10.1242
Epoch: 3, loss (training): 10.0599, loss (eval): 10.1105
Epoch: 4, loss (training): 10.0665, loss (eval): 10.043
Epoch: 5, loss (training): 10.024, loss (eval): 10.0661
Epoch: 6, loss (training): 10.0411, loss (eval): 9.9832
Epoch: 7, loss (training): 10.0336, loss (eval): 10.072
Epoch: 8, loss (training): 10.0186, loss (eval): 10.0742
Epoch: 9, loss (training): 9.9908, loss (eval): 10.0594
Epoch: 10, loss (training): 10.0001, loss (eval): 10.113
Epoch: 11, loss (training): 9.9943, loss (eval): 10.2124
Epoch: 12, loss (training): 9.9879, loss (eval): 10.057
Epoch: 13, loss (training): 10.0036, loss (eval): 9.9904
Epoch: 14, loss (training): 10.0214, loss (eval): 10.0996
Epoch: 15, loss (training): 10.0114, loss (eval): 10.1483
Epoch: 16, loss (training): 10.0216, loss (eval): 10.112
Epoch: 17, loss (training): 10.0193, loss (eval): 9.9988
Epoch: 18, loss (training): 9.9944, loss (eval): 10.1624
Epoch: 19, loss (training): 10.0213, loss (eval): 10.0556
Epoch: 20, loss (training): 9.9859, loss (eval): 10.0725
Epoch: 21, loss (training): 9.989, loss (eval): 10.1075
Epoch: 22, loss (training): 9.9678, loss (eval): 10.1002
Epoch: 23, loss (training): 9.9926, loss (eval): 10.1386
Epoch: 24, loss (training): 9.9837, loss (eval): 10.1783
Epoch: 25, loss (training): 9.977, loss (eval): 10.094
Early-stopping. Training converged after 26 epochs.
start update posterior model
Epoch: 0, loss (training): 16.4914, loss (eval): 16.5458
Epoch: 1, loss (training): 16.4873, loss (eval): 16.4823
Epoch: 2, loss (training): 16.4886, loss (eval): 16.4801
Epoch: 3, loss (training): 16.4872, loss (eval): 16.4818
Epoch: 4, loss (training): 16.4798, loss (eval): 16.4682
Epoch: 5, loss (training): 16.4796, loss (eval): 16.5118
Epoch: 6, loss (training): 16.4817, loss (eval): 16.4795
Epoch: 7, loss (training): 16.4877, loss (eval): 16.4804
Epoch: 8, loss (training): 16.4806, loss (eval): 16.4876
Epoch: 9, loss (training): 16.4802, loss (eval): 16.47
Epoch: 10, loss (training): 16.4776, loss (eval): 16.472
Epoch: 11, loss (training): 16.4792, loss (eval): 16.4698
Epoch: 12, loss (training): 16.4784, loss (eval): 16.471
Epoch: 13, loss (training): 16.4786, loss (eval): 16.4745
Epoch: 14, loss (training): 16.4775, loss (eval): 16.4634
Epoch: 15, loss (training): 16.4828, loss (eval): 16.5186
Epoch: 16, loss (training): 16.4808, loss (eval): 16.4807
Epoch: 17, loss (training): 16.4835, loss (eval): 16.4984
Epoch: 18, loss (training): 16.4808, loss (eval): 16.4704
Epoch: 19, loss (training): 16.4811, loss (eval): 16.4927
Epoch: 20, loss (training): 16.4783, loss (eval): 16.487
Epoch: 21, loss (training): 16.4785, loss (eval): 16.4929
Epoch: 22, loss (training): 16.4829, loss (eval): 16.565
Epoch: 23, loss (training): 16.4763, loss (eval): 16.4774
Epoch: 24, loss (training): 16.4796, loss (eval): 16.4792
Epoch: 25, loss (training): 16.4853, loss (eval): 16.4815
Epoch: 26, loss (training): 16.4828, loss (eval): 16.4693
Epoch: 27, loss (training): 16.4816, loss (eval): 16.4707
Epoch: 28, loss (training): 16.4824, loss (eval): 16.4754
Epoch: 29, loss (training): 16.4797, loss (eval): 16.4804
Epoch: 30, loss (training): 16.4827, loss (eval): 16.4739
Epoch: 31, loss (training): 16.4784, loss (eval): 16.4872
Epoch: 32, loss (training): 16.4805, loss (eval): 16.4741
Epoch: 33, loss (training): 16.4818, loss (eval): 16.476
Early-stopping. Training converged after 34 epochs.
Iteration: 7
optimizer_post_lr: [0.0014701837812499995]
prob_prior: 0.014995576820477717
start update likelihood model
Epoch: 0, loss (training): 10.1859, loss (eval): 10.6944
Epoch: 1, loss (training): 10.1707, loss (eval): 10.5297
Epoch: 2, loss (training): 10.1181, loss (eval): 10.4619
Epoch: 3, loss (training): 10.0926, loss (eval): 10.4133
Epoch: 4, loss (training): 10.108, loss (eval): 10.4161
Epoch: 5, loss (training): 10.0706, loss (eval): 10.3956
Epoch: 6, loss (training): 10.0673, loss (eval): 10.3435
Epoch: 7, loss (training): 10.0874, loss (eval): 10.364
Epoch: 8, loss (training): 10.081, loss (eval): 10.3315
Epoch: 9, loss (training): 10.1033, loss (eval): 10.365
Epoch: 10, loss (training): 10.0801, loss (eval): 10.3915
Epoch: 11, loss (training): 10.0528, loss (eval): 10.3666
Epoch: 12, loss (training): 10.0695, loss (eval): 10.4064
Epoch: 13, loss (training): 10.0835, loss (eval): 10.3573
Epoch: 14, loss (training): 10.0749, loss (eval): 10.4143
Epoch: 15, loss (training): 10.0553, loss (eval): 10.4395
Epoch: 16, loss (training): 10.0436, loss (eval): 10.3968
Epoch: 17, loss (training): 10.0832, loss (eval): 10.341
Epoch: 18, loss (training): 10.0592, loss (eval): 10.3436
Epoch: 19, loss (training): 10.0418, loss (eval): 10.3229
Epoch: 20, loss (training): 10.0394, loss (eval): 10.4034
Epoch: 21, loss (training): 10.0306, loss (eval): 10.3318
Epoch: 22, loss (training): 10.0218, loss (eval): 10.3861
Epoch: 23, loss (training): 10.0444, loss (eval): 10.3656
Epoch: 24, loss (training): 10.0278, loss (eval): 10.3413
Epoch: 25, loss (training): 10.0237, loss (eval): 10.368
Epoch: 26, loss (training): 10.0502, loss (eval): 10.3579
Epoch: 27, loss (training): 10.0368, loss (eval): 10.402
Epoch: 28, loss (training): 10.0382, loss (eval): 10.454
Epoch: 29, loss (training): 10.0374, loss (eval): 10.3537
Epoch: 30, loss (training): 10.0065, loss (eval): 10.3693
Epoch: 31, loss (training): 10.0314, loss (eval): 10.3477
Epoch: 32, loss (training): 10.0279, loss (eval): 10.3365
Epoch: 33, loss (training): 10.1117, loss (eval): 10.4749
Epoch: 34, loss (training): 10.039, loss (eval): 10.3965
Epoch: 35, loss (training): 10.0418, loss (eval): 10.3725
Epoch: 36, loss (training): 10.0391, loss (eval): 10.5492
Epoch: 37, loss (training): 10.0066, loss (eval): 10.6017
Epoch: 38, loss (training): 10.0087, loss (eval): 10.3951
Early-stopping. Training converged after 39 epochs.
start update posterior model
Epoch: 0, loss (training): 17.3368, loss (eval): 17.9522
Epoch: 1, loss (training): 17.3203, loss (eval): 17.3209
Epoch: 2, loss (training): 17.3182, loss (eval): 17.3173
Epoch: 3, loss (training): 17.3128, loss (eval): 17.3092
Epoch: 4, loss (training): 17.3144, loss (eval): 17.3095
Epoch: 5, loss (training): 17.3157, loss (eval): 17.3103
Epoch: 6, loss (training): 17.3228, loss (eval): 17.3218
Epoch: 7, loss (training): 17.3147, loss (eval): 17.3142
Epoch: 8, loss (training): 17.3187, loss (eval): 17.3133
Epoch: 9, loss (training): 17.3154, loss (eval): 17.3121
Epoch: 10, loss (training): 17.3162, loss (eval): 17.3141
Epoch: 11, loss (training): 17.3171, loss (eval): 17.3213
Epoch: 12, loss (training): 17.3173, loss (eval): 17.3049
Epoch: 13, loss (training): 17.3154, loss (eval): 17.3118
Epoch: 14, loss (training): 17.3138, loss (eval): 17.3221
Epoch: 15, loss (training): 17.3179, loss (eval): 17.3257
Epoch: 16, loss (training): 17.3176, loss (eval): 17.3041
Epoch: 17, loss (training): 17.3121, loss (eval): 17.3145
Epoch: 18, loss (training): 17.3166, loss (eval): 17.3015
Epoch: 19, loss (training): 17.3179, loss (eval): 17.3101
Epoch: 20, loss (training): 17.3159, loss (eval): 17.3081
Epoch: 21, loss (training): 17.3149, loss (eval): 17.3122
Epoch: 22, loss (training): 17.3132, loss (eval): 17.3162
Epoch: 23, loss (training): 17.3161, loss (eval): 17.3119
Epoch: 24, loss (training): 17.3131, loss (eval): 17.31
Epoch: 25, loss (training): 17.3179, loss (eval): 17.3642
Epoch: 26, loss (training): 17.3132, loss (eval): 17.3092
Epoch: 27, loss (training): 17.3131, loss (eval): 17.3154
Epoch: 28, loss (training): 17.3127, loss (eval): 17.3335
Epoch: 29, loss (training): 17.3191, loss (eval): 17.3173
Epoch: 30, loss (training): 17.3156, loss (eval): 17.3415
Epoch: 31, loss (training): 17.3173, loss (eval): 17.3555
Epoch: 32, loss (training): 17.3136, loss (eval): 17.3242
Epoch: 33, loss (training): 17.3119, loss (eval): 17.3243
Epoch: 34, loss (training): 17.3146, loss (eval): 17.3369
Epoch: 35, loss (training): 17.3167, loss (eval): 17.3271
Epoch: 36, loss (training): 17.3152, loss (eval): 17.3129
Epoch: 37, loss (training): 17.3117, loss (eval): 17.3082
Early-stopping. Training converged after 38 epochs.
Iteration: 8
optimizer_post_lr: [0.0013966745921874994]
prob_prior: 0.007446583070924344
start update likelihood model
Epoch: 0, loss (training): 10.1393, loss (eval): 10.1596
Epoch: 1, loss (training): 10.0439, loss (eval): 10.2527
Epoch: 2, loss (training): 9.9775, loss (eval): 10.1855
Epoch: 3, loss (training): 9.9697, loss (eval): 10.365
Epoch: 4, loss (training): 9.9349, loss (eval): 10.1674
Epoch: 5, loss (training): 9.9696, loss (eval): 10.1393
Epoch: 6, loss (training): 9.9475, loss (eval): 10.171
Epoch: 7, loss (training): 9.9472, loss (eval): 10.2166
Epoch: 8, loss (training): 9.9578, loss (eval): 10.2134
Epoch: 9, loss (training): 9.9515, loss (eval): 10.1295
Epoch: 10, loss (training): 9.9221, loss (eval): 10.1912
Epoch: 11, loss (training): 9.9344, loss (eval): 10.1092
Epoch: 12, loss (training): 9.9219, loss (eval): 10.1521
Epoch: 13, loss (training): 9.8996, loss (eval): 10.1369
Epoch: 14, loss (training): 9.9305, loss (eval): 10.146
Epoch: 15, loss (training): 9.8945, loss (eval): 10.1963
Epoch: 16, loss (training): 9.9158, loss (eval): 10.2768
Epoch: 17, loss (training): 9.9179, loss (eval): 10.1616
Epoch: 18, loss (training): 9.9094, loss (eval): 10.2377
Epoch: 19, loss (training): 9.9113, loss (eval): 10.1518
Epoch: 20, loss (training): 9.9341, loss (eval): 10.1716
Epoch: 21, loss (training): 9.8782, loss (eval): 10.1813
Epoch: 22, loss (training): 9.9336, loss (eval): 10.2081
Epoch: 23, loss (training): 9.9127, loss (eval): 10.2013
Epoch: 24, loss (training): 9.8855, loss (eval): 10.18
Epoch: 25, loss (training): 9.8954, loss (eval): 10.1972
Epoch: 26, loss (training): 9.8945, loss (eval): 10.1787
Epoch: 27, loss (training): 9.8942, loss (eval): 10.2187
Epoch: 28, loss (training): 9.9176, loss (eval): 10.2345
Epoch: 29, loss (training): 9.8844, loss (eval): 10.1408
Epoch: 30, loss (training): 9.8778, loss (eval): 10.2131
Early-stopping. Training converged after 31 epochs.
start update posterior model
Epoch: 0, loss (training): 17.869, loss (eval): 18.2622
Epoch: 1, loss (training): 17.8547, loss (eval): 17.8742
Epoch: 2, loss (training): 17.8576, loss (eval): 17.8508
Epoch: 3, loss (training): 17.86, loss (eval): 17.8401
Epoch: 4, loss (training): 17.8584, loss (eval): 17.8486
Epoch: 5, loss (training): 17.8602, loss (eval): 17.847
Epoch: 6, loss (training): 17.8536, loss (eval): 17.8617
Epoch: 7, loss (training): 17.8542, loss (eval): 17.8422
Epoch: 8, loss (training): 17.8596, loss (eval): 17.8486
Epoch: 9, loss (training): 17.8559, loss (eval): 17.8656
Epoch: 10, loss (training): 17.8536, loss (eval): 17.8521
Epoch: 11, loss (training): 17.856, loss (eval): 17.8539
Epoch: 12, loss (training): 17.855, loss (eval): 17.8523
Epoch: 13, loss (training): 17.8568, loss (eval): 17.8679
Epoch: 14, loss (training): 17.8552, loss (eval): 17.8448
Epoch: 15, loss (training): 17.8586, loss (eval): 17.8491
Epoch: 16, loss (training): 17.8571, loss (eval): 17.8514
Epoch: 17, loss (training): 17.8572, loss (eval): 17.857
Epoch: 18, loss (training): 17.8608, loss (eval): 17.8488
Epoch: 19, loss (training): 17.8562, loss (eval): 17.8648
Epoch: 20, loss (training): 17.8545, loss (eval): 17.8494
Epoch: 21, loss (training): 17.8622, loss (eval): 17.8584
Epoch: 22, loss (training): 17.8615, loss (eval): 17.8476
Early-stopping. Training converged after 23 epochs.
Iteration: 9
optimizer_post_lr: [0.0013268408625781243]
prob_prior: 0.003697863716482932
start update likelihood model
Epoch: 0, loss (training): 10.1827, loss (eval): 10.2669
Epoch: 1, loss (training): 10.1482, loss (eval): 10.1409
Epoch: 2, loss (training): 10.1, loss (eval): 10.129
Epoch: 3, loss (training): 10.0836, loss (eval): 10.1569
Epoch: 4, loss (training): 10.0663, loss (eval): 10.1206
Epoch: 5, loss (training): 10.0611, loss (eval): 10.06
Epoch: 6, loss (training): 10.0652, loss (eval): 10.1139
Epoch: 7, loss (training): 10.0601, loss (eval): 10.2225
Epoch: 8, loss (training): 10.0629, loss (eval): 10.27
Epoch: 9, loss (training): 10.0526, loss (eval): 10.1811
Epoch: 10, loss (training): 10.0374, loss (eval): 10.1331
Epoch: 11, loss (training): 10.0398, loss (eval): 10.122
Epoch: 12, loss (training): 10.0413, loss (eval): 10.1177
Epoch: 13, loss (training): 10.084, loss (eval): 10.256
Epoch: 14, loss (training): 10.0565, loss (eval): 10.2081
Epoch: 15, loss (training): 10.0406, loss (eval): 10.1283
Epoch: 16, loss (training): 10.0355, loss (eval): 10.1566
Epoch: 17, loss (training): 10.0583, loss (eval): 10.1663
Epoch: 18, loss (training): 10.0296, loss (eval): 10.197
Epoch: 19, loss (training): 10.0179, loss (eval): 10.1547
Epoch: 20, loss (training): 10.0103, loss (eval): 10.1796
Epoch: 21, loss (training): 10.0214, loss (eval): 10.1973
Epoch: 22, loss (training): 10.0483, loss (eval): 10.1587
Epoch: 23, loss (training): 10.049, loss (eval): 10.1982
Epoch: 24, loss (training): 10.0464, loss (eval): 10.3246
Early-stopping. Training converged after 25 epochs.
start update posterior model
Epoch: 0, loss (training): 18.0434, loss (eval): 18.2439
Epoch: 1, loss (training): 18.0323, loss (eval): 18.0273
Epoch: 2, loss (training): 18.0343, loss (eval): 18.0197
Epoch: 3, loss (training): 18.0325, loss (eval): 18.0241
Epoch: 4, loss (training): 18.0326, loss (eval): 18.0224
Epoch: 5, loss (training): 18.0345, loss (eval): 18.0542
Epoch: 6, loss (training): 18.0306, loss (eval): 18.0282
Epoch: 7, loss (training): 18.034, loss (eval): 18.034
Epoch: 8, loss (training): 18.0302, loss (eval): 18.0329
Epoch: 9, loss (training): 18.0288, loss (eval): 18.0397
Epoch: 10, loss (training): 18.0325, loss (eval): 18.0371
Epoch: 11, loss (training): 18.037, loss (eval): 18.03
Epoch: 12, loss (training): 18.0314, loss (eval): 18.0293
Epoch: 13, loss (training): 18.0339, loss (eval): 18.0363
Epoch: 14, loss (training): 18.0335, loss (eval): 18.0383
Epoch: 15, loss (training): 18.0307, loss (eval): 18.0375
Epoch: 16, loss (training): 18.0316, loss (eval): 18.0391
Epoch: 17, loss (training): 18.035, loss (eval): 18.0366
Epoch: 18, loss (training): 18.0369, loss (eval): 18.0271
Epoch: 19, loss (training): 18.035, loss (eval): 18.0426
Epoch: 20, loss (training): 18.03, loss (eval): 18.0203
Epoch: 21, loss (training): 18.0313, loss (eval): 18.0279
Early-stopping. Training converged after 22 epochs.
Iteration: 10
optimizer_post_lr: [0.001260498819449218]
prob_prior: 0.0018363047770289071
start update likelihood model
Epoch: 0, loss (training): 10.3143, loss (eval): 10.2712
Epoch: 1, loss (training): 10.2009, loss (eval): 10.155
Epoch: 2, loss (training): 10.1772, loss (eval): 10.1067
Epoch: 3, loss (training): 10.1689, loss (eval): 10.1501
Epoch: 4, loss (training): 10.1644, loss (eval): 10.1468
Epoch: 5, loss (training): 10.1665, loss (eval): 10.1489
Epoch: 6, loss (training): 10.1636, loss (eval): 10.0958
Epoch: 7, loss (training): 10.1479, loss (eval): 10.0838
Epoch: 8, loss (training): 10.1464, loss (eval): 10.1377
Epoch: 9, loss (training): 10.1591, loss (eval): 10.2007
Epoch: 10, loss (training): 10.1285, loss (eval): 10.143
Epoch: 11, loss (training): 10.1487, loss (eval): 10.0894
Epoch: 12, loss (training): 10.1569, loss (eval): 10.2014
Epoch: 13, loss (training): 10.1415, loss (eval): 10.1283
Epoch: 14, loss (training): 10.1037, loss (eval): 10.1311
Epoch: 15, loss (training): 10.1291, loss (eval): 10.1186
Epoch: 16, loss (training): 10.1033, loss (eval): 10.122
Epoch: 17, loss (training): 10.1055, loss (eval): 10.1515
Epoch: 18, loss (training): 10.0958, loss (eval): 10.1319
Epoch: 19, loss (training): 10.115, loss (eval): 10.0824
Epoch: 20, loss (training): 10.11, loss (eval): 10.1266
Epoch: 21, loss (training): 10.0942, loss (eval): 10.1226
Epoch: 22, loss (training): 10.1146, loss (eval): 10.1424
Epoch: 23, loss (training): 10.1003, loss (eval): 10.1027
Epoch: 24, loss (training): 10.1105, loss (eval): 10.1721
Epoch: 25, loss (training): 10.0779, loss (eval): 10.1338
Epoch: 26, loss (training): 10.1056, loss (eval): 10.1521
Epoch: 27, loss (training): 10.1224, loss (eval): 10.1479
Epoch: 28, loss (training): 10.0847, loss (eval): 10.1756
Epoch: 29, loss (training): 10.0878, loss (eval): 10.1055
Epoch: 30, loss (training): 10.0976, loss (eval): 10.1808
Epoch: 31, loss (training): 10.075, loss (eval): 10.1426
Epoch: 32, loss (training): 10.0894, loss (eval): 10.1449
Epoch: 33, loss (training): 10.0914, loss (eval): 10.2513
Epoch: 34, loss (training): 10.0795, loss (eval): 10.153
Epoch: 35, loss (training): 10.0653, loss (eval): 10.1558
Epoch: 36, loss (training): 10.0763, loss (eval): 10.1538
Epoch: 37, loss (training): 10.0998, loss (eval): 10.1544
Epoch: 38, loss (training): 10.0541, loss (eval): 10.2603
Early-stopping. Training converged after 39 epochs.
start update posterior model
Epoch: 0, loss (training): 17.2667, loss (eval): 18.0492
Epoch: 1, loss (training): 17.2336, loss (eval): 17.2161
Epoch: 2, loss (training): 17.2312, loss (eval): 17.2266
Epoch: 3, loss (training): 17.2371, loss (eval): 17.241
Epoch: 4, loss (training): 17.2366, loss (eval): 17.2327
Epoch: 5, loss (training): 17.2301, loss (eval): 17.2254
Epoch: 6, loss (training): 17.2318, loss (eval): 17.2337
Epoch: 7, loss (training): 17.2323, loss (eval): 17.2365
Epoch: 8, loss (training): 17.2339, loss (eval): 17.2298
Epoch: 9, loss (training): 17.23, loss (eval): 17.2268
Epoch: 10, loss (training): 17.2313, loss (eval): 17.2223
Epoch: 11, loss (training): 17.231, loss (eval): 17.2227
Epoch: 12, loss (training): 17.2307, loss (eval): 17.2323
Epoch: 13, loss (training): 17.2285, loss (eval): 17.2245
Epoch: 14, loss (training): 17.2302, loss (eval): 17.2887
Epoch: 15, loss (training): 17.2256, loss (eval): 17.2292
Epoch: 16, loss (training): 17.2291, loss (eval): 17.2312
Epoch: 17, loss (training): 17.2301, loss (eval): 17.2563
Epoch: 18, loss (training): 17.2292, loss (eval): 17.2713
Epoch: 19, loss (training): 17.2257, loss (eval): 17.224
Epoch: 20, loss (training): 17.223, loss (eval): 17.2419
Early-stopping. Training converged after 21 epochs.

Runtime:1542.44
0
1
2
3
4
5
6
7
8
9
