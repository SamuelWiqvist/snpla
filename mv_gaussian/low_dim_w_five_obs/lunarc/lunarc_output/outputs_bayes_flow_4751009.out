Input args:
Dim: 2
seed: 5
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/2d w 5 obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.805199354821816, eval loss: 6.430910587310791
Epoch: 1, loss: 0.49419709742069245, eval loss: 0.5557882189750671
Epoch: 2, loss: 0.4606439559045248, eval loss: 0.47094660997390747
Epoch: 3, loss: 0.4480877546791453, eval loss: 0.5004593729972839
Epoch: 4, loss: 0.432712147187558, eval loss: 0.45901480317115784
Epoch: 5, loss: 0.4229666924060439, eval loss: 0.5101715922355652
Epoch: 6, loss: 0.41917311810539104, eval loss: 0.4222334623336792
Epoch: 7, loss: 0.41393038332811555, eval loss: 0.5483160018920898
Epoch: 8, loss: 0.41139068320480876, eval loss: 0.45691588521003723
Epoch: 9, loss: 0.40293425045965703, eval loss: 0.4171239137649536
Epoch: 10, loss: 0.40335767035197934, eval loss: 0.4117564260959625
Epoch: 11, loss: 0.39984104344364824, eval loss: 0.3839873969554901
Epoch: 12, loss: 0.3997750754255685, eval loss: 0.3715997636318207
Epoch: 13, loss: 0.3974799315351993, eval loss: 0.43883001804351807
Epoch: 14, loss: 0.3948040689184563, eval loss: 0.39985188841819763
Epoch: 15, loss: 0.3927235358845792, eval loss: 0.4143601357936859
Epoch: 16, loss: 0.3941441115420457, eval loss: 0.39473241567611694
Epoch: 17, loss: 0.39173071021807115, eval loss: 0.405446320772171
Epoch: 18, loss: 0.391292703357758, eval loss: 0.39803388714790344
Epoch: 19, loss: 0.3912635084266367, eval loss: 0.40779897570610046
Epoch: 20, loss: 0.3882147799327504, eval loss: 0.39244362711906433
Epoch: 21, loss: 0.3912483659910504, eval loss: 0.4144068956375122
Epoch: 22, loss: 0.3870778952746332, eval loss: 0.381043940782547
Epoch: 23, loss: 0.3875488226208836, eval loss: 0.38957521319389343
Epoch: 24, loss: 0.3887288178812014, eval loss: 0.40002718567848206
Epoch: 25, loss: 0.3883976529344, eval loss: 0.4821396768093109
Epoch: 26, loss: 0.3890865671506617, eval loss: 0.3920433819293976
Epoch: 27, loss: 0.3868515272651348, eval loss: 0.45356452465057373
Epoch: 28, loss: 0.3868955810472835, eval loss: 0.3808619976043701
Epoch: 29, loss: 0.3888915958610596, eval loss: 0.39614224433898926
Epoch: 30, loss: 0.3875136041885707, eval loss: 0.40594786405563354
Epoch: 31, loss: 0.38635454736824615, eval loss: 0.37318071722984314
Epoch: 32, loss: 0.3869973322617079, eval loss: 0.3670734465122223
Epoch: 33, loss: 0.3861976357149251, eval loss: 0.3834385573863983
Epoch: 34, loss: 0.38791597037459724, eval loss: 0.37824222445487976
Epoch: 35, loss: 0.38630451625969725, eval loss: 0.40998539328575134
Epoch: 36, loss: 0.385096782676992, eval loss: 0.3826477825641632
Epoch: 37, loss: 0.3878202829882503, eval loss: 0.37734344601631165
Epoch: 38, loss: 0.38605840667143637, eval loss: 0.41602399945259094
Epoch: 39, loss: 0.3874023576191394, eval loss: 0.3828488886356354
Epoch: 40, loss: 0.3863227155918139, eval loss: 0.38061338663101196
Epoch: 41, loss: 0.385301261957793, eval loss: 0.37313711643218994
Epoch: 42, loss: 0.38595864654213075, eval loss: 0.3701196014881134
Epoch: 43, loss: 0.38660429605602986, eval loss: 0.39821651577949524
Epoch: 44, loss: 0.3851447964692488, eval loss: 0.3735258877277374
Epoch: 45, loss: 0.3882978658808861, eval loss: 0.4039812386035919
Epoch: 46, loss: 0.3870531521069643, eval loss: 0.38913384079933167
Epoch: 47, loss: 0.3877076470293105, eval loss: 0.40037116408348083
Epoch: 48, loss: 0.38534766893833877, eval loss: 0.378961443901062
Epoch: 49, loss: 0.3861584585544915, eval loss: 0.4018218219280243

Runtime:592.26
KL div untrained: 175460306067.1558
KL div trained: 0.0074
