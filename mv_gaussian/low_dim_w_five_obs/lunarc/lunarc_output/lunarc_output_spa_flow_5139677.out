Input args:
Dim: 2
seed: 8
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
[1.0, 0.4965853037914095, 0.2465969639416065, 0.12245642825298195, 0.06081006262521797, 0.0301973834223185, 0.014995576820477717, 0.007446583070924344, 0.003697863716482932, 0.0018363047770289071]
start full training
Iteration: 1
optimizer_post_lr: [0.002]
prob_prior: 1.0
start update likelihood model
Epoch: 0, loss (training): 27.0844, loss (eval): 39.1268
Epoch: 1, loss (training): 20.7343, loss (eval): 22.3825
Epoch: 2, loss (training): 18.5315, loss (eval): 19.2303
Epoch: 3, loss (training): 17.2692, loss (eval): 17.8621
Epoch: 4, loss (training): 16.2159, loss (eval): 16.7779
Epoch: 5, loss (training): 15.3008, loss (eval): 15.8561
Epoch: 6, loss (training): 14.3651, loss (eval): 14.929
Epoch: 7, loss (training): 13.489, loss (eval): 14.1169
Epoch: 8, loss (training): 12.959, loss (eval): 13.1758
Epoch: 9, loss (training): 12.3056, loss (eval): 12.7964
Epoch: 10, loss (training): 11.7755, loss (eval): 12.2414
Epoch: 11, loss (training): 11.3032, loss (eval): 11.718
Epoch: 12, loss (training): 10.9789, loss (eval): 11.2003
Epoch: 13, loss (training): 10.8163, loss (eval): 11.0995
Epoch: 14, loss (training): 10.6606, loss (eval): 10.9529
Epoch: 15, loss (training): 10.5524, loss (eval): 10.6631
Epoch: 16, loss (training): 10.4617, loss (eval): 10.6091
Epoch: 17, loss (training): 10.428, loss (eval): 10.6013
Epoch: 18, loss (training): 10.3363, loss (eval): 10.6408
Epoch: 19, loss (training): 10.321, loss (eval): 10.3356
Epoch: 20, loss (training): 10.2705, loss (eval): 10.4434
Epoch: 21, loss (training): 10.2503, loss (eval): 10.365
Epoch: 22, loss (training): 10.2518, loss (eval): 10.3801
Epoch: 23, loss (training): 10.2846, loss (eval): 10.4365
Epoch: 24, loss (training): 10.2657, loss (eval): 10.7044
Epoch: 25, loss (training): 10.1817, loss (eval): 10.4451
Epoch: 26, loss (training): 10.2088, loss (eval): 10.4827
Epoch: 27, loss (training): 10.1528, loss (eval): 10.4582
Epoch: 28, loss (training): 10.238, loss (eval): 10.34
Epoch: 29, loss (training): 10.1949, loss (eval): 10.51
Epoch: 30, loss (training): 10.1604, loss (eval): 10.2205
Epoch: 31, loss (training): 10.1363, loss (eval): 10.2837
Epoch: 32, loss (training): 10.1923, loss (eval): 10.5162
Epoch: 33, loss (training): 10.1457, loss (eval): 10.3302
Epoch: 34, loss (training): 10.1561, loss (eval): 10.415
Epoch: 35, loss (training): 10.1051, loss (eval): 10.2113
Epoch: 36, loss (training): 10.1016, loss (eval): 10.3439
Epoch: 37, loss (training): 10.1411, loss (eval): 10.503
Epoch: 38, loss (training): 10.0487, loss (eval): 10.3265
Epoch: 39, loss (training): 10.1099, loss (eval): 10.278
Epoch: 40, loss (training): 10.095, loss (eval): 10.3094
Epoch: 41, loss (training): 10.0791, loss (eval): 10.3716
Epoch: 42, loss (training): 10.0669, loss (eval): 10.2067
Epoch: 43, loss (training): 10.0942, loss (eval): 10.3366
Epoch: 44, loss (training): 10.0543, loss (eval): 10.3897
Epoch: 45, loss (training): 10.0172, loss (eval): 10.2302
Epoch: 46, loss (training): 10.0263, loss (eval): 10.2224
Epoch: 47, loss (training): 10.0295, loss (eval): 10.3216
Epoch: 48, loss (training): 10.0058, loss (eval): 10.2704
Epoch: 49, loss (training): 10.0232, loss (eval): 10.4477
Epoch: 50, loss (training): 10.0403, loss (eval): 10.2327
Epoch: 51, loss (training): 10.0679, loss (eval): 10.466
Epoch: 52, loss (training): 10.0266, loss (eval): 10.3312
Epoch: 53, loss (training): 10.0298, loss (eval): 10.2252
Epoch: 54, loss (training): 10.0242, loss (eval): 10.2539
Epoch: 55, loss (training): 10.0179, loss (eval): 10.3006
Epoch: 56, loss (training): 10.0102, loss (eval): 10.2475
Epoch: 57, loss (training): 9.9912, loss (eval): 10.2292
Epoch: 58, loss (training): 10.0197, loss (eval): 10.2029
Epoch: 59, loss (training): 10.0374, loss (eval): 10.3132
Epoch: 60, loss (training): 9.9884, loss (eval): 10.2395
Epoch: 61, loss (training): 10.0111, loss (eval): 10.4568
Epoch: 62, loss (training): 10.0153, loss (eval): 10.2906
Epoch: 63, loss (training): 10.0588, loss (eval): 10.2588
Epoch: 64, loss (training): 10.0289, loss (eval): 10.4954
Epoch: 65, loss (training): 10.0124, loss (eval): 10.3042
Epoch: 66, loss (training): 10.0147, loss (eval): 10.2632
Epoch: 67, loss (training): 9.946, loss (eval): 10.2073
Epoch: 68, loss (training): 10.0259, loss (eval): 10.2797
Epoch: 69, loss (training): 10.0138, loss (eval): 10.156
Epoch: 70, loss (training): 10.0387, loss (eval): 10.2679
Epoch: 71, loss (training): 9.962, loss (eval): 10.2278
Epoch: 72, loss (training): 10.0194, loss (eval): 10.2617
Epoch: 73, loss (training): 9.9699, loss (eval): 10.3774
Epoch: 74, loss (training): 9.9774, loss (eval): 10.3956
start update posterior model from prior pred - hot start
Epoch: 0, loss (training): 3.4179, loss (eval): 6.7587
Epoch: 1, loss (training): 1.881, loss (eval): 1.9403
Epoch: 2, loss (training): 1.3963, loss (eval): 1.423
Epoch: 3, loss (training): 0.954, loss (eval): 1.2875
Epoch: 4, loss (training): 0.8759, loss (eval): 1.0235
Epoch: 5, loss (training): 0.7828, loss (eval): 1.0818
Epoch: 6, loss (training): 0.6903, loss (eval): 0.8396
Epoch: 7, loss (training): 0.584, loss (eval): 0.7677
Epoch: 8, loss (training): 0.5291, loss (eval): 0.7444
Epoch: 9, loss (training): 0.531, loss (eval): 0.7402
start update posterior model
Epoch: 0, loss (training): 12.5156, loss (eval): 12.463
Epoch: 1, loss (training): 12.4502, loss (eval): 12.4309
Epoch: 2, loss (training): 12.4444, loss (eval): 12.4836
Epoch: 3, loss (training): 12.4477, loss (eval): 12.4244
Epoch: 4, loss (training): 12.4415, loss (eval): 12.43
Epoch: 5, loss (training): 12.4327, loss (eval): 12.4739
Epoch: 6, loss (training): 12.4394, loss (eval): 12.4135
Epoch: 7, loss (training): 12.4352, loss (eval): 12.5084
Epoch: 8, loss (training): 12.433, loss (eval): 12.4148
Epoch: 9, loss (training): 12.4362, loss (eval): 12.427
Epoch: 10, loss (training): 12.4333, loss (eval): 12.4142
Epoch: 11, loss (training): 12.4294, loss (eval): 12.4705
Epoch: 12, loss (training): 12.4214, loss (eval): 12.4213
Epoch: 13, loss (training): 12.4435, loss (eval): 12.4037
Epoch: 14, loss (training): 12.4161, loss (eval): 12.4031
Epoch: 15, loss (training): 12.4149, loss (eval): 12.4119
Epoch: 16, loss (training): 12.4281, loss (eval): 12.401
Epoch: 17, loss (training): 12.4242, loss (eval): 12.3944
Epoch: 18, loss (training): 12.4212, loss (eval): 12.5184
Epoch: 19, loss (training): 12.4338, loss (eval): 12.4491
Epoch: 20, loss (training): 12.424, loss (eval): 12.3962
Epoch: 21, loss (training): 12.4122, loss (eval): 12.4017
Epoch: 22, loss (training): 12.4292, loss (eval): 12.3973
Epoch: 23, loss (training): 12.4371, loss (eval): 12.4003
Epoch: 24, loss (training): 12.4184, loss (eval): 12.4103
Epoch: 25, loss (training): 12.4143, loss (eval): 12.3982
Epoch: 26, loss (training): 12.4289, loss (eval): 12.4532
Epoch: 27, loss (training): 12.4274, loss (eval): 12.4153
Epoch: 28, loss (training): 12.4259, loss (eval): 12.4998
Epoch: 29, loss (training): 12.4228, loss (eval): 12.4029
Epoch: 30, loss (training): 12.4151, loss (eval): 12.4342
Epoch: 31, loss (training): 12.4181, loss (eval): 12.4164
Epoch: 32, loss (training): 12.4195, loss (eval): 12.3992
Epoch: 33, loss (training): 12.4197, loss (eval): 12.4148
Epoch: 34, loss (training): 12.4134, loss (eval): 12.3968
Epoch: 35, loss (training): 12.4103, loss (eval): 12.4235
Epoch: 36, loss (training): 12.4142, loss (eval): 12.4393
Early-stopping. Training converged after 37 epochs.
Iteration: 2
optimizer_post_lr: [0.0019]
prob_prior: 0.4965853037914095
start update likelihood model
Epoch: 0, loss (training): 10.3217, loss (eval): 10.2752
Epoch: 1, loss (training): 10.3137, loss (eval): 10.2707
Epoch: 2, loss (training): 10.2154, loss (eval): 10.2934
Epoch: 3, loss (training): 10.2258, loss (eval): 10.1869
Epoch: 4, loss (training): 10.165, loss (eval): 10.2151
Epoch: 5, loss (training): 10.1619, loss (eval): 10.2322
Epoch: 6, loss (training): 10.1301, loss (eval): 10.2248
Epoch: 7, loss (training): 10.1295, loss (eval): 10.3895
Epoch: 8, loss (training): 10.1211, loss (eval): 10.2815
Epoch: 9, loss (training): 10.1219, loss (eval): 10.2159
Epoch: 10, loss (training): 10.1207, loss (eval): 10.3968
Epoch: 11, loss (training): 10.0849, loss (eval): 10.2787
Epoch: 12, loss (training): 10.0839, loss (eval): 10.2261
Epoch: 13, loss (training): 10.0897, loss (eval): 10.176
Epoch: 14, loss (training): 10.0937, loss (eval): 10.3783
Epoch: 15, loss (training): 10.1247, loss (eval): 10.1989
Epoch: 16, loss (training): 10.1057, loss (eval): 10.2585
Epoch: 17, loss (training): 10.0776, loss (eval): 10.4502
Epoch: 18, loss (training): 10.0856, loss (eval): 10.218
Epoch: 19, loss (training): 10.096, loss (eval): 10.2952
Epoch: 20, loss (training): 10.0538, loss (eval): 10.2962
Epoch: 21, loss (training): 10.0608, loss (eval): 10.1988
Epoch: 22, loss (training): 10.0578, loss (eval): 10.4395
Epoch: 23, loss (training): 10.0606, loss (eval): 10.3443
Epoch: 24, loss (training): 10.0322, loss (eval): 10.1458
Epoch: 25, loss (training): 10.0449, loss (eval): 10.2938
Epoch: 26, loss (training): 10.0425, loss (eval): 10.1743
Epoch: 27, loss (training): 10.0572, loss (eval): 10.2788
Epoch: 28, loss (training): 10.0342, loss (eval): 10.2755
Epoch: 29, loss (training): 10.0382, loss (eval): 10.1953
Epoch: 30, loss (training): 10.0249, loss (eval): 10.272
Epoch: 31, loss (training): 10.0176, loss (eval): 10.2891
Epoch: 32, loss (training): 10.0226, loss (eval): 10.2175
Epoch: 33, loss (training): 9.9945, loss (eval): 10.2079
Epoch: 34, loss (training): 10.0615, loss (eval): 10.274
Epoch: 35, loss (training): 10.0732, loss (eval): 10.2543
Epoch: 36, loss (training): 10.0677, loss (eval): 10.2408
Epoch: 37, loss (training): 10.0234, loss (eval): 10.2583
Epoch: 38, loss (training): 9.998, loss (eval): 10.272
Epoch: 39, loss (training): 10.0627, loss (eval): 10.2223
Epoch: 40, loss (training): 10.0343, loss (eval): 10.352
Epoch: 41, loss (training): 9.9698, loss (eval): 10.2809
Epoch: 42, loss (training): 10.0263, loss (eval): 10.3609
Epoch: 43, loss (training): 10.0046, loss (eval): 10.3471
Early-stopping. Training converged after 44 epochs.
start update posterior model
Epoch: 0, loss (training): 13.4233, loss (eval): 13.6863
Epoch: 1, loss (training): 13.4171, loss (eval): 13.407
Epoch: 2, loss (training): 13.4173, loss (eval): 13.4282
Epoch: 3, loss (training): 13.4237, loss (eval): 13.399
Epoch: 4, loss (training): 13.4198, loss (eval): 13.4223
Epoch: 5, loss (training): 13.4191, loss (eval): 13.4018
Epoch: 6, loss (training): 13.4195, loss (eval): 13.4201
Epoch: 7, loss (training): 13.4173, loss (eval): 13.406
Epoch: 8, loss (training): 13.4143, loss (eval): 13.4179
Epoch: 9, loss (training): 13.412, loss (eval): 13.4178
Epoch: 10, loss (training): 13.4116, loss (eval): 13.4133
Epoch: 11, loss (training): 13.4146, loss (eval): 13.4096
Epoch: 12, loss (training): 13.4169, loss (eval): 13.4032
Epoch: 13, loss (training): 13.4162, loss (eval): 13.3939
Epoch: 14, loss (training): 13.4268, loss (eval): 13.3878
Epoch: 15, loss (training): 13.4051, loss (eval): 13.4239
Epoch: 16, loss (training): 13.4207, loss (eval): 13.4016
Epoch: 17, loss (training): 13.4116, loss (eval): 13.4528
Epoch: 18, loss (training): 13.4128, loss (eval): 13.4013
Epoch: 19, loss (training): 13.4122, loss (eval): 13.3924
Epoch: 20, loss (training): 13.4122, loss (eval): 13.3939
Epoch: 21, loss (training): 13.4117, loss (eval): 13.4197
Epoch: 22, loss (training): 13.4068, loss (eval): 13.4062
Epoch: 23, loss (training): 13.4146, loss (eval): 13.3946
Epoch: 24, loss (training): 13.4097, loss (eval): 13.3901
Epoch: 25, loss (training): 13.4131, loss (eval): 13.4179
Epoch: 26, loss (training): 13.4103, loss (eval): 13.4341
Epoch: 27, loss (training): 13.4121, loss (eval): 13.4072
Epoch: 28, loss (training): 13.4141, loss (eval): 13.3922
Epoch: 29, loss (training): 13.4121, loss (eval): 13.4349
Epoch: 30, loss (training): 13.4088, loss (eval): 13.3926
Epoch: 31, loss (training): 13.4094, loss (eval): 13.4014
Epoch: 32, loss (training): 13.4081, loss (eval): 13.4906
Epoch: 33, loss (training): 13.4122, loss (eval): 13.4256
Early-stopping. Training converged after 34 epochs.
Iteration: 3
optimizer_post_lr: [0.001805]
prob_prior: 0.2465969639416065
start update likelihood model
Epoch: 0, loss (training): 10.232, loss (eval): 10.3938
Epoch: 1, loss (training): 10.1806, loss (eval): 10.4914
Epoch: 2, loss (training): 10.1034, loss (eval): 10.3146
Epoch: 3, loss (training): 10.1276, loss (eval): 10.3682
Epoch: 4, loss (training): 10.0837, loss (eval): 10.4064
Epoch: 5, loss (training): 10.0709, loss (eval): 10.4207
Epoch: 6, loss (training): 10.0729, loss (eval): 10.2872
Epoch: 7, loss (training): 10.0718, loss (eval): 10.4118
Epoch: 8, loss (training): 10.0723, loss (eval): 10.4322
Epoch: 9, loss (training): 10.076, loss (eval): 10.4486
Epoch: 10, loss (training): 10.0831, loss (eval): 10.4079
Epoch: 11, loss (training): 10.0412, loss (eval): 10.3319
Epoch: 12, loss (training): 10.0584, loss (eval): 10.333
Epoch: 13, loss (training): 10.0696, loss (eval): 10.5179
Epoch: 14, loss (training): 10.062, loss (eval): 10.4759
Epoch: 15, loss (training): 10.0105, loss (eval): 10.3072
Epoch: 16, loss (training): 10.0241, loss (eval): 10.3598
Epoch: 17, loss (training): 10.0252, loss (eval): 10.3553
Epoch: 18, loss (training): 10.0313, loss (eval): 10.3897
Epoch: 19, loss (training): 9.9862, loss (eval): 10.3511
Epoch: 20, loss (training): 10.027, loss (eval): 10.3991
Epoch: 21, loss (training): 10.0111, loss (eval): 10.4058
Epoch: 22, loss (training): 9.9946, loss (eval): 10.3583
Epoch: 23, loss (training): 10.017, loss (eval): 10.334
Epoch: 24, loss (training): 10.0033, loss (eval): 10.3688
Epoch: 25, loss (training): 9.9925, loss (eval): 10.5114
Early-stopping. Training converged after 26 epochs.
start update posterior model
Epoch: 0, loss (training): 13.4385, loss (eval): 13.4561
Epoch: 1, loss (training): 13.4475, loss (eval): 13.4286
Epoch: 2, loss (training): 13.4421, loss (eval): 13.4315
Epoch: 3, loss (training): 13.4416, loss (eval): 13.4273
Epoch: 4, loss (training): 13.4494, loss (eval): 13.4342
Epoch: 5, loss (training): 13.4431, loss (eval): 13.4298
Epoch: 6, loss (training): 13.446, loss (eval): 13.4534
Epoch: 7, loss (training): 13.443, loss (eval): 13.4411
Epoch: 8, loss (training): 13.4429, loss (eval): 13.4333
Epoch: 9, loss (training): 13.4474, loss (eval): 13.4532
Epoch: 10, loss (training): 13.448, loss (eval): 13.4482
Epoch: 11, loss (training): 13.4407, loss (eval): 13.4476
Epoch: 12, loss (training): 13.4414, loss (eval): 13.4245
Epoch: 13, loss (training): 13.4378, loss (eval): 13.4463
Epoch: 14, loss (training): 13.4402, loss (eval): 13.4442
Epoch: 15, loss (training): 13.4437, loss (eval): 13.4296
Epoch: 16, loss (training): 13.44, loss (eval): 13.4401
Epoch: 17, loss (training): 13.4436, loss (eval): 13.4241
Epoch: 18, loss (training): 13.4422, loss (eval): 13.435
Epoch: 19, loss (training): 13.4381, loss (eval): 13.4546
Epoch: 20, loss (training): 13.4403, loss (eval): 13.4485
Epoch: 21, loss (training): 13.4509, loss (eval): 13.4308
Epoch: 22, loss (training): 13.4358, loss (eval): 13.4458
Epoch: 23, loss (training): 13.4363, loss (eval): 13.4447
Epoch: 24, loss (training): 13.4453, loss (eval): 13.4476
Epoch: 25, loss (training): 13.4448, loss (eval): 13.4521
Epoch: 26, loss (training): 13.4373, loss (eval): 13.4555
Epoch: 27, loss (training): 13.4466, loss (eval): 13.4643
Epoch: 28, loss (training): 13.4399, loss (eval): 13.4425
Epoch: 29, loss (training): 13.4424, loss (eval): 13.4631
Epoch: 30, loss (training): 13.4412, loss (eval): 13.4383
Epoch: 31, loss (training): 13.4431, loss (eval): 13.4335
Epoch: 32, loss (training): 13.4408, loss (eval): 13.427
Epoch: 33, loss (training): 13.4407, loss (eval): 13.4278
Epoch: 34, loss (training): 13.4392, loss (eval): 13.4456
Epoch: 35, loss (training): 13.4408, loss (eval): 13.439
Epoch: 36, loss (training): 13.4455, loss (eval): 13.4384
Early-stopping. Training converged after 37 epochs.
Iteration: 4
optimizer_post_lr: [0.00171475]
prob_prior: 0.12245642825298195
start update likelihood model
Epoch: 0, loss (training): 10.1577, loss (eval): 10.1864
Epoch: 1, loss (training): 10.1202, loss (eval): 10.3086
Epoch: 2, loss (training): 10.1005, loss (eval): 10.3285
Epoch: 3, loss (training): 10.0289, loss (eval): 10.2371
Epoch: 4, loss (training): 10.0294, loss (eval): 10.3062
Epoch: 5, loss (training): 10.0566, loss (eval): 10.2216
Epoch: 6, loss (training): 10.0092, loss (eval): 10.2357
Epoch: 7, loss (training): 10.0722, loss (eval): 10.3121
Epoch: 8, loss (training): 10.0094, loss (eval): 10.2155
Epoch: 9, loss (training): 10.0522, loss (eval): 10.2158
Epoch: 10, loss (training): 10.0398, loss (eval): 10.2235
Epoch: 11, loss (training): 10.0005, loss (eval): 10.2798
Epoch: 12, loss (training): 9.9925, loss (eval): 10.3232
Epoch: 13, loss (training): 9.9911, loss (eval): 10.27
Epoch: 14, loss (training): 9.9975, loss (eval): 10.307
Epoch: 15, loss (training): 9.9959, loss (eval): 10.1905
Epoch: 16, loss (training): 9.9998, loss (eval): 10.4845
Epoch: 17, loss (training): 9.9949, loss (eval): 10.2564
Epoch: 18, loss (training): 10.0288, loss (eval): 10.258
Epoch: 19, loss (training): 9.9636, loss (eval): 10.3144
Early-stopping. Training converged after 20 epochs.
start update posterior model
Epoch: 0, loss (training): 12.4559, loss (eval): 12.4636
Epoch: 1, loss (training): 12.4497, loss (eval): 12.4361
Epoch: 2, loss (training): 12.4475, loss (eval): 12.4402
Epoch: 3, loss (training): 12.4506, loss (eval): 12.4475
Epoch: 4, loss (training): 12.4474, loss (eval): 12.4455
Epoch: 5, loss (training): 12.4608, loss (eval): 12.4417
Epoch: 6, loss (training): 12.4502, loss (eval): 12.441
Epoch: 7, loss (training): 12.447, loss (eval): 12.4538
Epoch: 8, loss (training): 12.4541, loss (eval): 12.4688
Epoch: 9, loss (training): 12.4459, loss (eval): 12.4737
Epoch: 10, loss (training): 12.4548, loss (eval): 12.4373
Epoch: 11, loss (training): 12.4467, loss (eval): 12.4419
Epoch: 12, loss (training): 12.4489, loss (eval): 12.4469
Epoch: 13, loss (training): 12.449, loss (eval): 12.439
Epoch: 14, loss (training): 12.452, loss (eval): 12.442
Epoch: 15, loss (training): 12.4486, loss (eval): 12.4758
Epoch: 16, loss (training): 12.4487, loss (eval): 12.4349
Epoch: 17, loss (training): 12.4459, loss (eval): 12.4525
Epoch: 18, loss (training): 12.4515, loss (eval): 12.4457
Epoch: 19, loss (training): 12.4532, loss (eval): 12.4429
Epoch: 20, loss (training): 12.4506, loss (eval): 12.4449
Epoch: 21, loss (training): 12.4478, loss (eval): 12.4427
Epoch: 22, loss (training): 12.4513, loss (eval): 12.4497
Epoch: 23, loss (training): 12.4476, loss (eval): 12.4455
Epoch: 24, loss (training): 12.4491, loss (eval): 12.4567
Epoch: 25, loss (training): 12.4452, loss (eval): 12.4437
Epoch: 26, loss (training): 12.4497, loss (eval): 12.4398
Epoch: 27, loss (training): 12.4477, loss (eval): 12.4499
Epoch: 28, loss (training): 12.4545, loss (eval): 12.4353
Epoch: 29, loss (training): 12.446, loss (eval): 12.4392
Epoch: 30, loss (training): 12.4495, loss (eval): 12.4477
Epoch: 31, loss (training): 12.4486, loss (eval): 12.4458
Epoch: 32, loss (training): 12.4492, loss (eval): 12.4414
Epoch: 33, loss (training): 12.4513, loss (eval): 12.4516
Epoch: 34, loss (training): 12.4495, loss (eval): 12.4477
Epoch: 35, loss (training): 12.4472, loss (eval): 12.4407
Early-stopping. Training converged after 36 epochs.
Iteration: 5
optimizer_post_lr: [0.0016290124999999997]
prob_prior: 0.06081006262521797
start update likelihood model
Epoch: 0, loss (training): 10.1855, loss (eval): 10.0867
Epoch: 1, loss (training): 10.1647, loss (eval): 10.207
Epoch: 2, loss (training): 10.136, loss (eval): 10.1979
Epoch: 3, loss (training): 10.1331, loss (eval): 10.1239
Epoch: 4, loss (training): 10.1108, loss (eval): 10.2131
Epoch: 5, loss (training): 10.1131, loss (eval): 10.1911
Epoch: 6, loss (training): 10.0866, loss (eval): 10.1452
Epoch: 7, loss (training): 10.101, loss (eval): 10.123
Epoch: 8, loss (training): 10.0751, loss (eval): 10.0682
Epoch: 9, loss (training): 10.1118, loss (eval): 10.1107
Epoch: 10, loss (training): 10.0941, loss (eval): 10.085
Epoch: 11, loss (training): 10.0903, loss (eval): 10.188
Epoch: 12, loss (training): 10.1038, loss (eval): 10.1893
Epoch: 13, loss (training): 10.082, loss (eval): 10.1248
Epoch: 14, loss (training): 10.0854, loss (eval): 10.1515
Epoch: 15, loss (training): 10.1122, loss (eval): 10.1945
Epoch: 16, loss (training): 10.0719, loss (eval): 10.1546
Epoch: 17, loss (training): 10.0665, loss (eval): 10.1087
Epoch: 18, loss (training): 10.0729, loss (eval): 10.2189
Epoch: 19, loss (training): 10.0783, loss (eval): 10.0757
Epoch: 20, loss (training): 10.0784, loss (eval): 10.1889
Epoch: 21, loss (training): 10.0481, loss (eval): 10.1262
Epoch: 22, loss (training): 10.0489, loss (eval): 10.1481
Epoch: 23, loss (training): 10.0434, loss (eval): 10.0963
Epoch: 24, loss (training): 10.0392, loss (eval): 10.1337
Epoch: 25, loss (training): 10.0437, loss (eval): 10.1649
Epoch: 26, loss (training): 10.0376, loss (eval): 10.0983
Epoch: 27, loss (training): 10.0388, loss (eval): 10.119
Early-stopping. Training converged after 28 epochs.
start update posterior model
Epoch: 0, loss (training): 13.013, loss (eval): 13.2267
Epoch: 1, loss (training): 13.0097, loss (eval): 13.002
Epoch: 2, loss (training): 13.005, loss (eval): 13.0049
Epoch: 3, loss (training): 13.0086, loss (eval): 13.0022
Epoch: 4, loss (training): 13.0067, loss (eval): 12.9997
Epoch: 5, loss (training): 13.007, loss (eval): 13.0022
Epoch: 6, loss (training): 13.0084, loss (eval): 13.0164
Epoch: 7, loss (training): 13.0066, loss (eval): 13.0052
Epoch: 8, loss (training): 13.007, loss (eval): 12.9988
Epoch: 9, loss (training): 13.013, loss (eval): 13.0057
Epoch: 10, loss (training): 13.0031, loss (eval): 13.0019
Epoch: 11, loss (training): 13.0067, loss (eval): 12.9964
Epoch: 12, loss (training): 13.0042, loss (eval): 12.9923
Epoch: 13, loss (training): 13.0069, loss (eval): 13.0031
Epoch: 14, loss (training): 13.0074, loss (eval): 13.0178
Epoch: 15, loss (training): 13.0029, loss (eval): 12.9979
Epoch: 16, loss (training): 13.0033, loss (eval): 13.0004
Epoch: 17, loss (training): 13.0029, loss (eval): 13.004
Epoch: 18, loss (training): 13.0053, loss (eval): 13.0014
Epoch: 19, loss (training): 13.0044, loss (eval): 13.0042
Epoch: 20, loss (training): 13.0065, loss (eval): 12.9949
Epoch: 21, loss (training): 13.0074, loss (eval): 13.0192
Epoch: 22, loss (training): 13.0075, loss (eval): 13.0021
Epoch: 23, loss (training): 13.0075, loss (eval): 13.0128
Epoch: 24, loss (training): 13.0077, loss (eval): 13.0035
Epoch: 25, loss (training): 13.0057, loss (eval): 12.9998
Epoch: 26, loss (training): 13.0041, loss (eval): 12.9955
Epoch: 27, loss (training): 13.0092, loss (eval): 13.0181
Epoch: 28, loss (training): 13.0024, loss (eval): 13.0023
Epoch: 29, loss (training): 13.0056, loss (eval): 13.0068
Epoch: 30, loss (training): 13.0042, loss (eval): 13.0116
Epoch: 31, loss (training): 13.0067, loss (eval): 13.0034
Early-stopping. Training converged after 32 epochs.
Iteration: 6
optimizer_post_lr: [0.0015475618749999996]
prob_prior: 0.0301973834223185
start update likelihood model
Epoch: 0, loss (training): 10.1843, loss (eval): 10.178
Epoch: 1, loss (training): 10.1424, loss (eval): 10.1857
Epoch: 2, loss (training): 10.1009, loss (eval): 10.1379
Epoch: 3, loss (training): 10.0915, loss (eval): 10.1368
Epoch: 4, loss (training): 10.089, loss (eval): 10.1603
Epoch: 5, loss (training): 10.0649, loss (eval): 10.28
Epoch: 6, loss (training): 10.0875, loss (eval): 10.194
Epoch: 7, loss (training): 10.0685, loss (eval): 10.2291
Epoch: 8, loss (training): 10.0387, loss (eval): 10.1639
Epoch: 9, loss (training): 10.0423, loss (eval): 10.2182
Epoch: 10, loss (training): 10.0262, loss (eval): 10.182
Epoch: 11, loss (training): 10.0356, loss (eval): 10.1601
Epoch: 12, loss (training): 10.0153, loss (eval): 10.217
Epoch: 13, loss (training): 10.0499, loss (eval): 10.1805
Epoch: 14, loss (training): 10.0594, loss (eval): 10.3083
Epoch: 15, loss (training): 10.0681, loss (eval): 10.1643
Epoch: 16, loss (training): 10.048, loss (eval): 10.2399
Epoch: 17, loss (training): 10.029, loss (eval): 10.1613
Epoch: 18, loss (training): 10.0084, loss (eval): 10.1845
Epoch: 19, loss (training): 10.0271, loss (eval): 10.2143
Epoch: 20, loss (training): 10.0454, loss (eval): 10.1883
Epoch: 21, loss (training): 10.0173, loss (eval): 10.3477
Epoch: 22, loss (training): 10.0245, loss (eval): 10.3083
Early-stopping. Training converged after 23 epochs.
start update posterior model
Epoch: 0, loss (training): 13.1387, loss (eval): 13.3845
Epoch: 1, loss (training): 13.1296, loss (eval): 13.1211
Epoch: 2, loss (training): 13.1293, loss (eval): 13.1252
Epoch: 3, loss (training): 13.1347, loss (eval): 13.1345
Epoch: 4, loss (training): 13.134, loss (eval): 13.1317
Epoch: 5, loss (training): 13.1328, loss (eval): 13.1304
Epoch: 6, loss (training): 13.1328, loss (eval): 13.1472
Epoch: 7, loss (training): 13.1282, loss (eval): 13.1317
Epoch: 8, loss (training): 13.1278, loss (eval): 13.1294
Epoch: 9, loss (training): 13.1286, loss (eval): 13.144
Epoch: 10, loss (training): 13.1313, loss (eval): 13.148
Epoch: 11, loss (training): 13.1301, loss (eval): 13.1221
Epoch: 12, loss (training): 13.1333, loss (eval): 13.1491
Epoch: 13, loss (training): 13.1305, loss (eval): 13.1222
Epoch: 14, loss (training): 13.1272, loss (eval): 13.1247
Epoch: 15, loss (training): 13.1308, loss (eval): 13.1369
Epoch: 16, loss (training): 13.1319, loss (eval): 13.149
Epoch: 17, loss (training): 13.1293, loss (eval): 13.1336
Epoch: 18, loss (training): 13.1331, loss (eval): 13.1254
Epoch: 19, loss (training): 13.1312, loss (eval): 13.1502
Epoch: 20, loss (training): 13.1284, loss (eval): 13.1254
Early-stopping. Training converged after 21 epochs.
Iteration: 7
optimizer_post_lr: [0.0014701837812499995]
prob_prior: 0.014995576820477717
start update likelihood model
Epoch: 0, loss (training): 10.1503, loss (eval): 10.2573
Epoch: 1, loss (training): 10.1111, loss (eval): 10.2153
Epoch: 2, loss (training): 10.0938, loss (eval): 10.2526
Epoch: 3, loss (training): 10.0651, loss (eval): 10.2316
Epoch: 4, loss (training): 10.0736, loss (eval): 10.2996
Epoch: 5, loss (training): 10.0782, loss (eval): 10.3303
Epoch: 6, loss (training): 10.0672, loss (eval): 10.2808
Epoch: 7, loss (training): 10.0584, loss (eval): 10.2874
Epoch: 8, loss (training): 10.0687, loss (eval): 10.2635
Epoch: 9, loss (training): 10.0543, loss (eval): 10.3026
Epoch: 10, loss (training): 10.0456, loss (eval): 10.178
Epoch: 11, loss (training): 10.042, loss (eval): 10.2844
Epoch: 12, loss (training): 10.0358, loss (eval): 10.2567
Epoch: 13, loss (training): 10.0499, loss (eval): 10.2125
Epoch: 14, loss (training): 10.0495, loss (eval): 10.2698
Epoch: 15, loss (training): 10.0971, loss (eval): 10.3322
Epoch: 16, loss (training): 10.0472, loss (eval): 10.2423
Epoch: 17, loss (training): 10.0333, loss (eval): 10.3659
Epoch: 18, loss (training): 10.0072, loss (eval): 10.2775
Epoch: 19, loss (training): 10.0187, loss (eval): 10.2803
Epoch: 20, loss (training): 10.0193, loss (eval): 10.2589
Epoch: 21, loss (training): 10.0246, loss (eval): 10.3764
Epoch: 22, loss (training): 10.0222, loss (eval): 10.3397
Epoch: 23, loss (training): 10.0122, loss (eval): 10.3087
Epoch: 24, loss (training): 10.0168, loss (eval): 10.3669
Epoch: 25, loss (training): 10.0045, loss (eval): 10.3645
Epoch: 26, loss (training): 10.0273, loss (eval): 10.3173
Epoch: 27, loss (training): 10.0067, loss (eval): 10.2765
Epoch: 28, loss (training): 9.9842, loss (eval): 10.3992
Epoch: 29, loss (training): 10.0222, loss (eval): 10.3295
Early-stopping. Training converged after 30 epochs.
start update posterior model
Epoch: 0, loss (training): 12.9374, loss (eval): 13.54
Epoch: 1, loss (training): 12.9169, loss (eval): 12.9182
Epoch: 2, loss (training): 12.9145, loss (eval): 12.9143
Epoch: 3, loss (training): 12.9158, loss (eval): 12.916
Epoch: 4, loss (training): 12.9166, loss (eval): 12.9155
Epoch: 5, loss (training): 12.9215, loss (eval): 12.9131
Epoch: 6, loss (training): 12.9176, loss (eval): 12.9262
Epoch: 7, loss (training): 12.9207, loss (eval): 12.9132
Epoch: 8, loss (training): 12.9206, loss (eval): 12.9146
Epoch: 9, loss (training): 12.9213, loss (eval): 12.9286
Epoch: 10, loss (training): 12.9158, loss (eval): 12.9234
Epoch: 11, loss (training): 12.9158, loss (eval): 12.9166
Epoch: 12, loss (training): 12.9201, loss (eval): 12.9124
Epoch: 13, loss (training): 12.9175, loss (eval): 12.9076
Epoch: 14, loss (training): 12.9169, loss (eval): 12.9125
Epoch: 15, loss (training): 12.9204, loss (eval): 12.911
Epoch: 16, loss (training): 12.9199, loss (eval): 12.9222
Epoch: 17, loss (training): 12.9191, loss (eval): 12.9118
Epoch: 18, loss (training): 12.9184, loss (eval): 12.9149
Epoch: 19, loss (training): 12.9136, loss (eval): 12.9093
Epoch: 20, loss (training): 12.9157, loss (eval): 12.9168
Epoch: 21, loss (training): 12.9216, loss (eval): 12.9111
Epoch: 22, loss (training): 12.9179, loss (eval): 12.9161
Epoch: 23, loss (training): 12.9176, loss (eval): 12.9161
Epoch: 24, loss (training): 12.9162, loss (eval): 12.9196
Epoch: 25, loss (training): 12.9169, loss (eval): 12.9249
Epoch: 26, loss (training): 12.9172, loss (eval): 12.9197
Epoch: 27, loss (training): 12.9197, loss (eval): 12.9088
Epoch: 28, loss (training): 12.9193, loss (eval): 12.9172
Epoch: 29, loss (training): 12.9186, loss (eval): 12.9118
Epoch: 30, loss (training): 12.9174, loss (eval): 12.909
Epoch: 31, loss (training): 12.9166, loss (eval): 12.9118
Epoch: 32, loss (training): 12.9175, loss (eval): 12.9147
Early-stopping. Training converged after 33 epochs.
Iteration: 8
optimizer_post_lr: [0.0013966745921874994]
prob_prior: 0.007446583070924344
start update likelihood model
Epoch: 0, loss (training): 10.2009, loss (eval): 10.1119
Epoch: 1, loss (training): 10.1349, loss (eval): 9.9767
Epoch: 2, loss (training): 10.1581, loss (eval): 10.1135
Epoch: 3, loss (training): 10.1131, loss (eval): 9.9781
Epoch: 4, loss (training): 10.0848, loss (eval): 9.937
Epoch: 5, loss (training): 10.0883, loss (eval): 9.9468
Epoch: 6, loss (training): 10.1055, loss (eval): 10.0082
Epoch: 7, loss (training): 10.0923, loss (eval): 10.0445
Epoch: 8, loss (training): 10.0613, loss (eval): 9.9767
Epoch: 9, loss (training): 10.0625, loss (eval): 9.9928
Epoch: 10, loss (training): 10.0761, loss (eval): 9.998
Epoch: 11, loss (training): 10.0747, loss (eval): 9.9718
Epoch: 12, loss (training): 10.0689, loss (eval): 10.0863
Epoch: 13, loss (training): 10.0416, loss (eval): 9.9535
Epoch: 14, loss (training): 10.0488, loss (eval): 9.9387
Epoch: 15, loss (training): 10.045, loss (eval): 9.9576
Epoch: 16, loss (training): 10.0397, loss (eval): 9.9499
Epoch: 17, loss (training): 10.0687, loss (eval): 9.964
Epoch: 18, loss (training): 10.0537, loss (eval): 9.9914
Epoch: 19, loss (training): 10.0576, loss (eval): 9.9775
Epoch: 20, loss (training): 10.0515, loss (eval): 9.9841
Epoch: 21, loss (training): 10.0519, loss (eval): 9.9974
Epoch: 22, loss (training): 10.0418, loss (eval): 9.9868
Epoch: 23, loss (training): 10.0315, loss (eval): 9.9744
Early-stopping. Training converged after 24 epochs.
start update posterior model
Epoch: 0, loss (training): 13.313, loss (eval): 13.3637
Epoch: 1, loss (training): 13.3069, loss (eval): 13.3174
Epoch: 2, loss (training): 13.3077, loss (eval): 13.3235
Epoch: 3, loss (training): 13.3095, loss (eval): 13.3078
Epoch: 4, loss (training): 13.3145, loss (eval): 13.3126
Epoch: 5, loss (training): 13.3095, loss (eval): 13.3083
Epoch: 6, loss (training): 13.3069, loss (eval): 13.3096
Epoch: 7, loss (training): 13.3082, loss (eval): 13.3017
Epoch: 8, loss (training): 13.3084, loss (eval): 13.3188
Epoch: 9, loss (training): 13.308, loss (eval): 13.3151
Epoch: 10, loss (training): 13.3108, loss (eval): 13.3427
Epoch: 11, loss (training): 13.3092, loss (eval): 13.327
Epoch: 12, loss (training): 13.3114, loss (eval): 13.3166
Epoch: 13, loss (training): 13.3069, loss (eval): 13.3266
Epoch: 14, loss (training): 13.3108, loss (eval): 13.306
Epoch: 15, loss (training): 13.3131, loss (eval): 13.3066
Epoch: 16, loss (training): 13.3124, loss (eval): 13.3102
Epoch: 17, loss (training): 13.3119, loss (eval): 13.3222
Epoch: 18, loss (training): 13.3122, loss (eval): 13.3177
Epoch: 19, loss (training): 13.3089, loss (eval): 13.307
Epoch: 20, loss (training): 13.3088, loss (eval): 13.3043
Epoch: 21, loss (training): 13.309, loss (eval): 13.311
Epoch: 22, loss (training): 13.3091, loss (eval): 13.3304
Epoch: 23, loss (training): 13.3091, loss (eval): 13.3194
Epoch: 24, loss (training): 13.3112, loss (eval): 13.3037
Epoch: 25, loss (training): 13.3072, loss (eval): 13.3072
Epoch: 26, loss (training): 13.3098, loss (eval): 13.3085
Early-stopping. Training converged after 27 epochs.
Iteration: 9
optimizer_post_lr: [0.0013268408625781243]
prob_prior: 0.003697863716482932
start update likelihood model
Epoch: 0, loss (training): 10.0881, loss (eval): 10.2497
Epoch: 1, loss (training): 10.0245, loss (eval): 10.172
Epoch: 2, loss (training): 10.0, loss (eval): 10.214
Epoch: 3, loss (training): 9.9973, loss (eval): 10.2665
Epoch: 4, loss (training): 9.991, loss (eval): 10.2627
Epoch: 5, loss (training): 9.9858, loss (eval): 10.2111
Epoch: 6, loss (training): 9.9886, loss (eval): 10.2267
Epoch: 7, loss (training): 9.9655, loss (eval): 10.2525
Epoch: 8, loss (training): 9.9772, loss (eval): 10.2187
Epoch: 9, loss (training): 9.999, loss (eval): 10.1814
Epoch: 10, loss (training): 9.9622, loss (eval): 10.289
Epoch: 11, loss (training): 9.9561, loss (eval): 10.1882
Epoch: 12, loss (training): 9.9441, loss (eval): 10.1283
Epoch: 13, loss (training): 9.9392, loss (eval): 10.1971
Epoch: 14, loss (training): 9.9456, loss (eval): 10.2475
Epoch: 15, loss (training): 9.9514, loss (eval): 10.1831
Epoch: 16, loss (training): 9.9368, loss (eval): 10.1817
Epoch: 17, loss (training): 9.956, loss (eval): 10.2231
Epoch: 18, loss (training): 9.9409, loss (eval): 10.2794
Epoch: 19, loss (training): 9.9456, loss (eval): 10.273
Epoch: 20, loss (training): 9.9493, loss (eval): 10.2666
Epoch: 21, loss (training): 9.9488, loss (eval): 10.2575
Epoch: 22, loss (training): 9.9429, loss (eval): 10.3386
Epoch: 23, loss (training): 9.9179, loss (eval): 10.1867
Epoch: 24, loss (training): 9.9276, loss (eval): 10.1799
Epoch: 25, loss (training): 9.9183, loss (eval): 10.1903
Epoch: 26, loss (training): 9.942, loss (eval): 10.2497
Epoch: 27, loss (training): 9.9653, loss (eval): 10.1912
Epoch: 28, loss (training): 9.9151, loss (eval): 10.2249
Epoch: 29, loss (training): 9.9627, loss (eval): 10.3549
Epoch: 30, loss (training): 9.9422, loss (eval): 10.263
Epoch: 31, loss (training): 9.9305, loss (eval): 10.2133
Early-stopping. Training converged after 32 epochs.
start update posterior model
Epoch: 0, loss (training): 12.8634, loss (eval): 12.8821
Epoch: 1, loss (training): 12.8628, loss (eval): 12.8589
Epoch: 2, loss (training): 12.8635, loss (eval): 12.8536
Epoch: 3, loss (training): 12.8615, loss (eval): 12.8462
Epoch: 4, loss (training): 12.8601, loss (eval): 12.8509
Epoch: 5, loss (training): 12.8576, loss (eval): 12.8498
Epoch: 6, loss (training): 12.8545, loss (eval): 12.8481
Epoch: 7, loss (training): 12.8564, loss (eval): 12.8582
Epoch: 8, loss (training): 12.8555, loss (eval): 12.85
Epoch: 9, loss (training): 12.8572, loss (eval): 12.8645
Epoch: 10, loss (training): 12.8524, loss (eval): 12.8427
Epoch: 11, loss (training): 12.8571, loss (eval): 12.8461
Epoch: 12, loss (training): 12.856, loss (eval): 12.8628
Epoch: 13, loss (training): 12.8571, loss (eval): 12.8628
Epoch: 14, loss (training): 12.8564, loss (eval): 12.8751
Epoch: 15, loss (training): 12.8528, loss (eval): 12.8632
Epoch: 16, loss (training): 12.8536, loss (eval): 12.8514
Epoch: 17, loss (training): 12.8558, loss (eval): 12.8488
Epoch: 18, loss (training): 12.8539, loss (eval): 12.847
Epoch: 19, loss (training): 12.8546, loss (eval): 12.8478
Epoch: 20, loss (training): 12.8523, loss (eval): 12.8518
Epoch: 21, loss (training): 12.855, loss (eval): 12.8424
Epoch: 22, loss (training): 12.8524, loss (eval): 12.8571
Epoch: 23, loss (training): 12.8582, loss (eval): 12.8519
Epoch: 24, loss (training): 12.8543, loss (eval): 12.8515
Epoch: 25, loss (training): 12.8539, loss (eval): 12.8532
Epoch: 26, loss (training): 12.8534, loss (eval): 12.8495
Epoch: 27, loss (training): 12.8544, loss (eval): 12.8564
Epoch: 28, loss (training): 12.8532, loss (eval): 12.8517
Epoch: 29, loss (training): 12.8525, loss (eval): 12.8428
Epoch: 30, loss (training): 12.8527, loss (eval): 12.8629
Epoch: 31, loss (training): 12.8557, loss (eval): 12.8563
Epoch: 32, loss (training): 12.8527, loss (eval): 12.8505
Epoch: 33, loss (training): 12.8515, loss (eval): 12.8624
Epoch: 34, loss (training): 12.8529, loss (eval): 12.8424
Epoch: 35, loss (training): 12.8545, loss (eval): 12.8517
Epoch: 36, loss (training): 12.8533, loss (eval): 12.8567
Epoch: 37, loss (training): 12.8546, loss (eval): 12.8542
Epoch: 38, loss (training): 12.8553, loss (eval): 12.8557
Epoch: 39, loss (training): 12.8569, loss (eval): 12.8423
Epoch: 40, loss (training): 12.8522, loss (eval): 12.8494
Epoch: 41, loss (training): 12.8551, loss (eval): 12.8506
Epoch: 42, loss (training): 12.8543, loss (eval): 12.8513
Epoch: 43, loss (training): 12.8525, loss (eval): 12.8539
Epoch: 44, loss (training): 12.8526, loss (eval): 12.8508
Epoch: 45, loss (training): 12.8552, loss (eval): 12.8503
Epoch: 46, loss (training): 12.8514, loss (eval): 12.8479
Epoch: 47, loss (training): 12.8512, loss (eval): 12.8505
Epoch: 48, loss (training): 12.8535, loss (eval): 12.8547
Epoch: 49, loss (training): 12.8514, loss (eval): 12.8492
Epoch: 50, loss (training): 12.8514, loss (eval): 12.8493
Epoch: 51, loss (training): 12.8558, loss (eval): 12.8679
Epoch: 52, loss (training): 12.8538, loss (eval): 12.8596
Epoch: 53, loss (training): 12.8538, loss (eval): 12.8592
Epoch: 54, loss (training): 12.854, loss (eval): 12.8472
Epoch: 55, loss (training): 12.8517, loss (eval): 12.845
Epoch: 56, loss (training): 12.8568, loss (eval): 12.8756
Epoch: 57, loss (training): 12.8539, loss (eval): 12.8421
Epoch: 58, loss (training): 12.8512, loss (eval): 12.8485
Epoch: 59, loss (training): 12.8526, loss (eval): 12.844
Epoch: 60, loss (training): 12.8532, loss (eval): 12.8632
Epoch: 61, loss (training): 12.854, loss (eval): 12.8489
Epoch: 62, loss (training): 12.8522, loss (eval): 12.8464
Epoch: 63, loss (training): 12.8535, loss (eval): 12.8525
Epoch: 64, loss (training): 12.8505, loss (eval): 12.8483
Epoch: 65, loss (training): 12.8522, loss (eval): 12.851
Epoch: 66, loss (training): 12.8543, loss (eval): 12.872
Epoch: 67, loss (training): 12.8543, loss (eval): 12.855
Epoch: 68, loss (training): 12.8514, loss (eval): 12.8447
Epoch: 69, loss (training): 12.8502, loss (eval): 12.8611
Epoch: 70, loss (training): 12.8541, loss (eval): 12.8512
Epoch: 71, loss (training): 12.851, loss (eval): 12.8497
Epoch: 72, loss (training): 12.8531, loss (eval): 12.8442
Epoch: 73, loss (training): 12.8566, loss (eval): 12.8425
Epoch: 74, loss (training): 12.8524, loss (eval): 12.8486
Iteration: 10
optimizer_post_lr: [0.001260498819449218]
prob_prior: 0.0018363047770289071
start update likelihood model
Epoch: 0, loss (training): 10.202, loss (eval): 10.1773
Epoch: 1, loss (training): 10.3717, loss (eval): 10.2376
Epoch: 2, loss (training): 10.1393, loss (eval): 10.2313
Epoch: 3, loss (training): 10.1014, loss (eval): 10.1835
Epoch: 4, loss (training): 10.0801, loss (eval): 10.2036
Epoch: 5, loss (training): 10.0668, loss (eval): 10.229
Epoch: 6, loss (training): 10.0867, loss (eval): 10.2603
Epoch: 7, loss (training): 10.0811, loss (eval): 10.2247
Epoch: 8, loss (training): 10.0494, loss (eval): 10.1656
Epoch: 9, loss (training): 10.0557, loss (eval): 10.2568
Epoch: 10, loss (training): 10.0647, loss (eval): 10.2334
Epoch: 11, loss (training): 10.0635, loss (eval): 10.2034
Epoch: 12, loss (training): 10.0566, loss (eval): 10.2054
Epoch: 13, loss (training): 10.0282, loss (eval): 10.1558
Epoch: 14, loss (training): 10.0337, loss (eval): 10.1743
Epoch: 15, loss (training): 10.0082, loss (eval): 10.2457
Epoch: 16, loss (training): 10.0364, loss (eval): 10.1623
Epoch: 17, loss (training): 10.0217, loss (eval): 10.215
Epoch: 18, loss (training): 10.0036, loss (eval): 10.1647
Epoch: 19, loss (training): 10.0269, loss (eval): 10.2761
Epoch: 20, loss (training): 10.022, loss (eval): 10.2179
Epoch: 21, loss (training): 10.0047, loss (eval): 10.2604
Epoch: 22, loss (training): 10.019, loss (eval): 10.2452
Epoch: 23, loss (training): 10.0144, loss (eval): 10.1717
Epoch: 24, loss (training): 9.9993, loss (eval): 10.2291
Epoch: 25, loss (training): 9.9951, loss (eval): 10.2605
Epoch: 26, loss (training): 10.005, loss (eval): 10.201
Epoch: 27, loss (training): 9.9949, loss (eval): 10.2701
Epoch: 28, loss (training): 10.0116, loss (eval): 10.1935
Epoch: 29, loss (training): 10.0027, loss (eval): 10.1874
Epoch: 30, loss (training): 9.9698, loss (eval): 10.1826
Epoch: 31, loss (training): 9.981, loss (eval): 10.2145
Epoch: 32, loss (training): 9.9864, loss (eval): 10.2166
Early-stopping. Training converged after 33 epochs.
start update posterior model
Epoch: 0, loss (training): 12.5612, loss (eval): 12.6296
Epoch: 1, loss (training): 12.5558, loss (eval): 12.5519
Epoch: 2, loss (training): 12.5559, loss (eval): 12.5492
Epoch: 3, loss (training): 12.5556, loss (eval): 12.5526
Epoch: 4, loss (training): 12.5526, loss (eval): 12.5524
Epoch: 5, loss (training): 12.5538, loss (eval): 12.5611
Epoch: 6, loss (training): 12.554, loss (eval): 12.5505
Epoch: 7, loss (training): 12.556, loss (eval): 12.5636
Epoch: 8, loss (training): 12.5554, loss (eval): 12.5444
Epoch: 9, loss (training): 12.5571, loss (eval): 12.5528
Epoch: 10, loss (training): 12.5554, loss (eval): 12.5699
Epoch: 11, loss (training): 12.556, loss (eval): 12.5457
Epoch: 12, loss (training): 12.5551, loss (eval): 12.5491
Epoch: 13, loss (training): 12.5579, loss (eval): 12.5508
Epoch: 14, loss (training): 12.555, loss (eval): 12.5492
Epoch: 15, loss (training): 12.5536, loss (eval): 12.5681
Epoch: 16, loss (training): 12.5557, loss (eval): 12.5702
Epoch: 17, loss (training): 12.5541, loss (eval): 12.5465
Epoch: 18, loss (training): 12.554, loss (eval): 12.5518
Epoch: 19, loss (training): 12.5554, loss (eval): 12.5644
Epoch: 20, loss (training): 12.5529, loss (eval): 12.5534
Epoch: 21, loss (training): 12.5547, loss (eval): 12.5516
Epoch: 22, loss (training): 12.5551, loss (eval): 12.5573
Epoch: 23, loss (training): 12.5533, loss (eval): 12.5543
Epoch: 24, loss (training): 12.5543, loss (eval): 12.5525
Epoch: 25, loss (training): 12.5536, loss (eval): 12.5585
Epoch: 26, loss (training): 12.5531, loss (eval): 12.5573
Epoch: 27, loss (training): 12.556, loss (eval): 12.5495
Early-stopping. Training converged after 28 epochs.

Runtime:1488.66
0
1
2
3
4
5
6
7
8
9
