Input args:
Dim: 2
seed: 23
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.7906919736787676, eval loss: 7.264708995819092
Epoch: 1, loss: 0.4807953792042099, eval loss: 0.4940749704837799
Epoch: 2, loss: 0.46104302185354756, eval loss: 0.4986632764339447
Epoch: 3, loss: 0.43643289119936524, eval loss: 0.6037948727607727
Epoch: 4, loss: 0.42430387886430254, eval loss: 0.39509448409080505
Epoch: 5, loss: 0.4214472321810899, eval loss: 0.48825690150260925
Epoch: 6, loss: 0.4110636084876023, eval loss: 0.4598348140716553
Epoch: 7, loss: 0.4079560680850409, eval loss: 0.4004277288913727
Epoch: 8, loss: 0.40386220411688556, eval loss: 0.4141288697719574
Epoch: 9, loss: 0.40245484384187874, eval loss: 0.4233192801475525
Epoch: 10, loss: 0.3935615618270822, eval loss: 0.4481988847255707
Epoch: 11, loss: 0.39492203776055246, eval loss: 0.4133531153202057
Epoch: 12, loss: 0.3929287468598341, eval loss: 0.4020004868507385
Epoch: 13, loss: 0.38923164058680415, eval loss: 0.4166635274887085
Epoch: 14, loss: 0.38788318618782797, eval loss: 0.41269978880882263
Epoch: 15, loss: 0.3879274738713866, eval loss: 0.3929511606693268
Epoch: 16, loss: 0.3868140377835516, eval loss: 0.43006473779678345
Epoch: 17, loss: 0.38719507177127527, eval loss: 0.4158700108528137
Epoch: 18, loss: 0.38652690208284185, eval loss: 0.39336785674095154
Epoch: 19, loss: 0.3870569287354556, eval loss: 0.415063738822937
Epoch: 20, loss: 0.38411501001392023, eval loss: 0.3956791162490845
Epoch: 21, loss: 0.3826334992241027, eval loss: 0.38197872042655945
Epoch: 22, loss: 0.3854113764077192, eval loss: 0.392304390668869
Epoch: 23, loss: 0.38246086248895156, eval loss: 0.3937925100326538
Epoch: 24, loss: 0.382308893959671, eval loss: 0.42166662216186523
Epoch: 25, loss: 0.3834954956507681, eval loss: 0.4143993556499481
Epoch: 26, loss: 0.3809332826985337, eval loss: 0.4553852677345276
Epoch: 27, loss: 0.3808127608645009, eval loss: 0.38312944769859314
Epoch: 28, loss: 0.37858705547376303, eval loss: 0.3920726478099823
Epoch: 29, loss: 0.3801112969283713, eval loss: 0.3836745321750641
Epoch: 30, loss: 0.380927089419929, eval loss: 0.39409470558166504
Epoch: 31, loss: 0.3790132547324174, eval loss: 0.40635377168655396
Epoch: 32, loss: 0.37882088552287313, eval loss: 0.44574621319770813
Epoch: 33, loss: 0.3788503471312288, eval loss: 0.39792755246162415
Epoch: 34, loss: 0.3794302851500106, eval loss: 0.40719372034072876
Epoch: 35, loss: 0.37718802996649176, eval loss: 0.40316927433013916
Epoch: 36, loss: 0.37904878952467697, eval loss: 0.38352933526039124
Epoch: 37, loss: 0.378636489972414, eval loss: 0.3850124478340149
Epoch: 38, loss: 0.37886902449536136, eval loss: 0.40402093529701233
Epoch: 39, loss: 0.37914145105693026, eval loss: 0.3988886773586273
Epoch: 40, loss: 0.37994270128605423, eval loss: 0.38869744539260864
Epoch: 41, loss: 0.3800768128587515, eval loss: 0.3682788908481598
Epoch: 42, loss: 0.3808580510644242, eval loss: 0.37768253684043884
Epoch: 43, loss: 0.38128662006842207, eval loss: 0.40401971340179443
Epoch: 44, loss: 0.3805782240955159, eval loss: 0.3757392168045044
Epoch: 45, loss: 0.3806679526309017, eval loss: 0.3881964087486267
Epoch: 46, loss: 0.37888220807086326, eval loss: 0.3911154568195343
Epoch: 47, loss: 0.378839282731351, eval loss: 0.3873688280582428
Epoch: 48, loss: 0.38114048570278103, eval loss: 0.391059547662735
Epoch: 49, loss: 0.37960240798594896, eval loss: 0.39063286781311035

Runtime:582.65
KL div untrained: 9885912377275.918
KL div trained: 0.0046
