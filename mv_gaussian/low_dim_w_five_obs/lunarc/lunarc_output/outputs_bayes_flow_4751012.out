Input args:
Dim: 2
seed: 8
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/2d w 5 obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.8244032915960997, eval loss: 6.097471714019775
Epoch: 1, loss: 0.47924522977788003, eval loss: 0.45518237352371216
Epoch: 2, loss: 0.44679397732019427, eval loss: 0.5078710317611694
Epoch: 3, loss: 0.4330334470770322, eval loss: 0.3915950059890747
Epoch: 4, loss: 0.42199715959606693, eval loss: 0.40525802969932556
Epoch: 5, loss: 0.41186394069110976, eval loss: 0.3895097076892853
Epoch: 6, loss: 0.40706447744167235, eval loss: 0.3551366329193115
Epoch: 7, loss: 0.4012961530830944, eval loss: 0.36423081159591675
Epoch: 8, loss: 0.39838798369746653, eval loss: 0.4491373896598816
Epoch: 9, loss: 0.3966170307272114, eval loss: 0.3663797974586487
Epoch: 10, loss: 0.39355943601171023, eval loss: 0.37088292837142944
Epoch: 11, loss: 0.3928604677456315, eval loss: 0.350748211145401
Epoch: 12, loss: 0.39218402614729714, eval loss: 0.38235288858413696
Epoch: 13, loss: 0.38883506107376886, eval loss: 0.39315855503082275
Epoch: 14, loss: 0.38856266095972386, eval loss: 0.3343888819217682
Epoch: 15, loss: 0.38756115552059783, eval loss: 0.35020339488983154
Epoch: 16, loss: 0.38475683203549127, eval loss: 0.34425491094589233
Epoch: 17, loss: 0.3858304639148264, eval loss: 0.35084670782089233
Epoch: 18, loss: 0.386467536530472, eval loss: 0.3163311779499054
Epoch: 19, loss: 0.3829244165268028, eval loss: 0.3254425823688507
Epoch: 20, loss: 0.38455453716102056, eval loss: 0.3332577347755432
Epoch: 21, loss: 0.38604539904859847, eval loss: 0.3508007526397705
Epoch: 22, loss: 0.38475057058152745, eval loss: 0.3350352346897125
Epoch: 23, loss: 0.3835258075472666, eval loss: 0.3471919596195221
Epoch: 24, loss: 0.3822899313969538, eval loss: 0.3646257221698761
Epoch: 25, loss: 0.38202914941764904, eval loss: 0.35357996821403503
Epoch: 26, loss: 0.38404504947422535, eval loss: 0.3801168203353882
Epoch: 27, loss: 0.3819923334912164, eval loss: 0.3289848566055298
Epoch: 28, loss: 0.38125361888965015, eval loss: 0.3323890268802643
Epoch: 29, loss: 0.38365687304758467, eval loss: 0.3382358253002167
Epoch: 30, loss: 0.38290265251340316, eval loss: 0.3294937312602997
Epoch: 31, loss: 0.38365440259411115, eval loss: 0.361806184053421
Epoch: 32, loss: 0.3843826391735638, eval loss: 0.32790443301200867
Epoch: 33, loss: 0.3825683772546472, eval loss: 0.3339528441429138
Epoch: 34, loss: 0.3813070154451998, eval loss: 0.3266327977180481
Epoch: 35, loss: 0.3835559722522885, eval loss: 0.32861536741256714
Epoch: 36, loss: 0.3825852851825766, eval loss: 0.31992071866989136
Epoch: 37, loss: 0.38341762585449035, eval loss: 0.31986430287361145
Epoch: 38, loss: 0.387249563356454, eval loss: 0.3361068665981293
Epoch: 39, loss: 0.38412989413947796, eval loss: 0.33669885993003845
Epoch: 40, loss: 0.3841675196506549, eval loss: 0.3319944441318512
Epoch: 41, loss: 0.3821479288733826, eval loss: 0.32667428255081177
Epoch: 42, loss: 0.38255467429778944, eval loss: 0.3097946047782898
Epoch: 43, loss: 0.38373804651608223, eval loss: 0.3289901912212372
Epoch: 44, loss: 0.38327970321450266, eval loss: 0.33224204182624817
Epoch: 45, loss: 0.38502933660987765, eval loss: 0.366462767124176
Epoch: 46, loss: 0.3824295591794726, eval loss: 0.327860563993454
Epoch: 47, loss: 0.38709539214003597, eval loss: 0.33590829372406006
Epoch: 48, loss: 0.3839204026962398, eval loss: 0.314431756734848
Epoch: 49, loss: 0.38402060340798927, eval loss: 0.3243062496185303

Runtime:584.26
KL div untrained: 358726.7422
KL div trained: 0.0427
