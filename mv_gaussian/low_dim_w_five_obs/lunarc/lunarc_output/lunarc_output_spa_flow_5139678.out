Input args:
Dim: 2
seed: 9
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
[1.0, 0.4965853037914095, 0.2465969639416065, 0.12245642825298195, 0.06081006262521797, 0.0301973834223185, 0.014995576820477717, 0.007446583070924344, 0.003697863716482932, 0.0018363047770289071]
start full training
Iteration: 1
optimizer_post_lr: [0.002]
prob_prior: 1.0
start update likelihood model
Epoch: 0, loss (training): 25.3941, loss (eval): 39.938
Epoch: 1, loss (training): 19.2219, loss (eval): 21.1025
Epoch: 2, loss (training): 17.0701, loss (eval): 18.4304
Epoch: 3, loss (training): 15.7163, loss (eval): 16.8001
Epoch: 4, loss (training): 14.4871, loss (eval): 15.6062
Epoch: 5, loss (training): 13.4074, loss (eval): 14.1482
Epoch: 6, loss (training): 12.6125, loss (eval): 13.2258
Epoch: 7, loss (training): 11.953, loss (eval): 12.5812
Epoch: 8, loss (training): 11.4791, loss (eval): 11.8898
Epoch: 9, loss (training): 11.1845, loss (eval): 11.5601
Epoch: 10, loss (training): 10.9022, loss (eval): 11.1319
Epoch: 11, loss (training): 10.6387, loss (eval): 10.8459
Epoch: 12, loss (training): 10.563, loss (eval): 10.6806
Epoch: 13, loss (training): 10.5794, loss (eval): 10.9891
Epoch: 14, loss (training): 10.3771, loss (eval): 10.7479
Epoch: 15, loss (training): 10.372, loss (eval): 10.5468
Epoch: 16, loss (training): 10.411, loss (eval): 10.7138
Epoch: 17, loss (training): 10.2622, loss (eval): 10.5452
Epoch: 18, loss (training): 10.1997, loss (eval): 10.7195
Epoch: 19, loss (training): 10.2725, loss (eval): 10.4576
Epoch: 20, loss (training): 10.2921, loss (eval): 10.5008
Epoch: 21, loss (training): 10.2485, loss (eval): 11.0358
Epoch: 22, loss (training): 10.1887, loss (eval): 10.5475
Epoch: 23, loss (training): 10.2273, loss (eval): 10.5444
Epoch: 24, loss (training): 10.2252, loss (eval): 10.5516
Epoch: 25, loss (training): 10.2032, loss (eval): 10.412
Epoch: 26, loss (training): 10.1928, loss (eval): 10.4667
Epoch: 27, loss (training): 10.1305, loss (eval): 10.4352
Epoch: 28, loss (training): 10.0988, loss (eval): 10.4179
Epoch: 29, loss (training): 10.1647, loss (eval): 10.4343
Epoch: 30, loss (training): 10.1462, loss (eval): 10.4575
Epoch: 31, loss (training): 10.1675, loss (eval): 10.4262
Epoch: 32, loss (training): 10.1535, loss (eval): 10.5981
Epoch: 33, loss (training): 10.1343, loss (eval): 10.4626
Epoch: 34, loss (training): 10.2332, loss (eval): 10.4955
Epoch: 35, loss (training): 10.1744, loss (eval): 10.471
Epoch: 36, loss (training): 10.1217, loss (eval): 10.5457
Epoch: 37, loss (training): 10.1568, loss (eval): 10.4527
Epoch: 38, loss (training): 10.0712, loss (eval): 10.4056
Epoch: 39, loss (training): 10.1311, loss (eval): 10.4742
Epoch: 40, loss (training): 10.1134, loss (eval): 10.521
Epoch: 41, loss (training): 10.0599, loss (eval): 10.2699
Epoch: 42, loss (training): 10.093, loss (eval): 10.4271
Epoch: 43, loss (training): 10.1215, loss (eval): 10.3815
Epoch: 44, loss (training): 10.0989, loss (eval): 10.5123
Epoch: 45, loss (training): 10.0786, loss (eval): 10.4392
Epoch: 46, loss (training): 10.0745, loss (eval): 10.3999
Epoch: 47, loss (training): 10.0877, loss (eval): 10.3605
Epoch: 48, loss (training): 10.0607, loss (eval): 10.4467
Epoch: 49, loss (training): 10.0738, loss (eval): 10.3017
Epoch: 50, loss (training): 10.0813, loss (eval): 10.4124
Epoch: 51, loss (training): 10.1043, loss (eval): 10.308
Epoch: 52, loss (training): 10.0663, loss (eval): 10.4144
Epoch: 53, loss (training): 10.0281, loss (eval): 10.3712
Epoch: 54, loss (training): 10.0259, loss (eval): 10.3876
Epoch: 55, loss (training): 10.0621, loss (eval): 10.3946
Epoch: 56, loss (training): 10.0232, loss (eval): 10.3875
Epoch: 57, loss (training): 9.9728, loss (eval): 10.4632
Epoch: 58, loss (training): 10.0373, loss (eval): 10.43
Epoch: 59, loss (training): 10.0282, loss (eval): 10.3494
Epoch: 60, loss (training): 10.0217, loss (eval): 10.3922
Early-stopping. Training converged after 61 epochs.
start update posterior model from prior pred - hot start
Epoch: 0, loss (training): 3.2166, loss (eval): 7.0607
Epoch: 1, loss (training): 1.5254, loss (eval): 2.0872
Epoch: 2, loss (training): 1.3133, loss (eval): 1.9852
Epoch: 3, loss (training): 1.0405, loss (eval): 1.4184
Epoch: 4, loss (training): 0.8112, loss (eval): 0.6465
Epoch: 5, loss (training): 0.7369, loss (eval): 0.6119
Epoch: 6, loss (training): 0.5956, loss (eval): 0.7952
Epoch: 7, loss (training): 0.6477, loss (eval): 0.6078
Epoch: 8, loss (training): 0.5571, loss (eval): 0.7298
Epoch: 9, loss (training): 0.6576, loss (eval): 0.5743
start update posterior model
Epoch: 0, loss (training): 14.8519, loss (eval): 14.5933
Epoch: 1, loss (training): 14.3947, loss (eval): 14.3652
Epoch: 2, loss (training): 14.3814, loss (eval): 14.3659
Epoch: 3, loss (training): 14.374, loss (eval): 14.3704
Epoch: 4, loss (training): 14.4087, loss (eval): 14.3452
Epoch: 5, loss (training): 14.3992, loss (eval): 14.3437
Epoch: 6, loss (training): 14.3665, loss (eval): 14.3677
Epoch: 7, loss (training): 14.3815, loss (eval): 14.3673
Epoch: 8, loss (training): 14.3947, loss (eval): 14.343
Epoch: 9, loss (training): 14.3882, loss (eval): 14.3364
Epoch: 10, loss (training): 14.3773, loss (eval): 14.3467
Epoch: 11, loss (training): 14.373, loss (eval): 14.4479
Epoch: 12, loss (training): 14.3623, loss (eval): 14.3619
Epoch: 13, loss (training): 14.3909, loss (eval): 14.3398
Epoch: 14, loss (training): 14.3723, loss (eval): 14.5566
Epoch: 15, loss (training): 14.378, loss (eval): 14.3936
Epoch: 16, loss (training): 14.371, loss (eval): 14.3444
Epoch: 17, loss (training): 14.3673, loss (eval): 14.4238
Epoch: 18, loss (training): 14.3863, loss (eval): 14.3686
Epoch: 19, loss (training): 14.364, loss (eval): 14.349
Epoch: 20, loss (training): 14.3872, loss (eval): 14.3368
Epoch: 21, loss (training): 14.371, loss (eval): 14.3635
Epoch: 22, loss (training): 14.3575, loss (eval): 14.3485
Epoch: 23, loss (training): 14.3673, loss (eval): 14.3531
Epoch: 24, loss (training): 14.3714, loss (eval): 14.3354
Epoch: 25, loss (training): 14.3582, loss (eval): 14.3653
Epoch: 26, loss (training): 14.3687, loss (eval): 14.3407
Epoch: 27, loss (training): 14.3854, loss (eval): 14.3397
Epoch: 28, loss (training): 14.3681, loss (eval): 14.4938
Epoch: 29, loss (training): 14.357, loss (eval): 14.3418
Epoch: 30, loss (training): 14.3699, loss (eval): 14.3741
Epoch: 31, loss (training): 14.3742, loss (eval): 14.3571
Epoch: 32, loss (training): 14.3636, loss (eval): 14.4769
Epoch: 33, loss (training): 14.3777, loss (eval): 14.325
Epoch: 34, loss (training): 14.3742, loss (eval): 14.3813
Epoch: 35, loss (training): 14.3779, loss (eval): 14.33
Epoch: 36, loss (training): 14.3631, loss (eval): 14.425
Epoch: 37, loss (training): 14.3541, loss (eval): 14.3426
Epoch: 38, loss (training): 14.367, loss (eval): 14.3705
Epoch: 39, loss (training): 14.3603, loss (eval): 14.3928
Epoch: 40, loss (training): 14.3668, loss (eval): 14.3984
Epoch: 41, loss (training): 14.3665, loss (eval): 14.3532
Epoch: 42, loss (training): 14.3755, loss (eval): 14.3271
Epoch: 43, loss (training): 14.3574, loss (eval): 14.3337
Epoch: 44, loss (training): 14.3581, loss (eval): 14.3535
Epoch: 45, loss (training): 14.3588, loss (eval): 14.3459
Epoch: 46, loss (training): 14.3587, loss (eval): 14.3473
Epoch: 47, loss (training): 14.3622, loss (eval): 14.3267
Epoch: 48, loss (training): 14.3571, loss (eval): 14.3512
Epoch: 49, loss (training): 14.3632, loss (eval): 14.3395
Epoch: 50, loss (training): 14.3638, loss (eval): 14.3539
Epoch: 51, loss (training): 14.3576, loss (eval): 14.3961
Epoch: 52, loss (training): 14.3525, loss (eval): 14.3347
Early-stopping. Training converged after 53 epochs.
Iteration: 2
optimizer_post_lr: [0.0019]
prob_prior: 0.4965853037914095
start update likelihood model
Epoch: 0, loss (training): 10.6174, loss (eval): 10.8041
Epoch: 1, loss (training): 10.3799, loss (eval): 10.2591
Epoch: 2, loss (training): 10.3539, loss (eval): 10.3029
Epoch: 3, loss (training): 10.2949, loss (eval): 10.2615
Epoch: 4, loss (training): 10.3124, loss (eval): 10.1801
Epoch: 5, loss (training): 10.2768, loss (eval): 10.1729
Epoch: 6, loss (training): 10.2509, loss (eval): 10.4309
Epoch: 7, loss (training): 10.2156, loss (eval): 10.2702
Epoch: 8, loss (training): 10.2154, loss (eval): 10.4097
Epoch: 9, loss (training): 10.1699, loss (eval): 10.1409
Epoch: 10, loss (training): 10.2479, loss (eval): 10.183
Epoch: 11, loss (training): 10.1548, loss (eval): 10.2172
Epoch: 12, loss (training): 10.1867, loss (eval): 10.0986
Epoch: 13, loss (training): 10.1373, loss (eval): 10.1729
Epoch: 14, loss (training): 10.183, loss (eval): 10.1706
Epoch: 15, loss (training): 10.1944, loss (eval): 10.1044
Epoch: 16, loss (training): 10.176, loss (eval): 10.1803
Epoch: 17, loss (training): 10.1609, loss (eval): 10.1772
Epoch: 18, loss (training): 10.0887, loss (eval): 10.0857
Epoch: 19, loss (training): 10.1235, loss (eval): 10.0739
Epoch: 20, loss (training): 10.1874, loss (eval): 10.2066
Epoch: 21, loss (training): 10.1351, loss (eval): 10.2339
Epoch: 22, loss (training): 10.1586, loss (eval): 10.1667
Epoch: 23, loss (training): 10.1391, loss (eval): 10.1143
Epoch: 24, loss (training): 10.1523, loss (eval): 10.3638
Epoch: 25, loss (training): 10.178, loss (eval): 10.2255
Epoch: 26, loss (training): 10.0911, loss (eval): 10.255
Epoch: 27, loss (training): 10.0829, loss (eval): 10.0924
Epoch: 28, loss (training): 10.0657, loss (eval): 10.0278
Epoch: 29, loss (training): 10.0922, loss (eval): 10.2384
Epoch: 30, loss (training): 10.1198, loss (eval): 10.4585
Epoch: 31, loss (training): 10.1222, loss (eval): 10.0331
Epoch: 32, loss (training): 10.1453, loss (eval): 10.2731
Epoch: 33, loss (training): 10.0842, loss (eval): 10.0702
Epoch: 34, loss (training): 10.0738, loss (eval): 10.0913
Epoch: 35, loss (training): 10.0949, loss (eval): 10.1182
Epoch: 36, loss (training): 10.073, loss (eval): 10.2334
Epoch: 37, loss (training): 10.1007, loss (eval): 10.1326
Epoch: 38, loss (training): 10.0776, loss (eval): 10.2027
Epoch: 39, loss (training): 10.0698, loss (eval): 10.0974
Epoch: 40, loss (training): 10.059, loss (eval): 10.1348
Epoch: 41, loss (training): 10.072, loss (eval): 10.0723
Epoch: 42, loss (training): 10.0997, loss (eval): 10.0895
Epoch: 43, loss (training): 10.1067, loss (eval): 10.0778
Epoch: 44, loss (training): 10.0576, loss (eval): 10.1826
Epoch: 45, loss (training): 10.0524, loss (eval): 10.1503
Epoch: 46, loss (training): 10.0763, loss (eval): 10.1002
Epoch: 47, loss (training): 10.0786, loss (eval): 10.2646
Early-stopping. Training converged after 48 epochs.
start update posterior model
Epoch: 0, loss (training): 13.0883, loss (eval): 14.0989
Epoch: 1, loss (training): 13.0657, loss (eval): 13.0725
Epoch: 2, loss (training): 13.0677, loss (eval): 13.0672
Epoch: 3, loss (training): 13.0713, loss (eval): 13.0686
Epoch: 4, loss (training): 13.0763, loss (eval): 13.0584
Epoch: 5, loss (training): 13.077, loss (eval): 13.072
Epoch: 6, loss (training): 13.07, loss (eval): 13.0591
Epoch: 7, loss (training): 13.0736, loss (eval): 13.1775
Epoch: 8, loss (training): 13.0737, loss (eval): 13.0581
Epoch: 9, loss (training): 13.0653, loss (eval): 13.1616
Epoch: 10, loss (training): 13.0634, loss (eval): 13.0551
Epoch: 11, loss (training): 13.076, loss (eval): 13.0444
Epoch: 12, loss (training): 13.0633, loss (eval): 13.0746
Epoch: 13, loss (training): 13.0607, loss (eval): 13.0543
Epoch: 14, loss (training): 13.0648, loss (eval): 13.0756
Epoch: 15, loss (training): 13.0617, loss (eval): 13.0524
Epoch: 16, loss (training): 13.0683, loss (eval): 13.1015
Epoch: 17, loss (training): 13.0629, loss (eval): 13.0775
Epoch: 18, loss (training): 13.0689, loss (eval): 13.0733
Epoch: 19, loss (training): 13.0709, loss (eval): 13.0994
Epoch: 20, loss (training): 13.0741, loss (eval): 13.0512
Epoch: 21, loss (training): 13.068, loss (eval): 13.0481
Epoch: 22, loss (training): 13.068, loss (eval): 13.0545
Epoch: 23, loss (training): 13.0681, loss (eval): 13.0586
Epoch: 24, loss (training): 13.0667, loss (eval): 13.0583
Epoch: 25, loss (training): 13.0569, loss (eval): 13.0604
Epoch: 26, loss (training): 13.0631, loss (eval): 13.0526
Epoch: 27, loss (training): 13.065, loss (eval): 13.0558
Epoch: 28, loss (training): 13.0671, loss (eval): 13.0991
Epoch: 29, loss (training): 13.0656, loss (eval): 13.0805
Epoch: 30, loss (training): 13.0598, loss (eval): 13.0549
Epoch: 31, loss (training): 13.0609, loss (eval): 13.0444
Epoch: 32, loss (training): 13.0643, loss (eval): 13.0484
Epoch: 33, loss (training): 13.0637, loss (eval): 13.0638
Epoch: 34, loss (training): 13.0608, loss (eval): 13.0899
Epoch: 35, loss (training): 13.0635, loss (eval): 13.0521
Epoch: 36, loss (training): 13.0638, loss (eval): 13.0362
Epoch: 37, loss (training): 13.0711, loss (eval): 13.0824
Epoch: 38, loss (training): 13.0734, loss (eval): 13.0754
Epoch: 39, loss (training): 13.0703, loss (eval): 13.09
Epoch: 40, loss (training): 13.0665, loss (eval): 13.0682
Epoch: 41, loss (training): 13.0607, loss (eval): 13.067
Epoch: 42, loss (training): 13.0678, loss (eval): 13.047
Epoch: 43, loss (training): 13.0725, loss (eval): 13.0612
Epoch: 44, loss (training): 13.0614, loss (eval): 13.0637
Epoch: 45, loss (training): 13.0616, loss (eval): 13.0592
Epoch: 46, loss (training): 13.062, loss (eval): 13.0445
Epoch: 47, loss (training): 13.0572, loss (eval): 13.0757
Epoch: 48, loss (training): 13.0663, loss (eval): 13.0562
Epoch: 49, loss (training): 13.0597, loss (eval): 13.0578
Epoch: 50, loss (training): 13.0578, loss (eval): 13.0582
Epoch: 51, loss (training): 13.067, loss (eval): 13.084
Epoch: 52, loss (training): 13.0601, loss (eval): 13.0438
Epoch: 53, loss (training): 13.0613, loss (eval): 13.0667
Epoch: 54, loss (training): 13.0612, loss (eval): 13.0599
Epoch: 55, loss (training): 13.0626, loss (eval): 13.0461
Early-stopping. Training converged after 56 epochs.
Iteration: 3
optimizer_post_lr: [0.001805]
prob_prior: 0.2465969639416065
start update likelihood model
Epoch: 0, loss (training): 10.2284, loss (eval): 10.179
Epoch: 1, loss (training): 10.197, loss (eval): 10.2139
Epoch: 2, loss (training): 10.1712, loss (eval): 10.2212
Epoch: 3, loss (training): 10.1359, loss (eval): 10.3636
Epoch: 4, loss (training): 10.1222, loss (eval): 10.2669
Epoch: 5, loss (training): 10.1582, loss (eval): 10.157
Epoch: 6, loss (training): 10.1482, loss (eval): 10.2351
Epoch: 7, loss (training): 10.1227, loss (eval): 10.2515
Epoch: 8, loss (training): 10.1434, loss (eval): 10.2864
Epoch: 9, loss (training): 10.1254, loss (eval): 10.2561
Epoch: 10, loss (training): 10.106, loss (eval): 10.2621
Epoch: 11, loss (training): 10.1003, loss (eval): 10.3037
Epoch: 12, loss (training): 10.1168, loss (eval): 10.2181
Epoch: 13, loss (training): 10.1219, loss (eval): 10.4109
Epoch: 14, loss (training): 10.0925, loss (eval): 10.2178
Epoch: 15, loss (training): 10.067, loss (eval): 10.3473
Epoch: 16, loss (training): 10.1326, loss (eval): 10.2857
Epoch: 17, loss (training): 10.0882, loss (eval): 10.2896
Epoch: 18, loss (training): 10.0788, loss (eval): 10.2723
Epoch: 19, loss (training): 10.0565, loss (eval): 10.4122
Epoch: 20, loss (training): 10.17, loss (eval): 10.5335
Epoch: 21, loss (training): 10.0698, loss (eval): 10.2533
Epoch: 22, loss (training): 10.0361, loss (eval): 10.2625
Epoch: 23, loss (training): 10.1055, loss (eval): 10.4534
Epoch: 24, loss (training): 10.1266, loss (eval): 10.3939
Early-stopping. Training converged after 25 epochs.
start update posterior model
Epoch: 0, loss (training): 13.2249, loss (eval): 13.3686
Epoch: 1, loss (training): 13.2178, loss (eval): 13.2101
Epoch: 2, loss (training): 13.2219, loss (eval): 13.204
Epoch: 3, loss (training): 13.2235, loss (eval): 13.2147
Epoch: 4, loss (training): 13.2134, loss (eval): 13.2096
Epoch: 5, loss (training): 13.2259, loss (eval): 13.2036
Epoch: 6, loss (training): 13.2215, loss (eval): 13.2571
Epoch: 7, loss (training): 13.2159, loss (eval): 13.2101
Epoch: 8, loss (training): 13.2247, loss (eval): 13.2113
Epoch: 9, loss (training): 13.2107, loss (eval): 13.2372
Epoch: 10, loss (training): 13.2157, loss (eval): 13.2092
Epoch: 11, loss (training): 13.2139, loss (eval): 13.2152
Epoch: 12, loss (training): 13.2191, loss (eval): 13.2106
Epoch: 13, loss (training): 13.2174, loss (eval): 13.2524
Epoch: 14, loss (training): 13.215, loss (eval): 13.2099
Epoch: 15, loss (training): 13.2138, loss (eval): 13.2334
Epoch: 16, loss (training): 13.2165, loss (eval): 13.2462
Epoch: 17, loss (training): 13.2168, loss (eval): 13.2046
Epoch: 18, loss (training): 13.2191, loss (eval): 13.1981
Epoch: 19, loss (training): 13.2216, loss (eval): 13.2057
Epoch: 20, loss (training): 13.2259, loss (eval): 13.2343
Epoch: 21, loss (training): 13.215, loss (eval): 13.2166
Epoch: 22, loss (training): 13.2127, loss (eval): 13.2242
Epoch: 23, loss (training): 13.2162, loss (eval): 13.2163
Epoch: 24, loss (training): 13.2104, loss (eval): 13.1997
Epoch: 25, loss (training): 13.2164, loss (eval): 13.2249
Epoch: 26, loss (training): 13.2159, loss (eval): 13.2689
Epoch: 27, loss (training): 13.217, loss (eval): 13.2066
Epoch: 28, loss (training): 13.2185, loss (eval): 13.2049
Epoch: 29, loss (training): 13.2148, loss (eval): 13.2132
Epoch: 30, loss (training): 13.2111, loss (eval): 13.2085
Epoch: 31, loss (training): 13.2195, loss (eval): 13.2351
Epoch: 32, loss (training): 13.2161, loss (eval): 13.2443
Epoch: 33, loss (training): 13.2183, loss (eval): 13.2257
Epoch: 34, loss (training): 13.2093, loss (eval): 13.207
Epoch: 35, loss (training): 13.2188, loss (eval): 13.2047
Epoch: 36, loss (training): 13.2173, loss (eval): 13.2068
Epoch: 37, loss (training): 13.211, loss (eval): 13.2102
Early-stopping. Training converged after 38 epochs.
Iteration: 4
optimizer_post_lr: [0.00171475]
prob_prior: 0.12245642825298195
start update likelihood model
Epoch: 0, loss (training): 10.2515, loss (eval): 10.3058
Epoch: 1, loss (training): 10.2159, loss (eval): 10.2379
Epoch: 2, loss (training): 10.1693, loss (eval): 10.1303
Epoch: 3, loss (training): 10.1694, loss (eval): 10.1986
Epoch: 4, loss (training): 10.1672, loss (eval): 10.2434
Epoch: 5, loss (training): 10.1486, loss (eval): 10.2688
Epoch: 6, loss (training): 10.1468, loss (eval): 10.1424
Epoch: 7, loss (training): 10.0918, loss (eval): 10.1866
Epoch: 8, loss (training): 10.1434, loss (eval): 10.2683
Epoch: 9, loss (training): 10.1193, loss (eval): 10.288
Epoch: 10, loss (training): 10.0824, loss (eval): 10.1706
Epoch: 11, loss (training): 10.1137, loss (eval): 10.1421
Epoch: 12, loss (training): 10.108, loss (eval): 10.2085
Epoch: 13, loss (training): 10.0866, loss (eval): 10.2339
Epoch: 14, loss (training): 10.0998, loss (eval): 10.1808
Epoch: 15, loss (training): 10.1042, loss (eval): 10.2022
Epoch: 16, loss (training): 10.0996, loss (eval): 10.1689
Epoch: 17, loss (training): 10.1304, loss (eval): 10.1906
Epoch: 18, loss (training): 10.0736, loss (eval): 10.2413
Epoch: 19, loss (training): 10.0723, loss (eval): 10.1931
Epoch: 20, loss (training): 10.056, loss (eval): 10.1526
Epoch: 21, loss (training): 10.0825, loss (eval): 10.1985
Early-stopping. Training converged after 22 epochs.
start update posterior model
Epoch: 0, loss (training): 13.4013, loss (eval): 13.4512
Epoch: 1, loss (training): 13.4083, loss (eval): 13.412
Epoch: 2, loss (training): 13.3954, loss (eval): 13.3847
Epoch: 3, loss (training): 13.3955, loss (eval): 13.406
Epoch: 4, loss (training): 13.4011, loss (eval): 13.4207
Epoch: 5, loss (training): 13.3992, loss (eval): 13.3816
Epoch: 6, loss (training): 13.4056, loss (eval): 13.3923
Epoch: 7, loss (training): 13.3967, loss (eval): 13.3845
Epoch: 8, loss (training): 13.4077, loss (eval): 13.3926
Epoch: 9, loss (training): 13.3963, loss (eval): 13.3869
Epoch: 10, loss (training): 13.4002, loss (eval): 13.385
Epoch: 11, loss (training): 13.3964, loss (eval): 13.4067
Epoch: 12, loss (training): 13.3931, loss (eval): 13.3963
Epoch: 13, loss (training): 13.3988, loss (eval): 13.3824
Epoch: 14, loss (training): 13.3984, loss (eval): 13.3912
Epoch: 15, loss (training): 13.3946, loss (eval): 13.3934
Epoch: 16, loss (training): 13.3986, loss (eval): 13.3805
Epoch: 17, loss (training): 13.3944, loss (eval): 13.3989
Epoch: 18, loss (training): 13.3929, loss (eval): 13.3919
Epoch: 19, loss (training): 13.3963, loss (eval): 13.3946
Epoch: 20, loss (training): 13.3982, loss (eval): 13.3982
Epoch: 21, loss (training): 13.3993, loss (eval): 13.3958
Epoch: 22, loss (training): 13.4078, loss (eval): 13.4294
Epoch: 23, loss (training): 13.3921, loss (eval): 13.3821
Epoch: 24, loss (training): 13.3977, loss (eval): 13.3888
Epoch: 25, loss (training): 13.3994, loss (eval): 13.3841
Epoch: 26, loss (training): 13.3967, loss (eval): 13.3881
Epoch: 27, loss (training): 13.395, loss (eval): 13.3875
Epoch: 28, loss (training): 13.3965, loss (eval): 13.3975
Epoch: 29, loss (training): 13.3925, loss (eval): 13.388
Epoch: 30, loss (training): 13.3986, loss (eval): 13.3865
Epoch: 31, loss (training): 13.4079, loss (eval): 13.4046
Epoch: 32, loss (training): 13.3991, loss (eval): 13.4125
Epoch: 33, loss (training): 13.3931, loss (eval): 13.3948
Epoch: 34, loss (training): 13.3953, loss (eval): 13.4358
Epoch: 35, loss (training): 13.3999, loss (eval): 13.4059
Early-stopping. Training converged after 36 epochs.
Iteration: 5
optimizer_post_lr: [0.0016290124999999997]
prob_prior: 0.06081006262521797
start update likelihood model
Epoch: 0, loss (training): 10.0853, loss (eval): 10.1181
Epoch: 1, loss (training): 10.0551, loss (eval): 10.2041
Epoch: 2, loss (training): 10.1176, loss (eval): 10.1636
Epoch: 3, loss (training): 10.0592, loss (eval): 10.25
Epoch: 4, loss (training): 10.0015, loss (eval): 10.1416
Epoch: 5, loss (training): 9.9858, loss (eval): 10.1504
Epoch: 6, loss (training): 10.001, loss (eval): 10.1281
Epoch: 7, loss (training): 9.9844, loss (eval): 10.1754
Epoch: 8, loss (training): 9.9886, loss (eval): 10.1796
Epoch: 9, loss (training): 10.0239, loss (eval): 10.1138
Epoch: 10, loss (training): 9.9807, loss (eval): 10.2609
Epoch: 11, loss (training): 9.9911, loss (eval): 10.2612
Epoch: 12, loss (training): 9.9741, loss (eval): 10.2574
Epoch: 13, loss (training): 9.9632, loss (eval): 10.12
Epoch: 14, loss (training): 9.9741, loss (eval): 10.2308
Epoch: 15, loss (training): 9.9763, loss (eval): 10.1507
Epoch: 16, loss (training): 9.9925, loss (eval): 10.3113
Epoch: 17, loss (training): 9.9711, loss (eval): 10.3547
Epoch: 18, loss (training): 9.9569, loss (eval): 10.163
Epoch: 19, loss (training): 9.9544, loss (eval): 10.2057
Epoch: 20, loss (training): 9.9804, loss (eval): 10.1911
Epoch: 21, loss (training): 9.975, loss (eval): 10.2719
Epoch: 22, loss (training): 9.9608, loss (eval): 10.3052
Epoch: 23, loss (training): 9.9477, loss (eval): 10.2326
Epoch: 24, loss (training): 9.9501, loss (eval): 10.3323
Epoch: 25, loss (training): 9.9617, loss (eval): 10.2649
Epoch: 26, loss (training): 9.9591, loss (eval): 10.3322
Epoch: 27, loss (training): 9.9277, loss (eval): 10.2128
Epoch: 28, loss (training): 9.9336, loss (eval): 10.2423
Early-stopping. Training converged after 29 epochs.
start update posterior model
Epoch: 0, loss (training): 13.1443, loss (eval): 13.1392
Epoch: 1, loss (training): 13.1432, loss (eval): 13.1372
Epoch: 2, loss (training): 13.1427, loss (eval): 13.1304
Epoch: 3, loss (training): 13.1405, loss (eval): 13.1441
Epoch: 4, loss (training): 13.1447, loss (eval): 13.1371
Epoch: 5, loss (training): 13.1459, loss (eval): 13.2059
Epoch: 6, loss (training): 13.1405, loss (eval): 13.1316
Epoch: 7, loss (training): 13.1411, loss (eval): 13.1508
Epoch: 8, loss (training): 13.139, loss (eval): 13.1358
Epoch: 9, loss (training): 13.1441, loss (eval): 13.1338
Epoch: 10, loss (training): 13.1426, loss (eval): 13.1416
Epoch: 11, loss (training): 13.1459, loss (eval): 13.1439
Epoch: 12, loss (training): 13.1431, loss (eval): 13.1387
Epoch: 13, loss (training): 13.1438, loss (eval): 13.1424
Epoch: 14, loss (training): 13.1428, loss (eval): 13.1339
Epoch: 15, loss (training): 13.1465, loss (eval): 13.1379
Epoch: 16, loss (training): 13.1466, loss (eval): 13.1424
Epoch: 17, loss (training): 13.1416, loss (eval): 13.1292
Epoch: 18, loss (training): 13.1475, loss (eval): 13.1311
Epoch: 19, loss (training): 13.1469, loss (eval): 13.1383
Epoch: 20, loss (training): 13.1421, loss (eval): 13.1413
Epoch: 21, loss (training): 13.1442, loss (eval): 13.1435
Epoch: 22, loss (training): 13.1419, loss (eval): 13.1353
Epoch: 23, loss (training): 13.1473, loss (eval): 13.1297
Epoch: 24, loss (training): 13.1404, loss (eval): 13.1392
Epoch: 25, loss (training): 13.139, loss (eval): 13.1295
Epoch: 26, loss (training): 13.1434, loss (eval): 13.1361
Epoch: 27, loss (training): 13.1463, loss (eval): 13.143
Epoch: 28, loss (training): 13.1446, loss (eval): 13.1327
Epoch: 29, loss (training): 13.143, loss (eval): 13.1392
Epoch: 30, loss (training): 13.1383, loss (eval): 13.1319
Epoch: 31, loss (training): 13.1497, loss (eval): 13.1339
Epoch: 32, loss (training): 13.1417, loss (eval): 13.1471
Epoch: 33, loss (training): 13.1398, loss (eval): 13.1361
Epoch: 34, loss (training): 13.1515, loss (eval): 13.1429
Epoch: 35, loss (training): 13.145, loss (eval): 13.1339
Epoch: 36, loss (training): 13.1417, loss (eval): 13.1268
Epoch: 37, loss (training): 13.1443, loss (eval): 13.1457
Epoch: 38, loss (training): 13.1443, loss (eval): 13.1318
Epoch: 39, loss (training): 13.1426, loss (eval): 13.1622
Epoch: 40, loss (training): 13.1464, loss (eval): 13.1391
Epoch: 41, loss (training): 13.1398, loss (eval): 13.1277
Epoch: 42, loss (training): 13.1459, loss (eval): 13.1338
Epoch: 43, loss (training): 13.1409, loss (eval): 13.138
Epoch: 44, loss (training): 13.1413, loss (eval): 13.133
Epoch: 45, loss (training): 13.146, loss (eval): 13.1428
Epoch: 46, loss (training): 13.1432, loss (eval): 13.1318
Epoch: 47, loss (training): 13.1382, loss (eval): 13.1313
Epoch: 48, loss (training): 13.1409, loss (eval): 13.1678
Epoch: 49, loss (training): 13.1468, loss (eval): 13.1306
Epoch: 50, loss (training): 13.1445, loss (eval): 13.1504
Epoch: 51, loss (training): 13.1452, loss (eval): 13.1365
Epoch: 52, loss (training): 13.1382, loss (eval): 13.1281
Epoch: 53, loss (training): 13.144, loss (eval): 13.1509
Epoch: 54, loss (training): 13.1405, loss (eval): 13.1366
Epoch: 55, loss (training): 13.1444, loss (eval): 13.1249
Epoch: 56, loss (training): 13.1422, loss (eval): 13.1384
Epoch: 57, loss (training): 13.1443, loss (eval): 13.1367
Epoch: 58, loss (training): 13.143, loss (eval): 13.152
Epoch: 59, loss (training): 13.1457, loss (eval): 13.1378
Epoch: 60, loss (training): 13.1426, loss (eval): 13.1565
Epoch: 61, loss (training): 13.1476, loss (eval): 13.1453
Epoch: 62, loss (training): 13.1422, loss (eval): 13.1422
Epoch: 63, loss (training): 13.146, loss (eval): 13.1384
Epoch: 64, loss (training): 13.1445, loss (eval): 13.1834
Epoch: 65, loss (training): 13.137, loss (eval): 13.1694
Epoch: 66, loss (training): 13.1423, loss (eval): 13.1338
Epoch: 67, loss (training): 13.1377, loss (eval): 13.1406
Epoch: 68, loss (training): 13.1417, loss (eval): 13.1452
Epoch: 69, loss (training): 13.1413, loss (eval): 13.1554
Epoch: 70, loss (training): 13.1456, loss (eval): 13.1326
Epoch: 71, loss (training): 13.1408, loss (eval): 13.1341
Epoch: 72, loss (training): 13.1433, loss (eval): 13.1518
Epoch: 73, loss (training): 13.1398, loss (eval): 13.1306
Epoch: 74, loss (training): 13.1419, loss (eval): 13.1491
Iteration: 6
optimizer_post_lr: [0.0015475618749999996]
prob_prior: 0.0301973834223185
start update likelihood model
Epoch: 0, loss (training): 10.2075, loss (eval): 9.9163
Epoch: 1, loss (training): 10.1653, loss (eval): 9.9214
Epoch: 2, loss (training): 10.1463, loss (eval): 9.9646
Epoch: 3, loss (training): 10.0979, loss (eval): 9.9064
Epoch: 4, loss (training): 10.1051, loss (eval): 9.8702
Epoch: 5, loss (training): 10.1215, loss (eval): 9.9252
Epoch: 6, loss (training): 10.0863, loss (eval): 9.8921
Epoch: 7, loss (training): 10.0675, loss (eval): 9.8751
Epoch: 8, loss (training): 10.0852, loss (eval): 9.8921
Epoch: 9, loss (training): 10.0674, loss (eval): 9.8989
Epoch: 10, loss (training): 10.0963, loss (eval): 10.0507
Epoch: 11, loss (training): 10.1075, loss (eval): 9.8019
Epoch: 12, loss (training): 10.0398, loss (eval): 9.9193
Epoch: 13, loss (training): 10.0447, loss (eval): 9.9555
Epoch: 14, loss (training): 10.0909, loss (eval): 9.9276
Epoch: 15, loss (training): 10.069, loss (eval): 9.9171
Epoch: 16, loss (training): 10.0518, loss (eval): 9.8697
Epoch: 17, loss (training): 10.0498, loss (eval): 9.8543
Epoch: 18, loss (training): 10.0773, loss (eval): 9.846
Epoch: 19, loss (training): 10.0627, loss (eval): 9.976
Epoch: 20, loss (training): 10.0396, loss (eval): 9.9026
Epoch: 21, loss (training): 10.0166, loss (eval): 9.8667
Epoch: 22, loss (training): 10.0625, loss (eval): 9.8697
Epoch: 23, loss (training): 10.0115, loss (eval): 9.9102
Epoch: 24, loss (training): 10.0491, loss (eval): 9.892
Epoch: 25, loss (training): 10.0208, loss (eval): 9.9329
Epoch: 26, loss (training): 10.0636, loss (eval): 9.9289
Epoch: 27, loss (training): 10.0448, loss (eval): 9.989
Epoch: 28, loss (training): 10.0092, loss (eval): 9.9484
Epoch: 29, loss (training): 10.0291, loss (eval): 9.9346
Epoch: 30, loss (training): 10.0238, loss (eval): 9.8996
Early-stopping. Training converged after 31 epochs.
start update posterior model
Epoch: 0, loss (training): 13.2392, loss (eval): 13.2637
Epoch: 1, loss (training): 13.2431, loss (eval): 13.2493
Epoch: 2, loss (training): 13.246, loss (eval): 13.2686
Epoch: 3, loss (training): 13.2371, loss (eval): 13.2247
Epoch: 4, loss (training): 13.2338, loss (eval): 13.2369
Epoch: 5, loss (training): 13.2351, loss (eval): 13.2443
Epoch: 6, loss (training): 13.238, loss (eval): 13.2372
Epoch: 7, loss (training): 13.2359, loss (eval): 13.2266
Epoch: 8, loss (training): 13.2381, loss (eval): 13.232
Epoch: 9, loss (training): 13.2389, loss (eval): 13.2372
Epoch: 10, loss (training): 13.2375, loss (eval): 13.2325
Epoch: 11, loss (training): 13.2359, loss (eval): 13.2285
Epoch: 12, loss (training): 13.2386, loss (eval): 13.2333
Epoch: 13, loss (training): 13.2349, loss (eval): 13.2695
Epoch: 14, loss (training): 13.2393, loss (eval): 13.228
Epoch: 15, loss (training): 13.2435, loss (eval): 13.2247
Epoch: 16, loss (training): 13.2428, loss (eval): 13.226
Epoch: 17, loss (training): 13.2343, loss (eval): 13.2554
Epoch: 18, loss (training): 13.2427, loss (eval): 13.2251
Epoch: 19, loss (training): 13.2393, loss (eval): 13.2291
Epoch: 20, loss (training): 13.236, loss (eval): 13.2392
Epoch: 21, loss (training): 13.2389, loss (eval): 13.229
Epoch: 22, loss (training): 13.2402, loss (eval): 13.2229
Epoch: 23, loss (training): 13.2382, loss (eval): 13.2418
Epoch: 24, loss (training): 13.2391, loss (eval): 13.2306
Epoch: 25, loss (training): 13.2392, loss (eval): 13.2273
Epoch: 26, loss (training): 13.2381, loss (eval): 13.2611
Epoch: 27, loss (training): 13.235, loss (eval): 13.2382
Epoch: 28, loss (training): 13.2353, loss (eval): 13.2395
Epoch: 29, loss (training): 13.2422, loss (eval): 13.2342
Epoch: 30, loss (training): 13.2341, loss (eval): 13.2401
Epoch: 31, loss (training): 13.2346, loss (eval): 13.2386
Epoch: 32, loss (training): 13.2381, loss (eval): 13.2392
Epoch: 33, loss (training): 13.2425, loss (eval): 13.2385
Epoch: 34, loss (training): 13.2381, loss (eval): 13.2257
Epoch: 35, loss (training): 13.2354, loss (eval): 13.2357
Epoch: 36, loss (training): 13.2401, loss (eval): 13.2406
Epoch: 37, loss (training): 13.2369, loss (eval): 13.2328
Epoch: 38, loss (training): 13.2436, loss (eval): 13.2313
Epoch: 39, loss (training): 13.2377, loss (eval): 13.2272
Epoch: 40, loss (training): 13.238, loss (eval): 13.2374
Epoch: 41, loss (training): 13.2341, loss (eval): 13.2273
Early-stopping. Training converged after 42 epochs.
Iteration: 7
optimizer_post_lr: [0.0014701837812499995]
prob_prior: 0.014995576820477717
start update likelihood model
Epoch: 0, loss (training): 10.2134, loss (eval): 10.3724
Epoch: 1, loss (training): 10.1736, loss (eval): 10.3623
Epoch: 2, loss (training): 10.1608, loss (eval): 10.3516
Epoch: 3, loss (training): 10.1001, loss (eval): 10.3145
Epoch: 4, loss (training): 10.0961, loss (eval): 10.457
Epoch: 5, loss (training): 10.103, loss (eval): 10.3613
Epoch: 6, loss (training): 10.0637, loss (eval): 10.3232
Epoch: 7, loss (training): 10.0489, loss (eval): 10.3492
Epoch: 8, loss (training): 10.0607, loss (eval): 10.358
Epoch: 9, loss (training): 10.0361, loss (eval): 10.3444
Epoch: 10, loss (training): 10.0682, loss (eval): 10.3365
Epoch: 11, loss (training): 10.0665, loss (eval): 10.4209
Epoch: 12, loss (training): 10.0467, loss (eval): 10.371
Epoch: 13, loss (training): 10.0393, loss (eval): 10.3233
Epoch: 14, loss (training): 10.0373, loss (eval): 10.3355
Epoch: 15, loss (training): 10.065, loss (eval): 10.325
Epoch: 16, loss (training): 10.0484, loss (eval): 10.4016
Epoch: 17, loss (training): 10.0569, loss (eval): 10.3389
Epoch: 18, loss (training): 10.0454, loss (eval): 10.4179
Epoch: 19, loss (training): 10.0165, loss (eval): 10.3159
Epoch: 20, loss (training): 10.0209, loss (eval): 10.4358
Epoch: 21, loss (training): 10.033, loss (eval): 10.3484
Epoch: 22, loss (training): 10.0246, loss (eval): 10.3071
Epoch: 23, loss (training): 10.0207, loss (eval): 10.3726
Epoch: 24, loss (training): 10.0257, loss (eval): 10.3139
Epoch: 25, loss (training): 10.032, loss (eval): 10.5408
Epoch: 26, loss (training): 10.0538, loss (eval): 10.4055
Epoch: 27, loss (training): 10.0644, loss (eval): 10.2927
Epoch: 28, loss (training): 10.039, loss (eval): 10.3383
Epoch: 29, loss (training): 10.0473, loss (eval): 10.3148
Epoch: 30, loss (training): 10.0504, loss (eval): 10.4236
Epoch: 31, loss (training): 10.0298, loss (eval): 10.357
Epoch: 32, loss (training): 10.0035, loss (eval): 10.3431
Epoch: 33, loss (training): 9.9933, loss (eval): 10.3246
Epoch: 34, loss (training): 10.0177, loss (eval): 10.3664
Epoch: 35, loss (training): 10.1114, loss (eval): 10.3427
Epoch: 36, loss (training): 10.036, loss (eval): 10.4295
Epoch: 37, loss (training): 10.0115, loss (eval): 10.3796
Epoch: 38, loss (training): 10.0263, loss (eval): 10.3569
Epoch: 39, loss (training): 10.021, loss (eval): 10.6053
Epoch: 40, loss (training): 10.0312, loss (eval): 10.366
Epoch: 41, loss (training): 10.0212, loss (eval): 10.312
Epoch: 42, loss (training): 10.01, loss (eval): 10.3436
Epoch: 43, loss (training): 9.9896, loss (eval): 10.4233
Epoch: 44, loss (training): 10.0301, loss (eval): 10.4381
Epoch: 45, loss (training): 9.9839, loss (eval): 10.3125
Epoch: 46, loss (training): 10.009, loss (eval): 10.4128
Early-stopping. Training converged after 47 epochs.
start update posterior model
Epoch: 0, loss (training): 13.1439, loss (eval): 13.2731
Epoch: 1, loss (training): 13.1403, loss (eval): 13.1335
Epoch: 2, loss (training): 13.1525, loss (eval): 13.14
Epoch: 3, loss (training): 13.144, loss (eval): 13.1595
Epoch: 4, loss (training): 13.1425, loss (eval): 13.1455
Epoch: 5, loss (training): 13.1411, loss (eval): 13.1429
Epoch: 6, loss (training): 13.1417, loss (eval): 13.1311
Epoch: 7, loss (training): 13.1457, loss (eval): 13.1342
Epoch: 8, loss (training): 13.1403, loss (eval): 13.1485
Epoch: 9, loss (training): 13.1439, loss (eval): 13.1427
Epoch: 10, loss (training): 13.1419, loss (eval): 13.1405
Epoch: 11, loss (training): 13.1452, loss (eval): 13.1343
Epoch: 12, loss (training): 13.1437, loss (eval): 13.1435
Epoch: 13, loss (training): 13.1442, loss (eval): 13.1511
Epoch: 14, loss (training): 13.1487, loss (eval): 13.1342
Epoch: 15, loss (training): 13.1465, loss (eval): 13.1336
Epoch: 16, loss (training): 13.1469, loss (eval): 13.1435
Epoch: 17, loss (training): 13.1459, loss (eval): 13.1664
Epoch: 18, loss (training): 13.1485, loss (eval): 13.1375
Epoch: 19, loss (training): 13.1443, loss (eval): 13.1378
Epoch: 20, loss (training): 13.1432, loss (eval): 13.133
Epoch: 21, loss (training): 13.1433, loss (eval): 13.1473
Epoch: 22, loss (training): 13.1452, loss (eval): 13.1466
Epoch: 23, loss (training): 13.146, loss (eval): 13.1697
Epoch: 24, loss (training): 13.1433, loss (eval): 13.1513
Epoch: 25, loss (training): 13.1439, loss (eval): 13.1408
Early-stopping. Training converged after 26 epochs.
Iteration: 8
optimizer_post_lr: [0.0013966745921874994]
prob_prior: 0.007446583070924344
start update likelihood model
Epoch: 0, loss (training): 10.2035, loss (eval): 10.1674
Epoch: 1, loss (training): 10.1125, loss (eval): 10.0421
Epoch: 2, loss (training): 10.0852, loss (eval): 10.0004
Epoch: 3, loss (training): 10.0725, loss (eval): 9.9988
Epoch: 4, loss (training): 10.0637, loss (eval): 9.9162
Epoch: 5, loss (training): 10.0644, loss (eval): 10.0397
Epoch: 6, loss (training): 10.0624, loss (eval): 9.926
Epoch: 7, loss (training): 10.0411, loss (eval): 10.0064
Epoch: 8, loss (training): 10.037, loss (eval): 10.0128
Epoch: 9, loss (training): 10.0156, loss (eval): 9.9976
Epoch: 10, loss (training): 10.0231, loss (eval): 10.011
Epoch: 11, loss (training): 10.0225, loss (eval): 10.0316
Epoch: 12, loss (training): 10.0367, loss (eval): 9.9711
Epoch: 13, loss (training): 10.0371, loss (eval): 10.061
Epoch: 14, loss (training): 10.0349, loss (eval): 10.0213
Epoch: 15, loss (training): 10.0181, loss (eval): 9.991
Epoch: 16, loss (training): 9.9989, loss (eval): 9.9918
Epoch: 17, loss (training): 10.0242, loss (eval): 10.0039
Epoch: 18, loss (training): 10.0021, loss (eval): 10.076
Epoch: 19, loss (training): 10.0051, loss (eval): 10.0017
Epoch: 20, loss (training): 10.0194, loss (eval): 9.9834
Epoch: 21, loss (training): 10.0039, loss (eval): 10.0828
Epoch: 22, loss (training): 9.9757, loss (eval): 10.0527
Epoch: 23, loss (training): 10.0065, loss (eval): 9.9663
Early-stopping. Training converged after 24 epochs.
start update posterior model
Epoch: 0, loss (training): 13.4395, loss (eval): 13.4766
Epoch: 1, loss (training): 13.4356, loss (eval): 13.4259
Epoch: 2, loss (training): 13.4415, loss (eval): 13.4357
Epoch: 3, loss (training): 13.4348, loss (eval): 13.4294
Epoch: 4, loss (training): 13.4368, loss (eval): 13.4373
Epoch: 5, loss (training): 13.4376, loss (eval): 13.4416
Epoch: 6, loss (training): 13.4353, loss (eval): 13.4282
Epoch: 7, loss (training): 13.4355, loss (eval): 13.426
Epoch: 8, loss (training): 13.44, loss (eval): 13.4402
Epoch: 9, loss (training): 13.44, loss (eval): 13.4289
Epoch: 10, loss (training): 13.4343, loss (eval): 13.4321
Epoch: 11, loss (training): 13.4386, loss (eval): 13.4588
Epoch: 12, loss (training): 13.436, loss (eval): 13.4474
Epoch: 13, loss (training): 13.4359, loss (eval): 13.4366
Epoch: 14, loss (training): 13.4336, loss (eval): 13.4336
Epoch: 15, loss (training): 13.4353, loss (eval): 13.4488
Epoch: 16, loss (training): 13.4385, loss (eval): 13.4398
Epoch: 17, loss (training): 13.4368, loss (eval): 13.4646
Epoch: 18, loss (training): 13.4368, loss (eval): 13.4332
Epoch: 19, loss (training): 13.4345, loss (eval): 13.4483
Epoch: 20, loss (training): 13.4386, loss (eval): 13.4327
Early-stopping. Training converged after 21 epochs.
Iteration: 9
optimizer_post_lr: [0.0013268408625781243]
prob_prior: 0.003697863716482932
start update likelihood model
Epoch: 0, loss (training): 10.1704, loss (eval): 10.0919
Epoch: 1, loss (training): 10.1416, loss (eval): 10.1113
Epoch: 2, loss (training): 10.1179, loss (eval): 10.0563
Epoch: 3, loss (training): 10.1076, loss (eval): 10.096
Epoch: 4, loss (training): 10.09, loss (eval): 10.0812
Epoch: 5, loss (training): 10.1024, loss (eval): 10.0916
Epoch: 6, loss (training): 10.1032, loss (eval): 10.1831
Epoch: 7, loss (training): 10.0775, loss (eval): 10.0657
Epoch: 8, loss (training): 10.0982, loss (eval): 10.1777
Epoch: 9, loss (training): 10.0675, loss (eval): 10.0636
Epoch: 10, loss (training): 10.1036, loss (eval): 10.1255
Epoch: 11, loss (training): 10.0818, loss (eval): 10.1157
Epoch: 12, loss (training): 10.0913, loss (eval): 10.1048
Epoch: 13, loss (training): 10.0906, loss (eval): 10.0932
Epoch: 14, loss (training): 10.0603, loss (eval): 10.0744
Epoch: 15, loss (training): 10.0718, loss (eval): 10.1228
Epoch: 16, loss (training): 10.0589, loss (eval): 10.0939
Epoch: 17, loss (training): 10.0578, loss (eval): 10.0811
Epoch: 18, loss (training): 10.067, loss (eval): 10.0634
Epoch: 19, loss (training): 10.0631, loss (eval): 10.1246
Epoch: 20, loss (training): 10.0698, loss (eval): 10.1265
Epoch: 21, loss (training): 10.0544, loss (eval): 10.1524
Early-stopping. Training converged after 22 epochs.
start update posterior model
Epoch: 0, loss (training): 13.0262, loss (eval): 13.1256
Epoch: 1, loss (training): 13.0252, loss (eval): 13.0302
Epoch: 2, loss (training): 13.0218, loss (eval): 13.0248
Epoch: 3, loss (training): 13.0237, loss (eval): 13.0381
Epoch: 4, loss (training): 13.0233, loss (eval): 13.0278
Epoch: 5, loss (training): 13.0229, loss (eval): 13.0401
Epoch: 6, loss (training): 13.0214, loss (eval): 13.0147
Epoch: 7, loss (training): 13.0213, loss (eval): 13.0322
Epoch: 8, loss (training): 13.0273, loss (eval): 13.0177
Epoch: 9, loss (training): 13.0238, loss (eval): 13.0203
Epoch: 10, loss (training): 13.0287, loss (eval): 13.0199
Epoch: 11, loss (training): 13.0265, loss (eval): 13.0468
Epoch: 12, loss (training): 13.0267, loss (eval): 13.0182
Epoch: 13, loss (training): 13.0257, loss (eval): 13.0274
Epoch: 14, loss (training): 13.0261, loss (eval): 13.0235
Epoch: 15, loss (training): 13.0217, loss (eval): 13.0299
Epoch: 16, loss (training): 13.0226, loss (eval): 13.0356
Epoch: 17, loss (training): 13.0213, loss (eval): 13.0244
Epoch: 18, loss (training): 13.0265, loss (eval): 13.0131
Epoch: 19, loss (training): 13.0225, loss (eval): 13.0147
Epoch: 20, loss (training): 13.0228, loss (eval): 13.0117
Epoch: 21, loss (training): 13.0208, loss (eval): 13.023
Epoch: 22, loss (training): 13.0181, loss (eval): 13.0197
Epoch: 23, loss (training): 13.0219, loss (eval): 13.0802
Epoch: 24, loss (training): 13.0232, loss (eval): 13.0316
Epoch: 25, loss (training): 13.026, loss (eval): 13.0207
Epoch: 26, loss (training): 13.0239, loss (eval): 13.0403
Epoch: 27, loss (training): 13.0218, loss (eval): 13.02
Epoch: 28, loss (training): 13.0243, loss (eval): 13.0646
Epoch: 29, loss (training): 13.0242, loss (eval): 13.0327
Epoch: 30, loss (training): 13.0184, loss (eval): 13.017
Epoch: 31, loss (training): 13.0206, loss (eval): 13.0264
Epoch: 32, loss (training): 13.0212, loss (eval): 13.0158
Epoch: 33, loss (training): 13.0209, loss (eval): 13.0455
Epoch: 34, loss (training): 13.0249, loss (eval): 13.0377
Epoch: 35, loss (training): 13.0228, loss (eval): 13.0173
Epoch: 36, loss (training): 13.0202, loss (eval): 13.014
Epoch: 37, loss (training): 13.019, loss (eval): 13.0105
Epoch: 38, loss (training): 13.0229, loss (eval): 13.0259
Epoch: 39, loss (training): 13.0241, loss (eval): 13.0135
Epoch: 40, loss (training): 13.0197, loss (eval): 13.0128
Epoch: 41, loss (training): 13.0212, loss (eval): 13.0127
Epoch: 42, loss (training): 13.0231, loss (eval): 13.0174
Epoch: 43, loss (training): 13.0181, loss (eval): 13.0193
Epoch: 44, loss (training): 13.023, loss (eval): 13.0358
Epoch: 45, loss (training): 13.0229, loss (eval): 13.0274
Epoch: 46, loss (training): 13.0247, loss (eval): 13.0189
Epoch: 47, loss (training): 13.0263, loss (eval): 13.0148
Epoch: 48, loss (training): 13.0212, loss (eval): 13.0231
Epoch: 49, loss (training): 13.0203, loss (eval): 13.0156
Epoch: 50, loss (training): 13.0209, loss (eval): 13.012
Epoch: 51, loss (training): 13.0205, loss (eval): 13.0274
Epoch: 52, loss (training): 13.0205, loss (eval): 13.0113
Epoch: 53, loss (training): 13.0224, loss (eval): 13.0274
Epoch: 54, loss (training): 13.0229, loss (eval): 13.0158
Epoch: 55, loss (training): 13.0251, loss (eval): 13.0367
Epoch: 56, loss (training): 13.0244, loss (eval): 13.0185
Epoch: 57, loss (training): 13.0206, loss (eval): 13.0101
Epoch: 58, loss (training): 13.0277, loss (eval): 13.0483
Epoch: 59, loss (training): 13.0208, loss (eval): 13.0159
Epoch: 60, loss (training): 13.0243, loss (eval): 13.0179
Epoch: 61, loss (training): 13.0215, loss (eval): 13.0209
Epoch: 62, loss (training): 13.0222, loss (eval): 13.0208
Epoch: 63, loss (training): 13.022, loss (eval): 13.0172
Epoch: 64, loss (training): 13.0225, loss (eval): 13.0297
Epoch: 65, loss (training): 13.0207, loss (eval): 13.0289
Epoch: 66, loss (training): 13.0199, loss (eval): 13.0162
Epoch: 67, loss (training): 13.0223, loss (eval): 13.0192
Epoch: 68, loss (training): 13.022, loss (eval): 13.0262
Epoch: 69, loss (training): 13.0226, loss (eval): 13.0314
Epoch: 70, loss (training): 13.0194, loss (eval): 13.0103
Epoch: 71, loss (training): 13.0248, loss (eval): 13.017
Epoch: 72, loss (training): 13.0232, loss (eval): 13.0391
Epoch: 73, loss (training): 13.0231, loss (eval): 13.0217
Epoch: 74, loss (training): 13.0187, loss (eval): 13.0243
Iteration: 10
optimizer_post_lr: [0.001260498819449218]
prob_prior: 0.0018363047770289071
start update likelihood model
Epoch: 0, loss (training): 10.1934, loss (eval): 10.2747
Epoch: 1, loss (training): 10.1505, loss (eval): 10.2989
Epoch: 2, loss (training): 10.0881, loss (eval): 10.2043
Epoch: 3, loss (training): 10.0848, loss (eval): 10.2881
Epoch: 4, loss (training): 10.1005, loss (eval): 10.2285
Epoch: 5, loss (training): 10.0887, loss (eval): 10.1921
Epoch: 6, loss (training): 10.0821, loss (eval): 10.2356
Epoch: 7, loss (training): 10.0809, loss (eval): 10.2687
Epoch: 8, loss (training): 10.0377, loss (eval): 10.2742
Epoch: 9, loss (training): 10.0253, loss (eval): 10.207
Epoch: 10, loss (training): 10.0439, loss (eval): 10.2112
Epoch: 11, loss (training): 10.0298, loss (eval): 10.1953
Epoch: 12, loss (training): 10.0229, loss (eval): 10.1732
Epoch: 13, loss (training): 10.0379, loss (eval): 10.2445
Epoch: 14, loss (training): 10.046, loss (eval): 10.208
Epoch: 15, loss (training): 10.0268, loss (eval): 10.2582
Epoch: 16, loss (training): 10.0403, loss (eval): 10.2509
Epoch: 17, loss (training): 10.0139, loss (eval): 10.1768
Epoch: 18, loss (training): 10.0372, loss (eval): 10.1825
Epoch: 19, loss (training): 10.0437, loss (eval): 10.2601
Epoch: 20, loss (training): 10.0319, loss (eval): 10.1729
Epoch: 21, loss (training): 10.0434, loss (eval): 10.2176
Epoch: 22, loss (training): 10.0311, loss (eval): 10.2626
Epoch: 23, loss (training): 10.0401, loss (eval): 10.2508
Epoch: 24, loss (training): 10.0475, loss (eval): 10.2603
Epoch: 25, loss (training): 10.0251, loss (eval): 10.2142
Epoch: 26, loss (training): 10.0015, loss (eval): 10.2432
Epoch: 27, loss (training): 9.9982, loss (eval): 10.2756
Epoch: 28, loss (training): 10.0229, loss (eval): 10.2578
Epoch: 29, loss (training): 10.0194, loss (eval): 10.3644
Epoch: 30, loss (training): 10.0012, loss (eval): 10.29
Epoch: 31, loss (training): 9.9765, loss (eval): 10.282
Epoch: 32, loss (training): 10.0225, loss (eval): 10.2567
Epoch: 33, loss (training): 9.9923, loss (eval): 10.258
Epoch: 34, loss (training): 9.9964, loss (eval): 10.2158
Epoch: 35, loss (training): 10.0037, loss (eval): 10.1952
Epoch: 36, loss (training): 10.0178, loss (eval): 10.2234
Epoch: 37, loss (training): 10.0097, loss (eval): 10.247
Epoch: 38, loss (training): 10.0192, loss (eval): 10.2179
Epoch: 39, loss (training): 10.0292, loss (eval): 10.2648
Early-stopping. Training converged after 40 epochs.
start update posterior model
Epoch: 0, loss (training): 13.6595, loss (eval): 13.9102
Epoch: 1, loss (training): 13.6471, loss (eval): 13.6412
Epoch: 2, loss (training): 13.6464, loss (eval): 13.6393
Epoch: 3, loss (training): 13.6498, loss (eval): 13.6386
Epoch: 4, loss (training): 13.6498, loss (eval): 13.6428
Epoch: 5, loss (training): 13.6452, loss (eval): 13.6529
Epoch: 6, loss (training): 13.6513, loss (eval): 13.6588
Epoch: 7, loss (training): 13.6459, loss (eval): 13.6662
Epoch: 8, loss (training): 13.6478, loss (eval): 13.6431
Epoch: 9, loss (training): 13.6522, loss (eval): 13.6446
Epoch: 10, loss (training): 13.6466, loss (eval): 13.638
Epoch: 11, loss (training): 13.648, loss (eval): 13.6543
Epoch: 12, loss (training): 13.6494, loss (eval): 13.6439
Epoch: 13, loss (training): 13.6475, loss (eval): 13.6503
Epoch: 14, loss (training): 13.6476, loss (eval): 13.646
Epoch: 15, loss (training): 13.6475, loss (eval): 13.6459
Epoch: 16, loss (training): 13.6521, loss (eval): 13.6474
Epoch: 17, loss (training): 13.6444, loss (eval): 13.6473
Epoch: 18, loss (training): 13.6502, loss (eval): 13.6414
Epoch: 19, loss (training): 13.6482, loss (eval): 13.6369
Epoch: 20, loss (training): 13.649, loss (eval): 13.6451
Epoch: 21, loss (training): 13.6517, loss (eval): 13.6676
Epoch: 22, loss (training): 13.6443, loss (eval): 13.6418
Epoch: 23, loss (training): 13.6489, loss (eval): 13.6455
Epoch: 24, loss (training): 13.6444, loss (eval): 13.6451
Epoch: 25, loss (training): 13.6524, loss (eval): 13.6526
Epoch: 26, loss (training): 13.6444, loss (eval): 13.6461
Epoch: 27, loss (training): 13.6468, loss (eval): 13.665
Epoch: 28, loss (training): 13.6464, loss (eval): 13.6452
Epoch: 29, loss (training): 13.6447, loss (eval): 13.645
Epoch: 30, loss (training): 13.6472, loss (eval): 13.6411
Epoch: 31, loss (training): 13.6481, loss (eval): 13.6406
Epoch: 32, loss (training): 13.6465, loss (eval): 13.6434
Epoch: 33, loss (training): 13.6501, loss (eval): 13.6513
Epoch: 34, loss (training): 13.6473, loss (eval): 13.6391
Epoch: 35, loss (training): 13.647, loss (eval): 13.6461
Epoch: 36, loss (training): 13.6462, loss (eval): 13.645
Epoch: 37, loss (training): 13.6471, loss (eval): 13.6625
Epoch: 38, loss (training): 13.6492, loss (eval): 13.645
Early-stopping. Training converged after 39 epochs.

Runtime:1848.79
0
1
2
3
4
5
6
7
8
9
