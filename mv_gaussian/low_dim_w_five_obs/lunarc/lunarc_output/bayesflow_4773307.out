Input args:
Dim: 2
seed: 34
seed_data: 10
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev/mv_gaussian/low_dim_w_five_obs/lunarc
/home/samwiq/snpla/seq-posterior-approx-w-nf-dev
Nbr trainable parameters: 17776
start training
Epoch: 0, loss: 0.8031074827723205, eval loss: 7.011046409606934
Epoch: 1, loss: 0.4911125656706281, eval loss: 0.5032663941383362
Epoch: 2, loss: 0.4536386641068384, eval loss: 0.5069166421890259
Epoch: 3, loss: 0.43520930599304847, eval loss: 0.44901391863822937
Epoch: 4, loss: 0.42666827123844997, eval loss: 0.43795719742774963
Epoch: 5, loss: 0.41911157934810034, eval loss: 0.4639846384525299
Epoch: 6, loss: 0.4141257474324084, eval loss: 0.4418943524360657
Epoch: 7, loss: 0.4093093401502119, eval loss: 0.46058332920074463
Epoch: 8, loss: 0.4031901289406232, eval loss: 0.43764227628707886
Epoch: 9, loss: 0.39763131113169947, eval loss: 0.48887747526168823
Epoch: 10, loss: 0.39583713364809225, eval loss: 0.44882285594940186
Epoch: 11, loss: 0.39309385822401965, eval loss: 0.4161710739135742
Epoch: 12, loss: 0.39232150979165453, eval loss: 0.4295908808708191
Epoch: 13, loss: 0.39017186022130773, eval loss: 0.4292110502719879
Epoch: 14, loss: 0.38932268361968453, eval loss: 0.4479505121707916
Epoch: 15, loss: 0.38958786599325324, eval loss: 0.4358275532722473
Epoch: 16, loss: 0.3875308810459319, eval loss: 0.43436577916145325
Epoch: 17, loss: 0.3837241033144528, eval loss: 0.41189780831336975
Epoch: 18, loss: 0.38740370722895023, eval loss: 0.43508315086364746
Epoch: 19, loss: 0.3863288478727918, eval loss: 0.41484200954437256
Epoch: 20, loss: 0.38552267891012887, eval loss: 0.4595194160938263
Epoch: 21, loss: 0.3819636052416172, eval loss: 0.4203517735004425
Epoch: 22, loss: 0.3836900397697173, eval loss: 0.4321330189704895
Epoch: 23, loss: 0.38170623657060787, eval loss: 0.49409961700439453
Epoch: 24, loss: 0.3835492347541731, eval loss: 0.4113980233669281
Epoch: 25, loss: 0.380519333632401, eval loss: 0.4075690805912018
Epoch: 26, loss: 0.37987358268001115, eval loss: 0.41515591740608215
Epoch: 27, loss: 0.3829383808828425, eval loss: 0.39728155732154846
Epoch: 28, loss: 0.37814338292286265, eval loss: 0.41217753291130066
Epoch: 29, loss: 0.3808264909223362, eval loss: 0.4179835319519043
Epoch: 30, loss: 0.378360794413602, eval loss: 0.41513845324516296
Epoch: 31, loss: 0.3815523329365897, eval loss: 0.40447792410850525
Epoch: 32, loss: 0.37741450341651217, eval loss: 0.41519880294799805
Epoch: 33, loss: 0.3805143674541614, eval loss: 0.41664478182792664
Epoch: 34, loss: 0.3787240720500267, eval loss: 0.3981810212135315
Epoch: 35, loss: 0.38186951956537085, eval loss: 0.4497242271900177
Epoch: 36, loss: 0.37877550588105807, eval loss: 0.40142667293548584
Epoch: 37, loss: 0.3791844385123113, eval loss: 0.4011019468307495
Epoch: 38, loss: 0.38137201418867334, eval loss: 0.4149359464645386
Epoch: 39, loss: 0.3782107277587056, eval loss: 0.43740418553352356
Epoch: 40, loss: 0.38019723465753485, eval loss: 0.4146522581577301
Epoch: 41, loss: 0.38049728433208657, eval loss: 0.41877222061157227
Epoch: 42, loss: 0.3822054127452793, eval loss: 0.40409231185913086
Epoch: 43, loss: 0.3808085600928098, eval loss: 0.4099307358264923
Epoch: 44, loss: 0.38068482930164466, eval loss: 0.40118035674095154
Epoch: 45, loss: 0.38119606747830403, eval loss: 0.42343124747276306
Epoch: 46, loss: 0.3807773237820948, eval loss: 0.4190636873245239
Epoch: 47, loss: 0.38137507763342, eval loss: 0.45829251408576965
Epoch: 48, loss: 0.3811279673804529, eval loss: 0.44160380959510803
Epoch: 49, loss: 0.3814361788958195, eval loss: 0.42623916268348694

Runtime:586.22
KL div untrained: 2.01223065008448e+18
KL div trained: 0.0136
